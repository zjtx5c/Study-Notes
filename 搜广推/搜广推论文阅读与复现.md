# ç”Ÿæˆå¼æ¨èç³»ç»Ÿ

## Content-Based Collaborative Generation for Recommender Systems

* ç”Ÿæˆå¼æ¨èæ‰€åˆ©ç”¨çš„å†…å®¹ä¿¡æ¯èƒ½åœ¨é•¿å°¾æ•ˆåº”ä¸‹å‘æŒ¥å·¨å¤§çš„æ½œåŠ›ï¼šColaRecåœ¨**å†…å®¹ä¿¡æ¯çš„å¸®åŠ©ä¸‹è·å¾—äº†æ›´å¥½çš„æ€§èƒ½**



### å¼•è¨€

#### æ¨èç³»ç»Ÿ**é¢ä¸´çš„ä¸¤ä¸ªå…³é”®æŒ‘æˆ˜**ï¼š

1. ååŒä¿¡æ¯çš„ç¨€ç–æ€§

   åœ¨å†·å¯åŠ¨ã€é•¿å°¾ç”¨æˆ·åœºæ™¯ä¸‹ï¼Œç¼ºå°‘ç”¨æˆ·-ç‰©å“äº¤äº’ï¼ˆinteractionï¼‰ä½¿å¾—ååŒè¿‡æ»¤éš¾ä»¥å­¦ä¹ æœ‰æ•ˆåå¥½ã€‚

2. å†…å®¹ä¿¡æ¯çš„è¡¨è¾¾å—é™

   å†…å®¹ä¿¡æ¯ï¼ˆå¦‚å•†å“æè¿°ã€æ–‡æœ¬ã€å›¾ç‰‡ï¼‰è™½ç„¶æ˜“è·å–ï¼Œä½†ç°æœ‰æ¨¡å‹å¾€å¾€ï¼š

   - **ç›´æ¥ç¼–ç å†…å®¹ â†’ åšåŒ¹é…æˆ–åˆ†ç±»**ï¼ˆe.g., å°†ç‰©å“å†…å®¹ç¼–ç åä¸ç”¨æˆ·è¡¨ç¤ºåšå†…ç§¯ï¼‰ï¼Œ

     > è€Œ ColaRec é€šè¿‡è®©æ¨¡å‹ç”Ÿæˆ item çš„æ ‡è¯†ç¬¦ GIDï¼Œ**è€Œä¸æ˜¯ç‚¹ç§¯åŒ¹é…**ï¼Œå°†æ¨è**å»ºæ¨¡ä¸ºåºåˆ—ç”Ÿæˆé—®é¢˜**ï¼Œè¿™å¤§å¤§**å¢å¼ºäº†è¡¨è¾¾èƒ½åŠ›**ï¼Œå¹¶èƒ½é€šè¿‡**å¤šä»»åŠ¡è®­ç»ƒèåˆååŒå’Œå†…å®¹ä¿¡æ¯**ï¼Œå®ç°æ›´å¼ºçš„å†·å¯åŠ¨å’Œæ³›åŒ–èƒ½åŠ›ã€‚

   - **è¡¨è¾¾èƒ½åŠ›å¼±**ï¼Œå¾ˆéš¾å­¦åˆ°é«˜è´¨é‡çš„å¤šç²’åº¦ï¼ˆmulti-granularityï¼‰ä¿¡æ¯ã€‚



#### å½“å‰ä¸»æµæ¨èèŒƒå¼çš„é—®é¢˜

å½“å‰çš„æ¨èæ¨¡å‹å¤§è‡´å¯åˆ†ä¸ºä»¥ä¸‹å‡ ç±»ï¼š

1. **ååŒè¿‡æ»¤ï¼ˆCFï¼‰æ¨¡å‹**ï¼šä¾èµ–äº¤äº’çŸ©é˜µï¼Œä½†æ— æ³•å¤„ç†å†·å¯åŠ¨ã€‚
2. **å†…å®¹é©±åŠ¨ï¼ˆContent-Basedï¼‰æ¨¡å‹**ï¼šè¡¨è¾¾èƒ½åŠ›æœ‰é™ã€‚
3. **æ£€ç´¢-æ’åºä¸¤é˜¶æ®µï¼ˆTwo-tower / DSSMï¼‰**ï¼šç¼ºå°‘å¤šä»»åŠ¡å»ºæ¨¡ä¸äº¤äº’ã€‚ï¼ˆè¿™ä¸ªå¦‚ä½•ç†è§£ï¼Ÿï¼‰

> è¿™äº›æ–¹æ³•å¤§å¤šé‡‡ç”¨â€œç‚¹å¼åŒ¹é…â€ï¼ˆpoint-wise matchingï¼‰ï¼Œè€Œéç”Ÿæˆå¼é¢„æµ‹ã€‚



#### æœ¬æ–‡æ–¹æ³•

> ä¸€ä¸ªåŸºäºæ–‡æœ¬å†…å®¹çš„æ¨èç³»ç»Ÿï¼Œé‡‡ç”¨**ç”Ÿæˆå¼å»ºæ¨¡æ€æƒ³**ï¼Œå°†æ¨èä»»åŠ¡å»ºæ¨¡ä¸º **åºåˆ—ç”Ÿæˆï¼ˆSequence Generationï¼‰ä»»åŠ¡**ã€‚

æ ¸å¿ƒæ€æƒ³

1. **ç”¨è‡ªç„¶è¯­è¨€çš„æ–¹å¼â€œç”Ÿæˆâ€ç‰©å“æ ‡è¯†ç¬¦ï¼ˆGIDï¼‰** æ¥è¡¨ç¤ºç”¨æˆ·æ„Ÿå…´è¶£çš„ç‰©å“ã€‚
2. GID æ˜¯ä¸€ä¸ª token åºåˆ—ï¼Œä»å¤šä¸ª codebook ä¸­é€‰å‡º token ç»„åˆï¼Œç±»ä¼¼å‘é‡é‡åŒ–ï¼ˆVQ-VAEï¼‰ã€‚
3. ä½¿ç”¨ **å…±äº« T5 encoder-decoder æ¶æ„**ï¼Œå¯¹è¾“å…¥å†…å®¹è¿›è¡Œå»ºæ¨¡ï¼Œè¾“å‡ºå¤šç²’åº¦çš„ token çº§åˆ«é¢„æµ‹ã€‚



#### ä¼˜åŠ¿

1. **èåˆå†…å®¹ä¸ååŒä¿¡å·**ï¼šé€šè¿‡ç¼–ç  item å†…å®¹å’Œå­¦ä¹ å¼ GID ç”Ÿæˆå™¨ï¼Œä½¿æ¨¡å‹å…¼é¡¾è¯­ä¹‰ä¸ååŒæ¨èèƒ½åŠ›ã€‚

2. **æ”¯æŒç»Ÿä¸€å»ºæ¨¡å¤šä¸ªæ¨èä»»åŠ¡**ï¼šæ¨èã€ç´¢å¼•ï¼ˆGIDæ„é€ ï¼‰ã€æ’åºã€å¯¹æ¯”å­¦ä¹ ç­‰ã€‚

3. **ç”Ÿæˆå¼è¾“å‡ºæä¾›å¯è§£é‡Šæ€§å’Œæ›´å¼ºçš„è¡¨ç¤ºå­¦ä¹ èƒ½åŠ›**ã€‚



### ç›¸å…³å·¥ä½œ

ä½œè€…å°†ç›¸å…³å·¥ä½œåˆ†ä¸ºä¸‰å¤§ç±»

#### Collaborative Filteringï¼ˆååŒè¿‡æ»¤ï¼‰

* ä¼ ç»ŸååŒè¿‡æ»¤

  å¦‚ **Matrix Factorization**ï¼ˆçŸ©é˜µåˆ†è§£ï¼‰ã€**Neural CF**ã€ä»¥åŠåç»­çš„å›¾ç¥ç»ç½‘ç»œæ–¹æ³•ï¼ˆå¦‚ NGCFã€LightGCNï¼‰ã€‚

  **ä¼˜ç‚¹**ï¼šèƒ½æœ‰æ•ˆæ•æ‰ç”¨æˆ·ä¹‹é—´çš„è¡Œä¸ºç›¸ä¼¼æ€§ã€‚

  **ç¼ºç‚¹**ï¼šä¸¥é‡ä¾èµ–äº¤äº’è¡Œä¸ºï¼ˆinteraction logsï¼‰ï¼Œå¯¹å†·å¯åŠ¨ç”¨æˆ·æˆ–ç‰©å“ä¸å‹å¥½ã€‚

* è¿‘æœŸçš„å‘é‡åŒ–ååŒæ–¹æ³•

  æ¯”å¦‚ **VQ-VAE for CF**ï¼Œå°†ç”¨æˆ·æˆ– item æ˜ å°„åˆ° codebook ä¸­çš„ç´¢å¼•ã€‚

  ä¸ ColaRec ä½¿ç”¨ GID çš„æ€æƒ³æœ‰ä¸€å®šç›¸ä¼¼ä¹‹å¤„ï¼Œä½†è¿™äº›æ–¹æ³•å¤šç”¨äºè¡¨ç¤ºå‹ç¼©æˆ–æ£€ç´¢ä¼˜åŒ–ï¼Œè€Œéç”Ÿæˆå¼å»ºæ¨¡ã€‚

  ç¡®å®è¿™ç§**ç¦»æ•£åŒ–å¤„ç†**ç¡®å®èƒ½å¤Ÿ**åŠ é€Ÿæ£€ç´¢** + **æé«˜æ³›åŒ–æ€§èƒ½**



#### Content-Based Recommendationï¼ˆå†…å®¹é©±åŠ¨æ¨èï¼‰

- å†…å®¹æ¨èæ–¹æ³•é€šè¿‡ç¼–ç  item çš„æ–‡æœ¬ä¿¡æ¯ï¼ˆå¦‚æ ‡é¢˜ã€æè¿°ï¼‰æ¥è¾…åŠ©æ¨èã€‚
- å¸¸ç”¨æ–¹å¼ï¼š
  - æ–‡æœ¬ â†’ å‘é‡ â†’ ä¸ç”¨æˆ·åšåŒ¹é…ï¼ˆä¾‹å¦‚ï¼šåŒå¡”ç»“æ„ DSSMï¼‰ã€‚
  - æˆ–ç”¨æ–‡æœ¬ç‰¹å¾åšæ’åºã€‚
- **é—®é¢˜**ï¼šè¿™äº›æ–¹æ³•å¾€å¾€å°†å†…å®¹ç¼–ç æˆä¸€ä¸ªå‘é‡ï¼ˆpoint representationï¼‰ï¼Œå¾ˆéš¾æŒ–æ˜å†…å®¹çš„å¤šç²’åº¦ä¿¡æ¯ã€‚

* ColaRec çš„ä¼˜åŠ¿ï¼š

  - ç›´æ¥åœ¨ token çº§åˆ«å»ºæ¨¡ item è¡¨ç¤ºï¼ˆå³ç”Ÿæˆ GID åºåˆ—ï¼‰ï¼›ï¼ˆè¿™ä¸ªå…·ä½“æ˜¯æ€ä¹ˆç†è§£çš„ï¼‰

  - ç”¨ decoder å¼ºåŒ–å¤šç²’åº¦ã€ç»“æ„åŒ–çš„å†…å®¹è¡¨è¾¾ã€‚



#### Generative Recommendationï¼ˆç”Ÿæˆå¼æ¨èï¼‰

è¿‘å¹´æ¥ï¼Œç”Ÿæˆå¼æ¨èï¼ˆGenerative Recommendationï¼‰é€æ¸å…´èµ·ï¼Œå°†æ¨èçœ‹ä½œåºåˆ—å»ºæ¨¡é—®é¢˜ã€‚

* **åŸºäº GPT/BERT çš„ç”Ÿæˆæ–¹æ³•**ï¼š

  - ä¾‹å¦‚ SASRecã€BERT4Rec ç­‰ï¼Œä½¿ç”¨ masked æˆ– auto-regressive æœºåˆ¶é¢„æµ‹ä¸‹ä¸€ä¸ª itemï¼›

  - ä½†ç”Ÿæˆçš„æ˜¯ item IDï¼Œ**æœ¬è´¨ä»æ˜¯ç¦»æ•£åˆ†ç±»**ï¼Œ==**ä¸å…·å¤‡ token çº§çš„ç»“æ„å»ºæ¨¡èƒ½åŠ›**ã€‚==
    - item ID æ˜¯åŸå­å•ä½ï¼Œä¸èƒ½åƒ ColaRec é‚£æ ·è¢«åˆ†è§£ä¸ºå¤š token

* **æ£€ç´¢ç”Ÿæˆï¼ˆretrieve-then-generateï¼‰ç±»æ–¹æ³•**ï¼š

  - ä¸€äº›æ–¹æ³•å°†ç”Ÿæˆå’Œæ£€ç´¢ç»“åˆï¼Œå¦‚ä½¿ç”¨æ–‡æœ¬æè¿°ç”Ÿæˆ item åç§°ï¼›

  - ä½†è¿™äº›é€šå¸¸ç”¨äºå†·å¯åŠ¨çš„è¡¥å……ï¼Œè€Œéæ ¸å¿ƒå»ºæ¨¡æœºåˆ¶ã€‚





### æ–¹æ³•è®º

1. æ¨¡å‹æ€»è§ˆ
2. user-itemæ¨èç³»ç»Ÿä»»åŠ¡
3. item-itemç´¢å¼•ä»»åŠ¡
4. å°†ä¸Šè¿°ä»»åŠ¡çš„è”åˆä¼˜åŒ–

#### æ¨¡å‹æ€»è§ˆ

å›¾3æ˜¾ç¤ºäº†æ‹Ÿè®®çš„ColaRecçš„æ¦‚è¿°ã€‚ColaRecä½¿ç”¨**åŸºäºå›¾çš„CFæ¨¡å‹**æ„å»ºGIDï¼Œè¯¥æ¨¡å‹æœ‰æ•ˆåœ°æ•è·äº†åä½œä¿¡å·ã€‚ColaRecçš„è®­ç»ƒåŒ…æ‹¬ä¸¤ä¸ªä»»åŠ¡ï¼š**ç”¨æˆ·é¡¹ç›®æ¨èä»»åŠ¡**å’Œ**é¡¹ç›®ç´¢å¼•ä»»åŠ¡**ã€‚ç”¨æˆ·é¡¹ç›®æ¨èæ—¨åœ¨å°†ç”¨æˆ·å†å²äº¤äº’é¡¹ç›®çš„**å†…å®¹ä¿¡æ¯**æ˜ å°„åˆ°æ¨èé¡¹ç›®çš„GIDä¸­ã€‚é¡¹ç›®ç´¢å¼•ä»»åŠ¡çš„ç›®æ ‡æ˜¯ä»**é¡¹ç›®ä¾§ä¿¡æ¯**åˆ°é¡¹ç›®GIDçš„æ˜ å°„ã€‚è¿™ä¸¤ä¸ªä»»åŠ¡éƒ½æ˜¯é€šè¿‡åŸºäº**å…±äº«ç¼–ç å™¨-è§£ç å™¨**çš„æ¨¡å‹ï¼ˆT5ï¼‰æ¥å®ç°çš„ã€‚æ¨èä»»åŠ¡ç»Ÿä¸€åä½œä¿¡å·å’Œé¡¹ç›®å†…å®¹ä¿¡æ¯ä»¥è·å¾—æ›´å¥½çš„æ¨èï¼Œè€Œç´¢å¼•ä»»åŠ¡åˆ™æ‰§è¡Œåä½œä¿¡å·å’Œå†…å®¹ä¿¡æ¯ä¹‹é—´çš„**å¯¹é½**ã€‚ã€å¤§æ¦‚æ‡‚äº†ï¼šå†å²å†…å®¹ä¿¡æ¯ï¼ˆåä½œä¿¡æ¯ï¼‰+å…·ä½“é¡¹ç›®ä¿¡æ¯ï¼ˆå†…å®¹ä¿¡æ¯ï¼‰->ç”Ÿæˆ GIDï¼ˆè¿™æ˜¯é€šè¿‡**æ¨èä»»åŠ¡å®ç°**çš„ï¼‰ï¼Œå¹¶ä¸”é€šè¿‡**ç´¢å¼•ä»»åŠ¡**æ¥å¯¹é½åä½œä¿¡æ¯ä¸å†…å®¹ä¿¡æ¯ã€‘

#### ç”Ÿæˆæ ‡è¯†ç¬¦æ„é€ 

GID æŒ‡**ç”Ÿæˆå¼**æ ‡è¯†ç¬¦ï¼Œæ˜¯ä¸ºæ¯ä¸ªç‰©å“åˆ†é…çš„ä¸€ä¸²ç‹¬ç‰¹çš„ä»¤ç‰Œåºåˆ—ï¼Œç”¨äºåœ¨**ç”Ÿæˆå¼æ¨èæ¡†æ¶**ä¸­æ ‡è¯†ç‰©å“ã€‚

GIDçš„æ„å»ºåœ¨ç”Ÿæˆæ¨èä¸­æ˜¯é‡ä¸­ä¹‹é‡çš„ã€‚ä¸€èˆ¬æ¥è¯´ï¼ŒGIDåº”æ»¡è¶³ä»¥ä¸‹æœŸæœ›ï¼š

1. éœ€è¦åŒ…å«åä½œä¿¡å·å’Œå†…å®¹ä¿¡æ¯çš„çŸ¥è¯†
2. ç›¸ä¼¼çš„ item åº”è¯¥æ‹¥æœ‰ç›¸ä¼¼çš„ GID
3. æ¯ä¸€ä¸ª item éƒ½åº”è¯¥æœ‰å”¯ä¸€çš„ GIDï¼Œä¸”æ¯ä¸€ä¸ª GID åªå¯¹åº”ä¸€ä¸ªç‰¹å®šçš„ item



è€ƒè™‘åˆ©ç”¨**åˆ†å±‚èšç±»æ–¹æ³•**ä»åŸºäºå›¾çš„CFï¼ˆååŒè¿‡æ»¤ï¼‰æ¨¡å‹æ„å»ºGIDï¼ˆå¯¹è±¡æ˜¯ item çš„è¡¨å¾å‘é‡ï¼‰ã€‚ä»¥ä¸‹æ˜¯è¿‡ç¨‹

1. é¦–å…ˆä»é¢„è®­ç»ƒçš„LightGCNæ¨¡å‹ä¸­æå– item è¡¨ç¤ºã€‚ï¼ˆè¿™ä¸ªè¡¨å¾å‘é‡æ˜¯åŸºäºååŒä¿¡æ¯æå–çš„ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œè‹¥ itemA ä¸ itemB çš„é‡å ç”¨æˆ·å æ¯”å¾ˆå¤§ï¼Œé‚£ä¹ˆå®ƒä»¬çš„è¡¨å¾å‘é‡å°±ä¼šéå¸¸ç›¸ä¼¼ï¼‰ã€‚
2. ç„¶åï¼ŒåŸºäº item è¡¨ç¤ºï¼Œåˆ†å±‚è°ƒç”¨çº¦æŸK-meansç®—æ³•ã€‚ï¼ˆå°±æ˜¯å…ˆèšç±»å‡ ä¸ªå¤§ç±»ï¼Œç„¶åå†åœ¨å¤§ç±»ä¸­èšç±»æˆå°ç±»ï¼‰å¯¹äº$t \in [1, l - 1]$ çš„ç¬¬ $t$ çº§èšç±»ï¼Œæ¯ä¸ªèšç±»ä¸­çš„é¡¹ç›®æ•°é‡ä¸è¶…è¿‡ $K ^ {l-t}$ã€‚ï¼ˆå…¶å®å°±æ˜¯ä¸€é¢—å¤šå‰æ ‘ï¼‰
3. å»ºç«‹ä¸€ä¸ª K-ary æ ‘æ¥ç»„ç»‡ item é›†ã€‚æ¯ä¸ª item å¯¹åº”ä¸€ä¸ªå¶å­èŠ‚ç‚¹ï¼Œè€Œä»æ ¹åˆ°å¶å­èŠ‚ç‚¹çš„è·¯å¾„æ˜¯é¡¹ç›®çš„GIDã€‚ä¾‹å¦‚ï¼šGID = `[3, 1, 2]` å°±è¡¨ç¤ºè¯¥ item ä»æ ¹èŠ‚ç‚¹å‡ºå‘ï¼Œä¾æ¬¡èµ°åˆ°ç¬¬3ä¸ªå­ç°‡ï¼Œå†åˆ°ç¬¬1ä¸ªå­ç°‡ï¼Œå†åˆ°ç¬¬2ä¸ªå­ç°‡ã€‚

å…¶ä»–æ³¨æ„äº‹é¡¹ï¼š

1. å› ä¸º LightGCN æ˜¯åœ¨ user-item **äº¤äº’å›¾**ï¼ˆç”¨ GNN è®­ç»ƒï¼‰ä¸Šè®­ç»ƒå‡ºæ¥çš„ï¼Œå®ƒçš„è¡¨ç¤ºèƒ½æ•æ‰ååŒä¿¡å·ï¼Œå› æ­¤èšç±»å½¢æˆçš„ GID ä¹Ÿ**å¤©ç„¶ç¼–ç äº†ååŒè¿‡æ»¤çš„ä¿¡æ¯**ã€‚

2. æ­¤å¤–ï¼Œå¯¹äº GID ä¸­çš„æ¯ä¸ªä½ç½®ï¼ˆä¾‹å¦‚è·¯å¾„ä¸­çš„æ¯ä¸€çº§ç¼–å·ï¼‰ï¼Œè¯¥æ¡†æ¶è¿˜è®¾è®¡äº†ä¸€ä¸ª**ç¼–ç å‘é‡è¡¨ï¼ˆcodebook embeddingï¼‰**ï¼Œç”¨äºåœ¨ç´¢å¼•ä»»åŠ¡ä¸­å¼•å…¥é¡¹ç›®çš„å†…å®¹ä¿¡æ¯ã€‚

   å¯ä»¥è¿™æ ·ç†è§£ï¼šGID = `[3, 1, 2]` â†’ æˆ‘ä»¬åˆ†åˆ«ä¸ºä½ç½®1çš„`3`ã€ä½ç½®2çš„`1`ã€ä½ç½®3çš„`2`æŸ¥è¯¢å¯¹åº”çš„ embeddingï¼ˆè¿™éƒ¨åˆ†åŒ…å«å†…å®¹ä¿¡æ¯ï¼Œå¯ä»¥ç†è§£ä¸ºæŸä¸ª**èšç±»ç¼–å·**çš„â€è¯­ä¹‰è¡¨ç¤ºâ€œï¼‰ï¼Œç„¶åæ‹¼æ¥èµ·æ¥ä½œä¸º item çš„æœ€ç»ˆç¼–ç ã€‚ï¼ˆæ‰€ä»¥è¯´ï¼Œé¢„è®­ç»ƒå¾—åˆ°çš„ç¼–ç ä»…ä»…åªæ˜¯ç”¨æ¥èšç±»çš„å—ï¼Ÿï¼‰

3. ç»¼ä¸Šï¼Œ**GID + codebook embedding** ç»“åˆèµ·æ¥ï¼Œå°±å¸®åŠ©æ¨èæ¨¡å‹åŒæ—¶å»ºæ¨¡äº†ï¼š

   * ååŒä¿¡å·ï¼ˆé€šè¿‡ LightGCN è¡¨ç¤ºå’Œèšç±»ç»“æ„ï¼‰ï¼›
   * å†…å®¹ä¿¡æ¯ï¼ˆé€šè¿‡ codebook åµŒå…¥å‘é‡ï¼‰ã€‚



#### User-Item æ¨è

* æ¨¡å‹è¾“å…¥ï¼ˆ`json` æ ¼å¼ï¼‰

  é’ˆå¯¹ä¸€æ¡ä¿¡æ¯äº¤äº’ $User_u-item_i$ ï¼Œæˆ‘ä»¬å¯ä»¥è¿™æ ·è¡¨ç¤º $item_i$ ï¼Œé¦–å…ˆåŠ å…¥å…¶åŸå­ä»¤ç‰Œ $iad_i$ æ¥æé«˜æ¨¡å‹çš„ä¿çœŸåº¦ï¼ˆå³æ¨¡å‹å…·ä½“åŒºåˆ† item çš„èƒ½åŠ›ï¼‰ï¼Œå…¶æ¬¡ï¼Œå†ä»¥å­—å…¸å½¢å¼çš„é”®å€¼å¯¹æ¥è¡¨ç¤ºä¸€äº›**å†…å®¹ä¿¡æ¯**ï¼ˆè¿™é‡Œçš„å†…å®¹ä¿¡æ¯å¯èƒ½æ˜¯é€šè¿‡ä¸€äº› raw data æ¯”å¦‚ JSON å…ƒæ•°æ®è·å–çš„ï¼‰

  $$
  c_i = [iad_i,k_1:v_1,k_2:v_2, \cdots]
  $$
  ==ååŒè¿‡æ»¤çš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š**ç”¨æˆ·çš„åå¥½å¯ä»¥é€šè¿‡ä»–äº’åŠ¨è¿‡çš„é¡¹ç›®æ¥æ¨æ–­**ã€‚==

  å› æ­¤ï¼Œæ¯ä¸ªç”¨æˆ·çš„è¾“å…¥å°±æ˜¯ä»–**æ‰€æœ‰äº’åŠ¨é¡¹ç›®çš„å†…å®¹ä¿¡æ¯**ä¹‹**é›†åˆ**ï¼Œè¿™æ ·ä¹Ÿèƒ½ä¿ç•™ååŒä¿¡å·ã€‚

  ç”±äº ColaRec è®­ç»ƒé˜¶æ®µåŒ…å«å¤šä¸ªä»»åŠ¡ï¼Œä¸ºäº†å‘Šè¯‰æ¨¡å‹â€œå½“å‰æ˜¯æ¨èä»»åŠ¡â€ï¼Œæˆ‘ä»¬ä¼šåœ¨è¾“å…¥çš„æœ€å‰é¢åŠ ä¸€ä¸ªç‰¹æ®Šçš„ä»»åŠ¡ tokenï¼š`tasku`ã€‚

  å› æ­¤ï¼Œç”¨æˆ· $u$ åœ¨æ¨èä»»åŠ¡ä¸­çš„**å®Œæ•´è¾“å…¥**æ˜¯ï¼š

  $$
  X_u = [ \text{task}_u,\{c_i |i \in I^{+}_u\}]
  $$
  $I^{+}_u$ è¡¨ç¤ºç”¨æˆ· $u$ æ‰€äº¤äº’è¿‡çš„ç‰©å“é›†åˆã€‚

* Item ç”Ÿæˆ

  æœ¬è´¨ä¸Šæ˜¯ä¸€ç§**åŸºäºEncoder-Decoder Transformerç»“æ„çš„åºåˆ—ç”Ÿæˆæ–¹å¼**ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯ï¼š**æ ¹æ®ç”¨æˆ·å†å²è¡Œä¸ºï¼Œé€æ­¥ç”Ÿæˆç›®æ ‡ç‰©å“çš„â€œGIDè·¯å¾„â€**ï¼ˆä¹Ÿå°±æ˜¯ä¹‹å‰æ„é€ çš„é‚£ä¸ªåˆ†å±‚è·¯å¾„å¼**ç¼–å·**ï¼‰ã€‚

  è¾“å…¥æ˜¯ä¹‹å‰æ„é€ çš„ `Xu = [task_token, c1, c2, ..., cn]`ï¼Œå³**ç”¨æˆ· u çš„å†å²äº¤äº’å†…å®¹ä¿¡æ¯ã€‚**
  
  Encoder ä¼šæå–è¿™ä¸ªè¾“å…¥åºåˆ—çš„è¯­ä¹‰è¡¨ç¤ºï¼Œè¾“å‡ºä¸€ä¸ªéšè—çŠ¶æ€å‘é‡ï¼Œè®°ä½œ `Encoder(Xu)`ã€‚
  
  $z^{<t}$ æ˜¯**ä¹‹å‰ç”Ÿæˆè¿‡**çš„ tokenï¼ˆæ¯”å¦‚å‰å‡ ä¸ª GID ç¼–å·ï¼‰
  $$
  \mathbf{d}_t = \text{Decoder}(\text{Encoder}(X_u),z ^ {<t})
  $$

  
  åœ¨æ¯ä¸€æ­¥ tï¼Œæˆ‘ä»¬å°†å½“å‰ decoder ç”Ÿæˆçš„å‘é‡ $\mathbf{d}_t$ï¼Œä¸ä¸€ä¸ª**â€œç¬¬ t ä½çš„ codebook embedding çŸ©é˜µâ€** $E_t$ åš ç‚¹ç§¯ï¼Œç„¶åé€šè¿‡ softmax å¾—åˆ°ç¬¬ t ä¸ª GID ç¼–å·çš„æ¦‚ç‡åˆ†å¸ƒã€‚
  $$
  p(z_t \mid z_{<t}, X_u) = \text{softmax}(d_t \cdot E_t^\top)
  $$
  é‡‡ç”¨äº¤å‰ç†µæŸå¤±è¿›è¡Œæ¨¡å‹ä¼˜åŒ–ã€‚==æ¨¡å‹è®­ç»ƒç›®æ ‡æ˜¯è®©å®ƒç”Ÿæˆçš„ GID è·¯å¾„å°½å¯èƒ½æ¥è¿‘çœŸå®ç›®æ ‡é¡¹ç›®çš„ GID è·¯å¾„==ã€‚æ‰€ä»¥ï¼Œæˆ‘ä»¬ç”¨**å¤šæ­¥äº¤å‰ç†µæŸå¤±**ï¼Œä¸€æ­¥ä¸€æ­¥åœ°è®¡ç®—çœŸå® token çš„ log æ¦‚ç‡ï¼›ç„¶ååŠ èµ·æ¥ï¼Œå½¢æˆ**å®Œæ•´çš„ç”Ÿæˆå¼æ¨èæŸå¤±**ã€‚å³æœ€å¤§åŒ–æ•´ä¸ª GID åºåˆ—çš„ç”Ÿæˆæ¦‚ç‡ã€‚
  $$
  \mathcal{L}_{\text{rec}} = - \sum_{t=1}^{l} \log p(z_t^i \mid X_u, z_1^i, z_2^i, \dots, z_{t-1}^i).
  $$
  å°æ€»ç»“ä¸€ä¸‹ï¼Œå…¶å®å°±æ˜¯ Encoder æ ¹æ®è¾“å…¥ç¼–ç éšå‘é‡ï¼ŒDecoder æ ¹æ®éšå‘é‡ä¸å†å²ä¿¡æ¯ï¼ˆGIDï¼‰ç¼–ç å‘é‡ $\mathbf{d}$ï¼Œ æ ¹æ®å‘é‡ $\mathbf{d}$ ä¸ code book embedding çŸ©é˜µçš„ç›¸å…³è®¡ç®—æƒ…å†µå¾—åˆ°å¯¹åº” GID çš„æ¦‚ç‡åˆ†å¸ƒã€‚
  
  **å…¶ä»»åŠ¡ç›®æ ‡æ˜¯ï¼šç»™å®šä¸€ä¸ªç”¨æˆ· $u$ çš„å†å²è¡Œä¸ºï¼ˆè¡¨ç¤ºä¸º $X_u$ï¼‰ï¼Œé¢„æµ‹è¿™ä¸ªç”¨æˆ·å¯èƒ½ä¼šç‚¹å‡»/äº¤äº’çš„ itemã€‚åœ¨è¿™é‡Œæ˜¯ç”Ÿæˆè¯¥ç”¨æˆ·æœ€å¯èƒ½ä¼šäº¤äº’çš„ item çš„ GID åºåˆ—ã€‚**æˆ‘ä»¬ä¸¾ä¸ªä¾‹å­æ¥è¯´æ˜è¿™ä¸ªæŸå¤±å‡½æ•°çš„è®­ç»ƒå«ä¹‰
  
  > çœ‹åˆ°è¿™ä¸ªç”¨æˆ·çš„ `X_u` åï¼Œæ›´å€¾å‘äºå…ˆç”Ÿæˆ token `"1"`ï¼Œå†æ˜¯ `"5"`ï¼Œæœ€åæ˜¯ `"9"`ï¼›
  >
  > ä»è€Œä¸‹æ¬¡çœ‹åˆ°ç±»ä¼¼ç”¨æˆ·è¡Œä¸ºæ—¶ï¼ˆç±»ä¼¼ç”¨æˆ·è¡Œä¸ºä»£è¡¨ç€ç±»ä¼¼çš„è¾“å…¥ï¼‰ï¼Œèƒ½å¤Ÿæ›´å®¹æ˜“æ¨èï¼ˆæ¦‚ç‡å˜é«˜ï¼‰å‡ºè¿™ä¸ªå•†å“ Dï¼ˆå¯¹åº” GID = 159ï¼‰ã€‚
  >
  > å¤§æ¦‚æ‡‚äº†

#### Item-Item ç´¢å¼•

ä¸ºäº†**å¯¹é½**åä½œä¿¡å·å’Œé¡¹ç›®å†…å®¹ä¿¡æ¯ï¼Œæˆ‘ä»¬å¼•å…¥äº†ä¸€ä¸ª**é¡¹ç›®ç´¢å¼•ä»»åŠ¡**ï¼Œè¯¥ä»»åŠ¡å°†åŸºäºå†…å®¹çš„è¯­ä¹‰ç©ºé—´æ˜ å°„åˆ°åŸºäºäº¤äº’çš„åä½œç©ºé—´ã€‚

* æ¨¡å‹è¾“å…¥ï¼Œå…¶ä¸­è¿™é‡Œçš„ $u$ æ˜¯å’Œ $item_i$ æœ‰è¿‡äº¤äº’çš„ç”¨æˆ·é›†åˆ
  $$
  X_i = \left[ \text{task}_i, c_i, \{uad_u \mid u \in U_i^+\} \right]
  $$
  $\{uad_u \mid u \in U_i^+\}$ è¡¨ç¤ºä¸ç‰©å“ $i$ æœ‰è¿‡äº¤äº’çš„ç”¨æˆ·é›†åˆå¯¹åº”çš„ç”¨æˆ·åŸå­æ ‡è¯†ç¬¦ï¼ˆuadï¼‰
  
* Item ç´¢å¼•ç”Ÿæˆ

  ä¸ä¸Šæ–‡åŸºæœ¬åŒç†
  $$
  \mathcal{L}_{\text{index}} = -\sum_{t=1}^{l} \log p(z_t^i \mid X_i, z_1^i, \dots, z_{t-1}^i)
  $$
  è¿™ä¹ˆæ“ä½œçš„æœ¬è´¨æ˜¯ï¼š**è®©æ¨¡å‹å­¦ä¼šæ ¹æ® item çš„å†…å®¹ + å®ƒçš„ååŒä¸Šä¸‹æ–‡ï¼ˆäº¤äº’ç”¨æˆ·ï¼‰æ¥ç”Ÿæˆå®ƒçš„ç»“æ„åŒ– IDï¼Œè¿™ä¸ª GID ç»“æ„æ—¢å¸¦ååŒè¯­ä¹‰ï¼Œä¹Ÿå¸¦å†…å®¹è¯­ä¹‰ã€‚**

  ç”Ÿæˆçš„ç›®æ ‡æ˜¯ï¼šå½“å‰ Item è‡ªå·±çš„ GID

* **è¯¥é˜¶æ®µçš„ä»»åŠ¡ç›®æ ‡æ˜¯ï¼šç»™å®šä¸€ä¸ª item çš„å†…å®¹ä¿¡æ¯ + å®ƒçš„äº¤äº’ç”¨æˆ·é›†åˆï¼Œé¢„æµ‹å®ƒçš„ GIDï¼ˆå³å…¶è¯­ä¹‰ token åºåˆ—ï¼‰ã€‚**

* Userâ€“Item ä»»åŠ¡è®© GID æ›´å¥½åœ°å»ºæ¨¡åå¥½ï¼›Itemâ€“Item ç´¢å¼•è®© GID æ›´å¥½åœ°å¯¹é½å†…å®¹ï¼›ä¸¤è€…ç›¸è¾…ç›¸æˆï¼Œæ„å»ºå‡ºå¯è§£é‡Šã€å¯æ§åˆ¶ã€ç»“æ„è‰¯å¥½çš„ item token ç©ºé—´ã€‚

  >User-Item ä»»åŠ¡è®© GID ä¸ç”¨æˆ·åå¥½å…³è”ï¼ˆå¦‚ â€œ23 25 10â€ å¯¹åº”è¿åŠ¨åå¥½ï¼‰ï¼ŒItem-Item ä»»åŠ¡è®© GID ä¸ç‰©å“å†…å®¹å…³è”ï¼ˆå¦‚ â€œ23 25â€ å¯¹åº”è¿åŠ¨è£…å¤‡ï¼‰ï¼Œç»“åˆä¸¤è€…å¯æ¸…æ™°è§£é‡Š â€œä¸ºä½•æ¨èè¯¥ç‰©å“â€ï¼ˆå› ç”¨æˆ·å–œæ¬¢è¿åŠ¨ä¸”ç‰©å“æ˜¯è¿åŠ¨è£…å¤‡ï¼‰ã€‚



#### å¤šä»»åŠ¡å­¦ä¹ 

é™¤äº†ä¸Šè¿°ä¸¤é¡¹ä»»åŠ¡å¤–ï¼Œæˆ‘ä»¬è¿˜å¼•å…¥äº†**æ’åæŸå¤±**æ¥æé«˜ColaRecçš„æ’åèƒ½åŠ›ï¼Œå¹¶å¼•å…¥äº†**å¯¹æ¯”æŸå¤±**æ¥è¿›è¡Œæ›´å¥½çš„å¯¹é½ã€‚

* Item æ’å

  ç›®æ ‡æ˜¯ï¼š**è®©æ­£æ ·æœ¬ï¼ˆç”¨æˆ·å–œæ¬¢çš„ç‰©å“ï¼‰æ¯”è´Ÿæ ·æœ¬å¾—åˆ†é«˜**ã€‚

  å¯¹åº”æ–‡ä¸­çš„å…¬å¼ï¼ˆ9ï¼‰ï¼ŒBPRçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šç”¨æˆ·å–œæ¬¢çš„ item åº”è¯¥æ¯”æœªç‚¹å‡»çš„ item æ›´**åŒ¹é…**ä»–çš„å…´è¶£ï¼Œé¢„æµ‹åˆ†æ›´é«˜ã€‚ä½“ç°åœ¨å…¬å¼ä¸Šå°±æ˜¯ $h(X_u) \cdot h(X_i) > h(X_u) \cdot h(X_i)$ å³ï¼Œ**ç”¨æˆ·ä¸æ­£æ ·æœ¬çš„åŒ¹é…å¾—åˆ† > ç”¨æˆ·ä¸è´Ÿæ ·æœ¬çš„åŒ¹é…å¾—åˆ†**ã€‚

  å…¶ä¸­ $h$ æ˜¯éšçŠ¶æ€å‘é‡

* å¯¹æ¯”å­¦ä¹ 

  è®¾è®¡è¿™ä¸ªæŸå¤±æ˜¯ä¸ºäº†è®©**GID ç»“æ„ç›¸ä¼¼çš„ itemï¼Œä¹Ÿåœ¨è¯­ä¹‰ç©ºé—´ä¸Šé è¿‘**ã€‚

  è¿™æ˜¯ä¸ºäº†å¢å¼º GID ç¼–ç ç»“æ„å’Œ item å†…å®¹ä¹‹é—´çš„ä¸€è‡´æ€§ï¼ˆå¯¹é½ collaborative signal å’Œ contentï¼‰ã€‚
  $$
  \mathcal{L_c}=-\ln \sigma(\mathbf{h}(X_i) \cdot(\mathbf{h}(X_{i+})-\mathbf{h}(X_{i-})))
  $$
  å¯¹åº”è®ºæ–‡ä¸­çš„å…¬å¼ï¼ˆ10ï¼‰ï¼Œæ³¨æ„ä¸å…¬å¼ï¼ˆ9ï¼‰åŒºåˆ†å¼€æ¥ã€‚è¿™é‡Œçš„æƒ³æ³•æ˜¯ï¼Œå…·æœ‰ç›¸ä¼¼GIDçš„ item åœ¨åŸºäºå†…å®¹çš„è¯­ä¹‰ç©ºé—´ä¸­ä¹Ÿåº”è¯¥æ˜¯ç›¸ä¼¼çš„ã€‚å‰è€…é’ˆå¯¹ User åè€…é’ˆå¯¹ Item

* è”åˆä¼˜åŒ–

  **å°†è¿™äº›æŸå¤±å‡½æ•°å…¨éƒ¨åŠ èµ·æ¥ï¼Œè¦æ·±åˆ»ç†è§£æ¯ä¸€æ­¥çš„å®é™…å«ä¹‰ï¼ï¼ï¼**

* å…¶ä»–æ³¨æ„äº‹é¡¹ï¼ˆtrickï¼‰ï¼šåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†é¿å…æ¨èè€…ç”Ÿæˆæ— æ•ˆçš„GIDï¼Œæˆ‘ä»¬é‡‡ç”¨çº¦æŸæ³¢æŸæœç´¢[6]æ¥é™åˆ¶åŸºäºå‰ç¼€ä»¤ç‰Œçš„å½“å‰ä»¤ç‰Œçš„ç”ŸæˆèŒƒå›´ã€‚

#### å…¶ä»–è¡¥å……

* User-Item ä¸ Item-Item çš„åŒºåˆ«

  > æ¨èä»»åŠ¡ï¼ˆå…¬å¼ 6ï¼‰ï¼šä»ç”¨æˆ·å†å²è¡Œä¸º â†’ ç”Ÿæˆä¸‹ä¸€ä¸ªå•†å“ GIDã€‚
  >
  > ç´¢å¼•ä»»åŠ¡ï¼ˆå…¬å¼ 8ï¼‰ï¼šä»ä¸€ä¸ªå•†å“çš„å†…å®¹ + ä¸å®ƒäº¤äº’çš„ç”¨æˆ· â†’ å†ç°è¿™ä¸ªå•†å“çš„ GIDã€‚
  >
  > ä¹Ÿå°±æ˜¯è¯´ï¼Œ**ç´¢å¼•ä»»åŠ¡æ˜¯ä»â€œå•†å“è§†è§’â€è¿›è¡Œå»ºæ¨¡çš„ï¼Œè€Œæ¨èæ˜¯ä»â€œç”¨æˆ·è§†è§’â€å»ºæ¨¡çš„ã€‚**
  >
  > **ç›¸å½“äºå…ˆè·å¾—å†çº æ­£**

### å®éªŒ

è¿›è¡Œå®éªŒæ¥å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š

1. ä¸ç°æœ‰çš„æ¨èæ–¹æ³•ç›¸æ¯”ï¼Œæ‹Ÿè®®çš„ColaRecçš„è¡¨ç°å¦‚ä½•ï¼Ÿ
2. å¤šä»»åŠ¡çš„è”åˆè®­ç»ƒå¦‚ä½•å½±å“ColaRecçš„è¡¨ç°ï¼Ÿ
3. GIDçš„è®¾è®¡å¦‚ä½•å½±å“æ¨èæ€§èƒ½ï¼Ÿ

> æˆ‘ä»¬ä½¿ç”¨å››ä¸ªçœŸå®çš„å…¬å…±æ•°æ®é›†æ¥è¯„ä¼° ColaRec çš„æ€§èƒ½ã€‚å…·ä½“è€Œè¨€ï¼Œå®éªŒåœ¨æ¥è‡ª Amazon å•†å“è¯„è®ºçš„ä¸‰ä¸ªå­ç±»åˆ«ï¼ˆâ€œç¾å®¹â€ã€â€œè¿åŠ¨ä¸æˆ·å¤–â€ä»¥åŠâ€œæ‰‹æœºä¸é…ä»¶â€ï¼‰å’Œæ¥è‡ª Food.com çš„â€œé£Ÿè°±â€æ•°æ®é›†ä¸Šè¿›è¡Œã€‚å¯¹äºç”¨æˆ·å’Œç‰©å“ï¼Œè‹¥å…¶äº¤äº’æ¬¡æ•°å°‘äºäº”æ¬¡ï¼Œåˆ™ä¼šè¢«è¿‡æ»¤æ‰ã€‚è¡¨ 1 å±•ç¤ºäº†è¿™å››ä¸ªæ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯ã€‚è‡³äºå†…å®¹ä¿¡æ¯ï¼Œæˆ‘ä»¬ä½¿ç”¨ Amazon å•†å“å…ƒæ•°æ®ä¸­çš„â€œæ ‡é¢˜â€ã€â€œå“ç‰Œâ€å’Œâ€œç±»åˆ«â€ä½œä¸ºç‰©å“çš„æ–‡æœ¬å†…å®¹ä¿¡æ¯ï¼›å¯¹äºé£Ÿè°±æ•°æ®é›†ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œåç§°â€ã€â€œæè¿°â€å’Œâ€œæ ‡ç­¾â€æ¥æè¿°ç‰©å“å†…å®¹ã€‚

#### è¯„ä¼°åè®®

* äº¤å‰éªŒè¯

* **é€šç”¨æ¨èè€Œéé¡ºåºæ¨è**ï¼ˆ==ä¹Ÿå°±æ˜¯è¯´è¿™ä¸ªæ¡†æ¶æ¨¡å‹å¹¶ä¸ç›´æ¥æ”¯æŒæ—¶åºä»»åŠ¡ï¼Œä½†æ˜¯è…¾è®¯å¹¿å‘Šå¤§èµ›æ˜¯ä¸€ä¸ªæ—¶åºä»»åŠ¡==ï¼‰

  éœ€è¦å¼•å…¥æ—¶åºä¿¡æ¯ï¼Œè¿™ä¸ªæˆ‘ä»¬å¯ä»¥åœ¨ OTTO ä¸­å­¦ä¹ åˆ°

* é‡‡ç”¨ä¸¤ç§æŒ‡æ ‡
  1. `recall@n`
  2. `NDCG@n`



#### æ€§èƒ½æ¯”è¾ƒ

* å¯¹æ•´ä¸ªç”¨æˆ·çš„æ¯”è¾ƒ

  ColaRecåœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šä¸è¿™äº›CFæ–¹æ³•ç›¸æ¯”éƒ½å–å¾—äº†å…·æœ‰ç«äº‰åŠ›çš„ç»“æœï¼Œè¯æ˜äº†ä¸ºååŒç”Ÿæˆæ¨èç³»ç»Ÿ**æ³¨å…¥å†…å®¹ä¿¡æ¯**çš„æ½œåŠ›ã€‚

* å¯¹é•¿å°¾ç”¨æˆ·çš„æ¯”è¾ƒ

  åœ¨ä¸ºé•¿å°¾ç”¨æˆ·ç”Ÿæˆæ¨èæ—¶ï¼ŒColaRecçš„è¡¨ç°æ˜æ˜¾ä¼˜äºæ‰€æœ‰åŸºçº¿ã€‚åŸå› æ˜¯ColaRecå¯¹ç”¨æˆ·-é¡¹ç›®äº¤äº’å’Œé¡¹ç›®å†…å®¹ä¿¡æ¯éƒ½è¿›è¡Œäº†å»ºæ¨¡ã€‚é‰´äºé•¿å°¾ç”¨æˆ·çš„**äº¤äº’ä¿¡æ¯è¾ƒå°‘**ï¼ŒColaRecåœ¨**å†…å®¹ä¿¡æ¯çš„å¸®åŠ©ä¸‹è·å¾—äº†æ›´å¥½çš„æ€§èƒ½**ã€‚æ€»ä¹‹ï¼Œä¸ç°æœ‰åŸºçº¿ç›¸æ¯”ï¼Œæ‰€æå‡ºçš„ColaRecå¯ä»¥æœ‰æ•ˆåœ°äº§ç”Ÿæ›´å¥½çš„æ€§èƒ½ã€‚è¿™ç§æ”¹è¿›å¯¹é•¿å°¾ç”¨æˆ·æ¥è¯´æ›´ä¸ºæ˜¾è‘—ã€‚



### æŸ¥æ¼è¡¥ç¼º

#### bpr æŸå¤±

BPRï¼ˆBayesian Personalized Rankingï¼‰æŸå¤±æ˜¯ä¸€ç§ä¸“ä¸ºæ¨èç³»ç»Ÿè®¾è®¡çš„æ’åºä¼˜åŒ–ç›®æ ‡å‡½æ•°ï¼Œä¸»è¦ç”¨äºä¼˜åŒ– **éšå¼åé¦ˆåœºæ™¯ä¸‹çš„ä¸ªæ€§åŒ–æ’åºæ¨è**ã€‚

**BPR æŸå¤±çš„ç›®æ ‡æ˜¯è®©ç”¨æˆ·æ›´å–œæ¬¢ï¼ˆæ›´é«˜è¯„åˆ†/æ›´å¸¸ç‚¹å‡»ï¼‰çš„ç‰©å“æ’åœ¨ä¸å–œæ¬¢çš„ç‰©å“å‰é¢ã€‚**

* éšå¼åé¦ˆæ˜¯æ¨èç³»ç»Ÿä¸­ä¸€ç§éå¸¸å¸¸è§çš„ç”¨æˆ·è¡Œä¸ºæ•°æ®ç±»å‹ï¼Œå®ƒ**ä¸ç›´æ¥è¡¨è¾¾ç”¨æˆ·æ˜¯å¦å–œæ¬¢æŸä¸ªé¡¹ç›®**ï¼Œè€Œæ˜¯é€šè¿‡ç”¨æˆ·çš„**è¡Œä¸ºç—•è¿¹**é—´æ¥æ¨æµ‹ç”¨æˆ·åå¥½ã€‚

  å¸¸è§çš„éšå¼åé¦ˆä¸¾ä¾‹ï¼š

  | è¡Œä¸º         | ç³»ç»Ÿå¦‚ä½•ç†è§£             |
  | ------------ | ------------------------ |
  | ç‚¹å‡»ä¸€ä¸ªå•†å“ | å¯èƒ½æ„Ÿå…´è¶£               |
  | æµè§ˆé¡µé¢     | æœ‰ä¸€å®šæ³¨æ„åŠ›             |
  | æ”¶è—ã€åŠ è´­   | åå¥½è¾ƒå¼º                 |
  | æ’­æ”¾è§†é¢‘     | æœ‰æ„æ„¿æ¶ˆè´¹               |
  | åœç•™æ—¶é•¿é•¿   | å¯èƒ½è®¤çœŸé˜…è¯»             |
  | é‡å¤è®¿é—®     | æ½œåœ¨é«˜å…´è¶£               |
  | è´­ä¹°         | æœ€å¼ºéšå¼åé¦ˆï¼Œå¼ºå…´è¶£ä¿¡å· |

  æ˜¾å¼åé¦ˆ vs éšå¼åé¦ˆ

  | ç‰¹ç‚¹             | æ˜¾å¼åé¦ˆï¼ˆExplicit Feedbackï¼‰    | éšå¼åé¦ˆï¼ˆImplicit Feedbackï¼‰ |
  | ---------------- | -------------------------------- | ----------------------------- |
  | ç”¨æˆ·æ˜¯å¦ä¸»åŠ¨è¡¨æ€ | âœ… æ˜¯ï¼ˆæ‰“åˆ†ã€ç‚¹èµç­‰ï¼‰             | âŒ å¦                          |
  | ä¿¡æ¯å‡†ç¡®åº¦       | é«˜ï¼Œä½†ç¨€ç–                       | ä½ï¼Œä½†ä¸°å¯Œ                    |
  | å¯è·å–æ€§         | è¾ƒéš¾ï¼Œå¤§å¤šåœ¨ç¤¾äº¤å¹³å°æˆ–è¯„æµ‹ç±»ç½‘ç«™ | å¾ˆå®¹æ˜“æ”¶é›†ï¼Œå¦‚ç”µå•†ã€App é‡Œ    |
  | ç¤ºä¾‹             | è¯„åˆ† 4 æ˜Ÿã€ç‚¹èµã€å·®è¯„            | ç‚¹å‡»ã€è´­ä¹°ã€æµè§ˆã€åŠ è´­ã€æ’­æ”¾  |

* èƒŒåçš„æ ¸å¿ƒæ€æƒ³ï¼šåœ¨éšå¼åé¦ˆä¸­ï¼Œåœ¨éšå¼åé¦ˆä¸­ï¼Œæˆ‘ä»¬åªæœ‰ç”¨æˆ·çš„æ­£å‘è¡Œä¸ºï¼ˆå¦‚ç‚¹å‡»ã€è´­ä¹°ï¼‰ï¼Œä½†æ²¡æœ‰æ˜ç¡®çš„è´Ÿåé¦ˆï¼ˆä¸å–œæ¬¢ï¼‰ã€‚
   BPR é€šè¿‡**â€œç”¨æˆ·å–œæ¬¢çš„ > æ²¡ç‚¹è¿‡çš„â€**è¿™ä¸ªå‡è®¾ï¼Œè®¾è®¡äº†ä»¥ä¸‹è®­ç»ƒç›®æ ‡ï¼š

  å¯¹äºæ¯ä¸ªä¸‰å…ƒç»„ï¼š$(u,i,j)$

  å…¶ä¸­ï¼š

  $u$ï¼šç”¨æˆ·

  $i$ï¼šç”¨æˆ· $u$ å–œæ¬¢/äº¤äº’è¿‡çš„ itemï¼ˆæ­£æ ·æœ¬ï¼‰

  $j$ï¼šç”¨æˆ·æ²¡æœ‰äº¤äº’è¿‡çš„ itemï¼ˆè´Ÿæ ·æœ¬ï¼‰

  BPR æ˜¯**ä¸“ä¸ºæ’åºä»»åŠ¡è®¾è®¡**çš„ lossï¼Œéå¸¸é€‚åˆæ¨èç³»ç»Ÿã€‚

* BPRæŸå¤±å…¬å¼

  BPR (Bayesian Personalized Ranking) çš„æŸå¤±å‡½æ•°å¯ä»¥è¡¨ç¤ºä¸ºï¼š

  $$
  \mathcal{L}_{\text{BPR}} = -\ln \sigma(\hat{y}_{ui} - \hat{y}_{uj})
  $$

  å…¶ä¸­ï¼š  
  - $\hat{y}_{ui}$ï¼šç”¨æˆ· $u$ å¯¹ item $i$ çš„é¢„æµ‹åå¥½å¾—åˆ†  
  - $\hat{y}_{uj}$ï¼šç”¨æˆ· $u$ å¯¹ item $j$ çš„é¢„æµ‹åå¥½å¾—åˆ†  
  - $\sigma(\cdot)$ï¼šsigmoid å‡½æ•°  

  æŸå¤±çš„å«ä¹‰ï¼š  

  - å¦‚æœæ¨¡å‹é¢„æµ‹ $\hat{y}_{ui} > \hat{y}_{uj}$ï¼ˆå³æ­£æ ·æœ¬çš„åˆ†æ•°æ›´é«˜ï¼‰ï¼Œåˆ™ $\sigma(\hat{y}_{ui} - \hat{y}_{uj})$ è¶‹è¿‘äº 1ï¼ŒæŸå¤± $-\ln \sigma(\cdot)$ è¶‹è¿‘äº 0ã€‚  
  - å¦‚æœé¢„æµ‹ç›¸åï¼ˆ$\hat{y}_{ui} < \hat{y}_{uj}$ï¼Œå³è´Ÿæ ·æœ¬æ’å‰é¢ï¼‰ï¼Œ$\sigma(\hat{y}_{ui} - \hat{y}_{uj})$ è¶‹è¿‘äº 0ï¼ŒæŸå¤± $-\ln \sigma(\cdot)$ ä¼šå˜å¤§ï¼Œæ¨¡å‹å› æ­¤å—åˆ°æƒ©ç½šã€‚

  

### å®éªŒå¤ç°

#### è¡¥å……è¯´æ˜

* ç›¸è¾ƒäºæ—©æœŸçš„å…¶ä»–æ¨¡å‹ï¼Œå¯¹äºæ¨¡å‹çš„å‚æ•°æ˜¯ç›´æ¥åœ¨æ¨¡å‹çš„ `__init__()` ä¸­æŒ‡å®šçš„ï¼Œè€Œä¸æ˜¯é€šè¿‡ `config`ï¼›è€Œåœ¨ `hugging-face` ç³»åˆ—ä¸­ï¼Œæ¨¡å‹ï¼ˆæ¯”å¦‚ T5ï¼‰çš„ç›¸å…³å‚æ•°ï¼ˆ`d_model`, `num_layers`, `d_ff`ï¼‰ç­‰ï¼Œéƒ½é›†ä¸­åœ¨ `T5Config` ä¸­ã€‚

  å½“ç„¶æˆ‘ä»¬ä½¿ç”¨è¿™ç§åšæ³•

  ```python
  model_2 = T5ForConditionalGeneration(config)
  ```

  **ä¸€èˆ¬é¢„ç¤ºç€æˆ‘ä»¬è‡ªå·±è¦è‡ªå·±è®­ç»ƒä¸€ä¸ªæ¨¡å‹**ï¼ˆå› ä¸ºè¿™æ ·çš„å®ä¾‹å®šä¹‰åªä½¿ç”¨äº† configï¼ŒæœªåŠ è½½é¢„è®­ç»ƒå‚æ•°ï¼‰ã€‚

  è€Œè¿™ç§åšæ³•

  ```python
  model = AutoModel.from_pretrained(model_ckpt, cache_dir = cache_dir)
  ```

  æˆ‘ä»¬ä¼šä» checkpoint ä¸­**åŠ è½½é¢„è®­ç»ƒæ¨¡å‹çš„æƒé‡**ï¼Œè€Œæ¨¡å‹å…·ä½“çš„ config ä¿¡æ¯åˆ™å›å» cache_dir çš„ç›®å½•ä¸‹è¯»å–ã€‚ç°æ ¹æ® cache_dir ä¸­çš„ç›¸å…³ä¿¡æ¯å®ä¾‹åŒ–ä¸€ä¸ª modelï¼Œç„¶åæ ¹æ® model_ckpt åˆå§‹åŒ–è¿™ä¸ª model çš„æƒé‡ã€‚

  

#### å…³äºé…ç½®æ–‡ä»¶å’Œå…¶ä»–æ–‡ä»¶

nndï¼ŒçœŸçš„éš¾å•Šï¼Œæ–°æ‰‹å®Œå…¨çœ‹ä¸æ‡‚

* `embeddings_single.pth` æ˜¯ä»€ä¹ˆä¸œè¥¿ï¼Ÿ

  `embeddings_single.pth` æ–‡ä»¶ä¸­**ä¿å­˜äº†GIDèšç±»æ‰€ä½¿ç”¨çš„ ==item== çš„åµŒå…¥è¡¨ç¤º**ï¼Œå¦‚è®ºæ–‡æ‰€è¯´æ˜¯**é€šè¿‡é¢„è®­ç»ƒçš„CFæ¨¡å‹**è·å¾—ã€‚ä¹Ÿå°±æ˜¯è¯´å®ƒåº”è¯¥æ˜¯ä½œä¸ºä»£ç ä¸­çš„é¢„è®­ç»ƒçš„ç»“æœï¼Ÿåº”è¯¥æ˜¯çš„ï¼Œæ˜¯ç”¨ `light-gcn` è¿›è¡Œè®­ç»ƒè·å¾—çš„

* `config_class.py`

  è¿™æ®µä»£ç å®šä¹‰äº†ä¸¤ä¸ªç”¨äºé…ç½®çš„æ•°æ®ç±»ï¼Œ**`DataFileConfig`** å’Œ **`DataProcessConfig`**ï¼Œå¹¶åœ¨è„šæœ¬ç»“å°¾åšäº†ç®€å•çš„æµ‹è¯•æ¼”ç¤ºã€‚å®ƒä»¬çš„ä½œç”¨å’ŒåŠŸèƒ½å¦‚ä¸‹ï¼š

  > 1. **`DataFileConfig` ç±» â€” æ•°æ®æ–‡ä»¶è·¯å¾„é…ç½®**
  >
  > - ç”¨äºç®¡ç†å’Œç”Ÿæˆé¡¹ç›®ä¸­æ•°æ®æ–‡ä»¶çš„è·¯å¾„å’Œç›¸å…³é…ç½®ã€‚
  > - æ ¹æ®ä¼ å…¥çš„å‚æ•°ï¼ˆæ¯”å¦‚æ•°æ®é›†åã€æ˜¯å¦æ— å†…å®¹ã€æ˜¯å¦ä½¿ç”¨æ–°å¢è¯ã€`diff_gid` æ ‡è®°ï¼‰åŠ¨æ€è®¾ç½®ï¼š
  >   - æ•°æ®é›†æ ¹è·¯å¾„
  >   - é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
  >   - è¯­æ–™æ–‡ä»¶åï¼ˆ`corpus_512.json` æˆ–å…¶ä»–å˜ä½“ï¼‰
  >   - æ–°å¢è¯å…¸è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
  >
  > ä½œç”¨æ˜¯æ–¹ä¾¿åç»­ç¨‹åºç»Ÿä¸€è°ƒç”¨æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„ã€‚
  >
  > 2. **`DataProcessConfig` æ•°æ®ç±» â€” æ•°æ®å¤„ç†ç›¸å…³å‚æ•°é…ç½®**
  >
  > - è¿™æ˜¯ç”¨ `@dataclass` å®šä¹‰çš„ä¸€ä¸ªè½»é‡ç±»ï¼Œä¸»è¦**å­˜å‚¨æ¨¡å‹è®­ç»ƒ/é¢„å¤„ç†è¿‡ç¨‹ä¸­çš„å„ç§è¶…å‚æ•°å’Œé…ç½®**ï¼ˆ**ç›´æ¥å’Œæ¨èç³»ç»Ÿçš„ä»»åŠ¡ç›¸å…³äº†**ï¼‰ã€‚
  > - åŒ…å«äº†ï¼š
  >   - ç‰¹æ®Šå¡«å……ç¬¦å·å­—ç¬¦ä¸²ï¼ˆå¦‚ `<extra_id_0>`ï¼‰
  >   - ç”¨æˆ·/ç‰©å“æ€»æ•°ï¼ŒåŠ¨æ€æ›´æ–°
  >   - åºåˆ—ç±»å‹ï¼ˆ`seq_type`ï¼‰ï¼Œé»˜è®¤ `'long'`
  >   - æœ€å¤§åºåˆ—é•¿åº¦ã€æœ€å¤§ token æ•°ã€é‡‡æ ·æ•°ç­‰é•¿åº¦å’Œé‡‡æ ·ç›¸å…³è¶…å‚æ•°
  >   - è´Ÿæ ·æœ¬é‡‡æ ·æ¯”ä¾‹
  >   - ä»¥åŠç›¸ä¼¼ç‰©å“æ–‡ä»¶åç­‰
  >
  > **é‡ç‚¹ï¼š`updata_for_type()` æ–¹æ³•**
  >
  > - è¿™æ˜¯ä¸€ä¸ªæ ¹æ® `seq_type` æ¥è°ƒæ•´é•¿åº¦ç›¸å…³å‚æ•°çš„æ–¹æ³•ã€‚
  > - æ¯”å¦‚å¦‚æœ `seq_type` æ˜¯ `'mlshort'`ï¼Œå°±æŠŠ `max_item_num` è®¾ä¸º 40ï¼Œ`max_token_num` 256ï¼Œç­‰ç­‰ã€‚
  > - è¿™æ ·å¯ä»¥æ–¹ä¾¿åœ°åˆ‡æ¢â€œé•¿åºåˆ—â€ã€â€œçŸ­åºåˆ—â€ç­‰ä¸åŒæ•°æ®é¢„å¤„ç†æ¨¡å¼ã€‚
  >
  > è¿™é‡Œç®€å•ç†è§£ä¸€ä¸‹å„ç§åºåˆ—çš„é•¿åº¦æƒ…å†µ
  >
  > > **`mlshort`** ç±»å‹çš„åºåˆ—ç¨å¾®é•¿ä¸€ç‚¹ï¼Œå…è®¸40ä¸ªç‰©å“ï¼Œæ ‡é¢˜ç­‰æ–‡æœ¬é™åˆ¶30ä¸ªtokenï¼Œè®­ç»ƒæ—¶é‡‡æ ·20ä¸ªç‰©å“ï¼Œé€‚åˆä¸­çŸ­åºåˆ—ä»»åŠ¡ã€‚
  > >
  > > **`micshort`** ç±»å‹åºåˆ—è¾ƒçŸ­ï¼Œæœ€å¤š20ä¸ªç‰©å“ï¼Œä½†æ ‡é¢˜å…è®¸ç¨é•¿ï¼ˆ35ä¸ªtokenï¼‰ï¼Œé‡‡æ ·15ä¸ªç‰©å“ï¼Œé€‚åˆæ›´çŸ­çš„åºåˆ—æˆ–å¯¹æ–‡æœ¬æè¿°è¦æ±‚ç¨é«˜çš„åœºæ™¯ã€‚
  > >
  > > **`short`** ç±»å‹æœ€çŸ­ï¼Œæœ€å¤š20ä¸ªç‰©å“ï¼Œæ ‡é¢˜é•¿åº¦30ï¼Œé‡‡æ ·10ä¸ªç‰©å“ï¼Œé€‚åˆéå¸¸è½»é‡çš„çŸ­åºåˆ—ä»»åŠ¡ã€‚

* `tokenization.py`

  > è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º `V4T5Tokenizer` çš„ç±»ï¼Œç»§æ‰¿è‡ª `T5TokenizerV1`ï¼ˆå‡è®¾æ˜¯æŸä¸ªåŸºäº T5 æ¨¡å‹çš„ tokenizer ç±»ï¼‰ï¼Œå®ƒä¸»è¦ç”¨äºå¯¹è¾“å…¥çš„æ–‡æœ¬æˆ–åºåˆ—æ•°æ®è¿›è¡Œ **åˆ†è¯ç¼–ç ã€æ‰¹é‡ç¼–ç å’Œå¡«å……å¤„ç†**ï¼Œæ–¹ä¾¿æ¨¡å‹æ¥å—æ ¼å¼åŒ–çš„è¾“å…¥ã€‚
  >
  > **å…·ä½“åŠŸèƒ½å’Œä½œç”¨åˆ†æ**
  >
  > **1. ç±»ç»§æ‰¿å’Œé‡å†™**
  >
  > - ç»§æ‰¿è‡ª `T5TokenizerV1`ï¼Œåˆ©ç”¨å…¶åŸºç¡€çš„åˆ†è¯å’Œç¼–ç åŠŸèƒ½ã€‚
  > - é€šè¿‡é‡å†™å’Œæ–°å¢æ–¹æ³•ï¼Œæ‰©å±•äº†å¯¹ç‰¹å®šä¸šåŠ¡éœ€æ±‚çš„æ”¯æŒï¼ˆæ¯”å¦‚è‡ªå®šä¹‰çš„å¡«å……ç¬¦å·ã€åºåˆ—ä½ç½®ç­‰ï¼‰ã€‚
  >
  > **2. å…³é”®æ–¹æ³•ä»‹ç»**
  >
  > `@classmethod from_pretrained(cls, pretrained_model_name_or_path, config=None, new_vob=None)`
  >
  > - ä»é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„åŠ è½½ tokenizerã€‚
  > - åŠ è½½åï¼ŒæŠŠä¼ å…¥çš„ `config` é‡Œçš„ç‰¹å®š padding tokenï¼ˆå¦‚ `atom_pad`ã€`atom_user_pad`ï¼‰è½¬æˆå¯¹åº”çš„ token idï¼Œä¿å­˜åˆ° tokenizer å¯¹è±¡é‡Œã€‚
  > - æ”¯æŒä¼ å…¥æ–°çš„è¯è¡¨ `new_vob`ï¼ŒåŠ¨æ€æ‰©å±• tokenizer çš„è¯è¡¨ã€‚
  > - è¿”å›å¢å¼ºåçš„ tokenizer å®ä¾‹ã€‚
  >
  > `__call__(self, items, pad_to_max=False, return_tensor=False, ty='user')`
  >
  > - è®© tokenizer å®ä¾‹å¯¹è±¡å¯ä»¥åƒå‡½æ•°ä¸€æ ·è°ƒç”¨ã€‚
  > - åˆ¤æ–­è¾“å…¥ `items` æ˜¯å•æ¡æ•°æ®è¿˜æ˜¯æ‰¹é‡åˆ—è¡¨ï¼Œåˆ†åˆ«è°ƒç”¨ `encode` æˆ– `batch_encode`ã€‚
  > - æ”¯æŒç›´æ¥è¿”å› PyTorch çš„ tensor æ ¼å¼ï¼ˆ`return_tensor=True`ï¼‰ã€‚
  > - `ty` ç”¨æ¥åŒºåˆ†å¯¹â€œç”¨æˆ·â€åºåˆ—è¿˜æ˜¯â€œç‰©å“â€åºåˆ—çš„ç¼–ç é€»è¾‘ã€‚
  >
  > `encode(self, items, ty='user')`
  >
  > - ç¼–ç å•æ¡è¾“å…¥åºåˆ—ã€‚
  > - æˆªæ–­åºåˆ—åˆ°æœ€å¤§é•¿åº¦ `max_item_num`ã€‚
  > - ä½¿ç”¨è‡ªå®šä¹‰å¡«å……ç¬¦å·ï¼ˆ`atom_pad_id`ï¼‰å¯¹åºåˆ—ä¸­æ¯ä¸ªitemçš„æ–‡æœ¬è¿›è¡Œç¼–ç å’Œé™åˆ¶é•¿åº¦ï¼ˆ`max_infor_len`ï¼‰ã€‚
  > - æ„å»ºè¾“å…¥çš„ token id åˆ—è¡¨ã€ä½ç½®ä¿¡æ¯ `input_positions`ã€ç´¢å¼• `input_index` ç­‰è¾…åŠ©ä¿¡æ¯ã€‚
  > - å¯¹ `ty == 'item'` æ—¶ï¼Œé¢å¤–æ·»åŠ ç”¨æˆ·ç›¸å…³çš„ padding æ ‡è®°ã€‚
  > - è¿”å›ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«æ¨¡å‹è¾“å…¥æ‰€éœ€çš„å„ç§ä¿¡æ¯ï¼ˆtoken idsï¼Œæ³¨æ„åŠ›æ©ç ï¼Œä½ç½®ç´¢å¼•ç­‰ï¼‰ã€‚
  >
  > `padding(self, item_batch, pad_to_max)`
  >
  > - å¯¹ä¸€ä¸ªæ‰¹é‡çš„ç¼–ç ç»“æœåš**ç»Ÿä¸€å¡«å……**ï¼Œä½¿å¾—æ¯æ¡åºåˆ—é•¿åº¦ä¸€è‡´ã€‚
  > - æ ¹æ® `pad_to_max` å†³å®šå¡«å……åˆ°æœ€å¤§ token æ•°é‡ï¼Œæˆ–è€…å½“å‰æ‰¹æ¬¡æœ€å¤§é•¿åº¦ã€‚
  > - å¯¹ token idsã€attention maskã€ä½ç½®ç´¢å¼•ç­‰åšç›¸åº”çš„ padding è¡¥é½ã€‚
  > - è¿”å›å¡«å……åçš„æ‰¹é‡å­—å…¸ã€‚
  >
  > `batch_encode(self, item_batch, pad_to_max=False, ty='user')`
  >
  > - æ‰¹é‡ç¼–ç æ–¹æ³•ï¼Œè°ƒç”¨ `encode` é€æ¡ç¼–ç ã€‚
  > - ç„¶åè°ƒç”¨ `padding` è¿›è¡Œç»Ÿä¸€å¡«å……ã€‚
  > - å¦‚æœæ˜¯ç‰©å“ç±»å‹ (`ty=='item'`)ï¼Œè¿˜ä¼šè¿”å›ç”¨æˆ·ç›¸å…³çš„ç´¢å¼•ä¿¡æ¯ã€‚
  > - è¿”å›é€‚åˆæ¨¡å‹è¾“å…¥çš„æ‰¹é‡å­—å…¸ã€‚
  >
  > **æ€»ä½“ä½œç”¨æ€»ç»“**
  >
  > `V4T5Tokenizer` è¿™ä¸ªç±»ä¸»è¦è´Ÿè´£ï¼š
  >
  > - æŠŠåŸå§‹æ–‡æœ¬æˆ–ç‰©å“ä¿¡æ¯è½¬æˆæ¨¡å‹å¯æ¥å—çš„ token id åºåˆ—ï¼›
  > - å¯¹åºåˆ—è¿›è¡Œä½ç½®ç¼–ç å’Œç´¢å¼•å¤„ç†ï¼Œé…åˆæ¨¡å‹ç»“æ„ï¼ˆæ¯”å¦‚ Transformerï¼‰ï¼›
  > - æ”¯æŒæ‰¹é‡è¾“å…¥ï¼Œå¹¶å¯¹æ‰¹é‡å†…ä¸åŒé•¿åº¦åºåˆ—åšåŠ¨æ€æˆ–å›ºå®šé•¿åº¦çš„ paddingï¼›
  > - æ”¯æŒæ‰©å±•è¯è¡¨å’Œè‡ªå®šä¹‰ç‰¹æ®Š tokenï¼Œæ»¡è¶³ç‰¹å®šä¸šåŠ¡éœ€æ±‚ã€‚
  >
  > **ä¸ºä»€ä¹ˆéœ€è¦å®ƒï¼Ÿ**
  >
  > æ¨¡å‹ï¼ˆå°¤å…¶æ˜¯åŸºäº Transformer çš„é¢„è®­ç»ƒæ¨¡å‹ï¼‰è¾“å…¥é€šå¸¸è¦æ±‚ï¼š
  >
  > - è¾“å…¥æ˜¯å›ºå®šé•¿åº¦çš„ token id åºåˆ—ï¼›
  > - éœ€è¦æœ‰ attention mask å’Œä½ç½®ä¿¡æ¯ï¼›
  > - æ”¯æŒæ‰¹é‡è®­ç»ƒï¼Œä¿è¯æ¯ä¸ª batch å†…è¾“å…¥å½¢çŠ¶ä¸€è‡´ï¼›
  > - éœ€è¦çµæ´»åœ°å¤„ç†ä¸åŒç±»å‹è¾“å…¥ï¼ˆç”¨æˆ·åºåˆ— vs ç‰©å“åºåˆ—ï¼‰ã€‚
  >
  > `V4T5Tokenizer` æ­£æ˜¯ä¸ºè¿™ç±»åœºæ™¯å®šåˆ¶çš„å·¥å…·ï¼Œå°è£…äº†åˆ†è¯ã€ç¼–ç ã€å¡«å……ã€æ‰¹å¤„ç†ä¸€ç³»åˆ—æ“ä½œã€‚



#### ä¸€äº›ç–‘é—®

* **å‘ç°å¹¶æ²¡æœ‰ `pretrained/t5-small/` è¿™ä¸ªä¸œè¥¿ï¼Œå¾ˆè‡ªé—­**

* å…³äº `corpus` æ˜¯ä»€ä¹ˆï¼Ÿ

  **corpusï¼ˆè¯­æ–™åº“ï¼‰å°±æ˜¯ä¸€å †â€œè®­ç»ƒç”¨çš„æ•°æ®æ–‡æœ¬é›†åˆâ€**ï¼Œå®ƒæ˜¯æ¨¡å‹å­¦ä¹ æ—¶çš„åŸææ–™ã€‚

  ä»£ç é‡Œçš„ `diff_gid` å‚æ•°å†³å®šäº†ç”¨å“ªç§â€œè¯­æ–™ç‰ˆæœ¬â€ï¼ˆä¸åŒçš„ corpus æ–‡ä»¶ï¼‰ï¼š

  | å‚æ•°å€¼     | åŠ è½½çš„ corpus æ–‡ä»¶       | å«ä¹‰ï¼ˆå¯èƒ½çš„å¤„ç†æ–¹å¼ï¼‰                           |
  | ---------- | ------------------------ | ------------------------------------------------ |
  | `None`     | `corpus_512.json`        | é»˜è®¤è¯­æ–™ï¼ŒåŸå§‹æˆ–æ ‡å‡†ç‰ˆæœ¬                         |
  | `'random'` | `corpus_512_random.json` | ç”¨éšæœºæ–¹å¼å¤„ç†æˆ–åˆ†ç»„è¿‡çš„è¯­æ–™ï¼Œå¯èƒ½éšæœºæ‰“ä¹±æˆ–åˆ’åˆ† |
  | `'bert'`   | `corpus_512_semi.json`   | ç”¨ BERT åŠç›‘ç£æ–¹æ³•å¤„ç†è¿‡çš„è¯­æ–™ï¼Œå¸¦è¯­ä¹‰ä¿¡æ¯å¢å¼º   |

  ä¸åŒç‰ˆæœ¬çš„ corpus ä»£è¡¨äº†æ•°æ®çš„ä¸åŒå¤„ç†æ–¹å¼ï¼Œæ¯”å¦‚ï¼š

  - **æ˜¯å¦æœ‰æ–‡æœ¬å†…å®¹ï¼ˆno_contentï¼‰**
  - **æ˜¯å¦å¯¹æ–‡æœ¬åšäº†ç‰¹æ®Šåˆ†ç»„ï¼ˆrandomï¼‰**
  - **æ˜¯å¦ç”¨é¢„è®­ç»ƒæ¨¡å‹å¦‚ BERT åšäº†ç‰¹å¾å¢å¼ºï¼ˆbertï¼‰**

* ä»€ä¹ˆæ˜¯ Hugging Faceï¼Ÿ

  Hugging Face æ˜¯ä¸€ä¸ªä¸“æ³¨äº **äººå·¥æ™ºèƒ½ï¼ˆAIï¼‰ä¸è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰** çš„å…¬å¸å’Œå¼€æºç¤¾åŒºï¼Œå…¶æ ¸å¿ƒè´¡çŒ®æ˜¯æä¾›äº†ä¸€å¥— **å¼ºå¤§ä¸”æ˜“ç”¨çš„å·¥å…·åŒ…ã€æ¨¡å‹åº“ä¸å¹³å°æœåŠ¡**ï¼Œå¹¿æ³›ç”¨äºå„ç§ AI ä»»åŠ¡ï¼Œå°¤å…¶æ˜¯åŸºäº Transformer æ¶æ„çš„æ¨¡å‹å¼€å‘ä¸éƒ¨ç½²ã€‚

  > | åç§°                          | ä½œç”¨                                                  | ä¸¾ä¾‹                                 |
  > | ----------------------------- | ----------------------------------------------------- | ------------------------------------ |
  > | **ğŸ¤— Transformers**            | å¼€æºåº“ï¼Œæä¾›é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚BERTã€GPTã€T5ç­‰ï¼‰å’Œä½¿ç”¨æ¥å£ | `from transformers import BertModel` |
  > | **Datasets**                  | ç”¨äºåŠ è½½ã€å¤„ç†å’Œåˆ†äº«å¤§è§„æ¨¡æ ‡å‡†æ•°æ®é›†                  | GLUEã€SQuADã€IMDB ç­‰                 |
  > | **Tokenizers**                | å¿«é€Ÿã€é«˜æ•ˆçš„åˆ†è¯å·¥å…·ï¼Œæ”¯æŒè®­ç»ƒè‡ªå·±çš„ tokenizer        | WordPieceã€BPEã€SentencePiece        |
  > | **Hubï¼ˆæ¨¡å‹ä»“åº“ï¼‰**           | æä¾›æµ·é‡é¢„è®­ç»ƒæ¨¡å‹ã€æ•°æ®é›†å’Œç©ºé—´ï¼ˆSpaceï¼‰             | https://huggingface.co/models        |
  > | **Spaces**                    | åŸºäº Gradio æˆ– Streamlit éƒ¨ç½² ML åº”ç”¨çš„å¯è§†åŒ–æ¼”ç¤ºå¹³å° | å¯åœ¨çº¿è¿è¡Œ AI demo                   |
  > | **Accelerate**                | ç®€åŒ–å¤šè®¾å¤‡ï¼ˆå¤šGPUã€TPUï¼‰è®­ç»ƒæµç¨‹çš„å·¥å…·                | è‡ªåŠ¨å¤„ç†åˆ†å¸ƒå¼è®­ç»ƒé€»è¾‘               |
  > | **AutoTrain**                 | é›¶ä»£ç è®­ç»ƒå¹³å°ï¼Œè‡ªåŠ¨å®Œæˆæ•°æ®é¢„å¤„ç†ã€æ¨¡å‹è®­ç»ƒä¸éƒ¨ç½²    | åƒ AutoML ä¸€æ ·ä¸€é”®è®­ç»ƒ               |
  > | **Inference API / Endpoints** | æ¨¡å‹æ‰˜ç®¡æœåŠ¡ï¼Œæ”¯æŒåœ¨çº¿æ¨ç†ä¸éƒ¨ç½²                      | æä¾› HTTP API è¿›è¡Œè°ƒç”¨               |
  >
  > ğŸ§  æ¨¡å‹ç¤ºä¾‹
  >
  > Hugging Face å¹³å°ä¸Šé›†æˆäº†å¤§é‡çŸ¥åæ¨¡å‹ï¼š
  >
  > - **BERT / RoBERTa**ï¼ˆè°·æ­Œ/Facebook æå‡ºçš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼‰
  >- **GPT ç³»åˆ—**ï¼ˆç”Ÿæˆå¼æ¨¡å‹ï¼‰
  > - **T5 / BART**ï¼ˆç”¨äºæ–‡æœ¬ç”Ÿæˆã€æ‘˜è¦ã€ç¿»è¯‘ç­‰ä»»åŠ¡ï¼‰
  > - **CLIP / DINO / SAM**ï¼ˆç”¨äºå¤šæ¨¡æ€ã€å›¾åƒç†è§£ç­‰ï¼‰
  > 
  > ä½ å¯ä»¥é€šè¿‡ä¸‹é¢è¿™ç§æ–¹å¼åŠ è½½å¹¶ä½¿ç”¨æ¨¡å‹ï¼š
  >
  > ```python
  >from transformers import pipeline
  > # å¿«é€Ÿä½¿ç”¨æƒ…æ„Ÿåˆ†ææ¨¡å‹
  > classifier = pipeline("sentiment-analysis")
  > result = classifier("I love Hugging Face!")
  > print(result)
  > ```
  > 
  > ğŸ§‘â€ğŸ”¬ Hugging Face åœ¨ç ”ç©¶å’Œå·¥ä¸šç•Œçš„æ„ä¹‰
  > 
  >- é™ä½ä½¿ç”¨å¤§å‹é¢„è®­ç»ƒæ¨¡å‹çš„é—¨æ§›ï¼ˆå°¤å…¶æ˜¯å¯¹é NLP ä¸“å®¶ï¼‰
  > - æä¾›ç¤¾åŒºåä½œä¸æ¨¡å‹å…±äº«å¹³å°
  >- æ”¯æŒä»ç ”ç©¶å®éªŒåˆ°å®é™…éƒ¨ç½²çš„å®Œæ•´æµç¨‹
  
* ä»¥ aug ä¸ºå‰ç¼€çš„å˜é‡çš„ä½œç”¨åŠè®ºæ–‡å¯¹åº”éƒ¨åˆ† / å…¬å¼

  > ä»¥`aug`ä¸ºå‰ç¼€çš„å˜é‡ï¼ˆ`aug_set`ã€`aug_iid`ã€`aug_item_content`ã€`aug_user_atomids`ç­‰ï¼‰ä¸»è¦ç”¨äº**æ„å»ºå¯¹æ¯”å­¦ä¹ ä¸­çš„æ­£æ ·æœ¬**ï¼Œæ”¯æŒè®ºæ–‡ä¸­ â€œå¯¹æ¯”æŸå¤±ï¼ˆcontrastive lossï¼‰â€ çš„è®¡ç®—ï¼Œç¡®ä¿**å…·æœ‰ç›¸ä¼¼ååŒä¿¡å·ï¼ˆGIDï¼‰çš„ç‰©å“åœ¨å†…å®¹è¯­ä¹‰ç©ºé—´ä¸­ä¹Ÿå…·æœ‰ç›¸ä¼¼æ€§ã€‚**
  >
  > - **å…·ä½“ä½œç”¨**ï¼š
  >
  >   - `aug_set`ï¼šé€šè¿‡`cid_neg_dict`è·å–ä¸å½“å‰`iid`çš„ GID å‰ 2 ä¸ªå‰ç¼€ç›¸åŒçš„ç‰©å“é›†åˆï¼ˆå³ GID ç›¸ä¼¼çš„ç‰©å“ï¼Œå¯¹åº”è®ºæ–‡ä¸­ â€œå…·æœ‰é‡å å‰ç¼€ GID çš„ç‰©å“â€ï¼‰ï¼›
  >   - `aug_iid`ï¼šä»`aug_set`ä¸­é‡‡æ ·çš„ç‰©å“ï¼Œä½œä¸ºå½“å‰`iid`çš„æ­£æ ·æœ¬ï¼ˆå¯¹åº”è®ºæ–‡ä¸­çš„`i_+`ï¼‰ï¼›
  >   - `aug_item_content`å’Œ`aug_item_atomid`ï¼š`aug_iid`çš„å†…å®¹ä¿¡æ¯å’ŒåŸå­ IDï¼Œç”¨äºæ„å»ºæ­£æ ·æœ¬çš„å†…å®¹è¡¨ç¤ºï¼›
  >   - `aug_user_atomids`ï¼šä¸`aug_iid`äº¤äº’è¿‡çš„ç”¨æˆ·ï¼Œç”¨äºå¢å¼ºæ­£æ ·æœ¬çš„ååŒä¿¡å·å…³è”ã€‚
  >
  > - **è®ºæ–‡å¯¹åº”éƒ¨åˆ†åŠå…¬å¼**ï¼š è¿™äº›å˜é‡å¯¹åº”è®ºæ–‡ 4.5 èŠ‚çš„ â€œå¯¹æ¯”å­¦ä¹ ï¼ˆContrastive Learningï¼‰â€ éƒ¨åˆ†ï¼Œå…·ä½“ç”¨äºè®¡ç®—**å¯¹æ¯”æŸå¤±â„’_c**ï¼ˆå…¬å¼ 10ï¼‰ã€‚è®ºæ–‡ä¸­æåˆ°ï¼Œå¯¹æ¯”æŸå¤±çš„ç›®çš„æ˜¯ â€œç¡®ä¿å…·æœ‰ç›¸ä¼¼ GID çš„ç‰©å“åœ¨å†…å®¹è¯­ä¹‰ç©ºé—´ä¸­ä¹Ÿç›¸ä¼¼â€ï¼Œä¸ºæ­¤éœ€è¦é‡‡æ · â€œå…·æœ‰é‡å å‰ç¼€ GID çš„ç‰©å“`i_+`ä½œä¸ºæ­£æ ·æœ¬â€ï¼Œè€Œ`aug`ç›¸å…³å˜é‡æ­£æ˜¯ç”¨äºæ„å»ºè¿™æ ·çš„æ­£æ ·æœ¬ï¼Œæ”¯æŒè¯¥æŸå¤±çš„è®¡ç®—ã€‚
  >
  >   å…¬å¼ 10 å¦‚ä¸‹ï¼š$\mathcal{L}_{c}=-ln \sigma\left(h\left(X_{i}\right) \cdot\left(h\left(X_{i_{+}}\right)-h\left(X_{i_{-}}\right)\right)\right)$å…¶ä¸­ï¼Œ`aug_iid`å³å…¬å¼ä¸­çš„`i_+`ï¼ˆæ­£æ ·æœ¬ï¼‰ï¼Œé€šè¿‡`aug`å˜é‡æ„å»ºçš„æ­£æ ·æœ¬ç‰¹å¾ç”¨äºè®¡ç®—`h(X_{i_+})`ï¼Œè¿›è€Œä¼˜åŒ–å¯¹æ¯”æŸå¤±ã€‚

* åœ¨ `class v7CL2TrainDataset(v4TrainDataset)`  è¿™ä»½ä»£ç ä¸­çš„ `__getitem__()` æ¨¡å—ä¸‹ï¼Œä¸ºä»€ä¹ˆæ„é€ ç”¨æˆ· content å­—æ®µè¦å‰”é™¤ iid å¯¹åº”çš„ Item çš„ content è€Œä¿ç•™å…¶ä»–äº¤äº’è¿‡çš„ item çš„ contentï¼Ÿ

  **ä¸ºäº†é˜²æ­¢æ•°æ®æ³„éœ²**

  éœ€è¦æ˜ç¡®çš„ä¸€ç‚¹æ˜¯æˆ‘ä»¬çš„ idx æ˜¯ä»¥äº¤äº’ä¿¡æ¯è¡¨ï¼ˆ==**ä¸ºçš„æ˜¯æ¨¡å‹åŸºäºçº¯ç²¹çš„å†å²äº¤äº’ä¿¡æ¯é¢„æµ‹ç›®æ ‡ç‰©å“**==ï¼‰ä¸ºä½œç”¨å¯¹è±¡çš„ï¼Œä¼šå¾—åˆ°å¯¹åº”çš„ user ä¸ itemã€‚äº‹å®ä¸Šè¿™ä¸ª item å°±æ˜¯æˆ‘ä»¬çš„ targetã€‚

  > ç”¨æˆ· content å­—æ®µçš„ä½œç”¨æ˜¯é€šè¿‡èšåˆç”¨æˆ·å†å²äº¤äº’è¿‡çš„ç‰©å“å†…å®¹ä¿¡æ¯æ¥è¡¨ç¤ºç”¨æˆ·åå¥½ï¼ˆå¯¹åº”è®ºæ–‡ä¸­ â€œç”¨æˆ·è¢«è¡¨ç¤ºä¸ºäº¤äº’ç‰©å“çš„å†…å®¹èšåˆâ€ï¼‰ã€‚è€Œä»£ç ä¸­çš„`iid`æ˜¯å½“å‰è®­ç»ƒæ ·æœ¬ä¸­çš„ç›®æ ‡ç‰©å“ï¼ˆå³æ­£æ ·æœ¬ç‰©å“ï¼‰ï¼Œè‹¥å°†å…¶ content åŒ…å«åœ¨ç”¨æˆ· content ä¸­ï¼Œä¼šå¯¼è‡´æ¨¡å‹åœ¨è®­ç»ƒæ—¶æå‰ â€œçœ‹åˆ°â€ ç›®æ ‡ç‰©å“çš„ä¿¡æ¯ï¼Œé€ æˆ**æ•°æ®æ³„éœ²**ã€‚è¿™ç§æ³„éœ²ä¼šä½¿æ¨¡å‹**æ— æ³•çœŸæ­£å­¦ä¹ ä» â€œç”¨æˆ·å†å²äº¤äº’â€ åˆ° â€œç›®æ ‡ç‰©å“â€ çš„æ˜ å°„å…³ç³»**ï¼Œå**è€Œå¯èƒ½é€šè¿‡ç›´æ¥è®°å¿†ç›®æ ‡ç‰©å“çš„ç‰¹å¾æ¥æ‹Ÿåˆè®­ç»ƒæ•°æ®ï¼Œå¯¼è‡´è¿‡æ‹Ÿåˆå’Œæ³›åŒ–èƒ½åŠ›ä¸‹é™**ã€‚å› æ­¤ï¼Œå‰”é™¤ iid å¯¹åº”çš„ Item çš„ content æ˜¯ä¸ºäº†ä¿è¯è®­ç»ƒçš„åˆç†æ€§ï¼Œ**ç¡®ä¿æ¨¡å‹åŸºäºçº¯ç²¹çš„å†å²äº¤äº’ä¿¡æ¯é¢„æµ‹ç›®æ ‡ç‰©å“ã€‚**

  





#### ç†è§£ä»£ç ä¹‹å‰–æ T5 ä¸æ•´ä¸ªå®éªŒæµç¨‹



#### ç†è§£æ•°æ®ä»£ç ä¹‹ç†è§£åˆ†è¯å™¨ `tokenizer`

åœ¨è¿™ä¸€éƒ¨åˆ†ï¼Œæˆ‘ä»¬å°†ä¼šå‰–æ T5Tokenizer ï¼Œå­¦ä¹ å®ƒçš„æœºåˆ¶å¹¶å°è¯•ç€è‡ªå·±**è‡ªå®šä¹‰**æˆ–è€…è¯´æ˜¯é‡æ„å±äºè‡ªå·±ä»»åŠ¡çš„åˆ†è¯å™¨ã€‚

æ•´ä¸ª `tokenization.py` å®ç°äº†è¿™æ ·çš„ä¸€ä¸ªåŠŸèƒ½ï¼š

> **å°†å¤šå­—æ®µç»“æ„åŒ–ä¿¡æ¯ï¼ˆå¦‚ç”¨æˆ·ã€ç‰©å“ã€å±æ€§ï¼‰ç¼–ç ä¸ºé€‚ç”¨äº T5 æ¨¡å‹çš„ token åºåˆ—è¾“å…¥ï¼ŒåŒæ—¶æ·»åŠ ä½ç½®ä¿¡æ¯ã€æ©ç ä¿¡æ¯ã€åˆ†æ®µä¿¡æ¯ç­‰ç”¨äº Transformer æ¨¡å‹çš„ç»†ç²’åº¦æ§åˆ¶ã€‚**
>
> ä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬è¦**å¤šå…³æ³¨è¾“å…¥æ•°æ®çš„ç»„ç»‡ç»“æ„ï¼Œæ ¹æ®è¿™ä¸€ç»„ç»‡ç»“æ„æ¥é‡æ„åˆ†è¯å™¨**



æœ‰ä¸€ä¸ªä¸»è¦çš„é—®é¢˜æ˜¯ï¼šè¿™æ®µä»£ç ä¸ºä»€ä¹ˆ**ä¸ç›´æ¥å†™ `V4T5Tokenizer`ï¼Œè€Œæ˜¯å…ˆå†™äº†ä¸€ä¸ªä¸­é—´ç±» `T5TokenizerV1`ï¼Ÿä¸èƒ½ç›´æ¥ç»§æ‰¿ `T5Tokenizer` å—ï¼Ÿ**

> æ˜¯å¯ä»¥ç›´æ¥ç»§æ‰¿ `T5Tokenizer` çš„ï¼Œä½†è®¾è®¡è€…é€šè¿‡å¼•å…¥ `T5TokenizerV1` æ˜¯ä¸ºäº†åšâ€œåˆ†å±‚æ‰©å±•â€ï¼Œå°†åŠŸèƒ½æ¨¡å—åŒ–ã€è§£è€¦ï¼Œæ–¹ä¾¿ç®¡ç†å’Œå¤ç”¨ä¸åŒç‰ˆæœ¬çš„ Tokenizer é€»è¾‘ã€‚
>
> ```bash
> T5Tokenizer (from HuggingFace)
>     â†“
> T5TokenizerV1  â† æ·»åŠ é€šç”¨è‡ªå®šä¹‰åŠŸèƒ½ï¼ˆlabelå¤„ç†ã€paddingã€åŸºæœ¬encodeï¼‰
>     â†“
> V4T5Tokenizer   â† ç‰¹å®šé¡¹ç›®ï¼ˆåŸå­å¡«å……ã€ä½ç½®ç¼–ç ã€å¤šå¤´ç”¨æˆ·ï¼‰
> ```
>
> **`T5TokenizerV1` çš„ä½œç”¨ï¼š**
>
> - åœ¨ HuggingFace çš„ `T5Tokenizer` ä¸Šæ‰©å±•äº†å‡ ä¸ªåŸºæœ¬åŠŸèƒ½ï¼Œæ¯”å¦‚ï¼š
>   - æ”¯æŒ `__call__()` ä¼ å…¥ `items` è‡ªåŠ¨ encode
>   - æ”¯æŒ `is_label` æ¨¡å¼ï¼ˆç”¨äºç”Ÿæˆæ ‡ç­¾ï¼‰
>   - æ”¯æŒ `batch_encode`, `padding`, `encode_semid`, `semid_padding` ç­‰é€šç”¨æ¥å£
> - æ˜¯ä¸€ç§â€œåŸºç¡€å¢å¼ºç‰ˆ T5Tokenizerâ€
>
> **`V4T5Tokenizer` çš„ä½œç”¨ï¼š**
>
> - åœ¨ `T5TokenizerV1` çš„åŸºç¡€ä¸Šï¼Œå†åŠ å…¥æ›´ç‰¹åŒ–çš„é€»è¾‘ï¼Œæ¯”å¦‚ï¼š
>   - `atom_pad`, `atom_user_pad`
>   - `input_positions`, `atom_index`, `user_atom_index` ç­‰è‡ªå®šä¹‰ç»“æ„åŒ–è¾“å…¥
>   - é’ˆå¯¹ç‰¹å®šä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚å›¾æ¨èã€çŸ¥è¯†å¡«å……ï¼‰çš„**å®šåˆ¶è¡Œä¸º**



* è®¤è¯†T5Tokenizer

  `T5Tokenizer` æ˜¯ Hugging Face Transformers åº“ä¸­ä¸º [T5 æ¨¡å‹ï¼ˆText-To-Text Transfer Transformerï¼‰](https://arxiv.org/abs/1910.10683) æä¾›çš„ **åˆ†è¯å™¨ï¼ˆTokenizerï¼‰**ã€‚å®ƒåŸºäº SentencePiece åˆ†è¯ç³»ç»Ÿï¼Œé€‚ç”¨äº T5 æ¨¡å‹å°†æ‰€æœ‰ NLP ä»»åŠ¡ï¼ˆå¦‚åˆ†ç±»ã€ç¿»è¯‘ã€æ‘˜è¦ç­‰ï¼‰**ç»Ÿä¸€è¡¨ç¤ºä¸ºæ–‡æœ¬åˆ°æ–‡æœ¬çš„æ ¼å¼ï¼ˆtext-to-textï¼‰**ã€‚

  å½“ç„¶ï¼Œå¦‚æœè¦å»è¯†åˆ«ä¸­æ–‡ã€æ—¥è¯­éœ€è¦å»æ‰¾æœ‰å¯¹åº”è¯æ±‡è¡¨çš„ modelï¼Œ"t5-small" çš„è¯æ±‡è¡¨æ˜¯åŸºäºè‹±æ–‡çš„ã€‚

  * ä»€ä¹ˆæ˜¯ SentencePiece åˆ†è¯ç³»ç»Ÿ

    `SentencePiece` æ˜¯ä¸€ç§ **åŸºäºå­è¯ï¼ˆsubwordï¼‰** çš„åˆ†è¯å·¥å…·ï¼Œç”± Google æå‡ºï¼Œå¸¸ç”¨äºå¯¹ **ä¸ä¾èµ–ç©ºæ ¼åˆ†è¯è¯­è¨€ï¼ˆå¦‚ä¸­æ–‡ã€æ—¥è¯­ï¼‰** è¿›è¡Œå»ºæ¨¡ã€‚

    ä¸å¸¸è§çš„åˆ†è¯æ–¹æ³•ï¼ˆå¦‚ WordPieceã€BPEï¼‰ä¸åŒï¼Œ**SentencePiece ä¸ä¾èµ–ç©ºæ ¼æˆ–é¢„å…ˆçš„è¯è¾¹ç•Œä¿¡æ¯**ï¼Œè€Œæ˜¯æŠŠæ•´ä¸ªè¾“å…¥å½“ä½œä¸€ä¸ªâ€œè¿ç»­çš„å­—ç¬¦æµâ€å¤„ç†ï¼Œä»ä¸­è‡ªåŠ¨å­¦ä¹ è¯æ±‡å•å…ƒã€‚

    å°±æ˜¯è¯´ **SentencePiece ä¸æ˜¯åƒè‹±è¯­é‚£æ ·ä¾èµ–ç©ºæ ¼æ¥åˆ†è¯ï¼Œè€Œæ˜¯æ ¹æ®å­è¯ï¼ˆsubwordï¼‰é¢‘ç‡è‡ªåŠ¨å­¦ä¹ åˆ‡åˆ†æ–¹å¼**ã€‚

    å¯¹è‹±æ–‡åˆ†è¯ï¼š

    ```python
    model_ckpt = "t5-small"
    tokenizer = T5Tokenizer.from_pretrained(model_ckpt, cache_dir = cache_dir_model)
    text2 = "my name is Shencong, I like watching movings!"
    tokens_2 = tokenizer.tokenize(text2)
    tokens_2
    ```

    ```bash
    ['â–my',
     'â–name',
     'â–is',
     'â–She',
     'n',
     'con',
     'g',
     ',',
     'â–I',
     'â–like',
     'â–watching',
     'â–moving',
     's',
     '!']
    ```

    `â–` ä»£è¡¨è¯è¾¹ç•Œï¼ˆå³ SentencePiece çš„â€œèµ·å§‹æ ‡å¿—â€ï¼‰

    

    å¯¹ä¸­æ–‡åˆ†è¯

    ```python
    model_cn = "google/mt5-base"
    tokenizer_cn = T5Tokenizer.from_pretrained(model_cn, cache_dir = cache_dir_model)
    tokenizer_cn.tokenize("æˆ‘å–œæ¬¢åƒç±³é¥­å’Œé¸¡è›‹ã€‚")
    ```

    ```bash
    ['â–', 'æˆ‘', 'å–œæ¬¢', 'åƒ', 'ç±³', 'é¥­', 'å’Œ', 'é¸¡', 'è›‹', 'ã€‚']
    ```

* å­¦ä¹  ``T5TokenizerV1``

  > å¯¹ `T5Tokenizer` çš„åˆçº§å°è£…ï¼Œå¢å¼ºåŠŸèƒ½åŒ…æ‹¬ï¼š
  >
  > - æŒ‚è½½è‡ªå®šä¹‰ `config` å¯¹è±¡ï¼ˆæ§åˆ¶ max lengthã€å­—æ®µæ•°é‡ç­‰ï¼‰
  > - æ”¯æŒ label çš„ç¼–ç ï¼ˆ`encode_semid`ï¼‰
  > - æ”¯æŒ batch ç¼–ç ã€padding
  > - é€‚åˆ**ç®€å• item åˆ—è¡¨çš„ç¼–ç **



##### å­¦ä¹  `tokenizer` çš„ç»„ç»‡ç»“æ„

é¦–å…ˆéœ€è¦æ˜ç¡®ä¸€äº› T5 çš„ç‰¹æ®Šç¼–ç 

1. ç»“æŸç¬¦ `.eos_token_id`	1	`'</s>'`
2. å¡«å……ç¬¦ `.pad_token_id`    0    `'<pad>'`

**å…¶æ¬¡ï¼Œè¿›å…¥ `__call__()` ä¸­ï¼Œè¿™é‡Œé’ˆå¯¹çš„æ˜¯ batch ä¸­ä¸€æ¡ item çš„ç¼–ç å¤„ç†**ï¼Œè¿”å›å½¢å¼å½“ç„¶æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œåœ¨ `batch_item` ä¸­çš„ä½“ç°æ˜¯ `[dic_item1, dic_item2, ..., dic_itemB]`

* `from_pretrained()`

  ```python
  @classmethod
  def from_pretrained(cls, pretrained_model_name_or_path,config=None,new_vob=None):
      # cls.config = config # ç›¸è¾ƒäºåŸæœ¬çš„tokenizerï¼Œä¼šæŠŠconfigåŠ è¿›æ¥
      # å¦‚æœæœ‰æ–°çš„å•è¯ï¼Œä¼šæ·»åŠ åˆ°tokenizerä¸­
      tokenizer = super().from_pretrained(pretrained_model_name_or_path,config=config)
      # å…³é”®ï¼šæ‰‹åŠ¨ç»‘å®š config åˆ°å®ä¾‹ä¸Š
      tokenizer.config = config
      tokenizer.atom_pad = config.atom_pad
      tokenizer.atom_pad_id = tokenizer.convert_tokens_to_ids(config.atom_pad)
      tokenizer.atom_user_pad = config.atom_user_pad
      tokenizer.atom_user_pad_id = tokenizer.convert_tokens_to_ids(config.atom_user_pad)
      if new_vob is not None:
          tokenizer.add_tokens(sorted(new_vob))
      return tokenizer
  ```

  

* `__call__()`

  ```python
  def __call__(self,items,pad_to_max=False,return_tensor=False,ty='user'):
      assert ty in ['user','item']
  
      if len(items) > 0 and isinstance(items[0],list):
          inputs = self.batch_encode(items,pad_to_max=pad_to_max,ty=ty)
  
      else:
          inputs = self.encode(items,ty=ty)
  
      if return_tensor:
          for k,v in inputs.items():
              inputs[k] = torch.LongTensor(v)
  
      return inputs
  ```



* `batch_encode()`

  ```python
  def batch_encode(self,item_batch,pad_to_max=False,ty='user'):
      # [dic_1, dic_2, ..., dic_n]
      item_batch = [self.encode(items,ty=ty) for items in item_batch] 
  
      ans_dict = self.padding(item_batch,pad_to_max)
      if ty == 'item':
          batch_user_index = [items['user_atom_index'] for items in item_batch]
          ans_dict.update({
              'user_atom_index':batch_user_index
          })
  
          return ans_dict
  ```

  éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ç¼–ç å’Œ `padding` æ“ä½œç»“æŸä¹‹åï¼Œè¿˜éœ€è¦å¯¹ `type == item` çš„æƒ…å†µä¸‹ï¼Œå¯¹ç”¨æˆ·åºåˆ—è¿›è¡Œå•ç‹¬å¤„ç†

  ```python
  batch_user_index = [items['user_atom_index'] for items in item_batch]
  ans_dict.update({
  	'user_atom_index':batch_user_index
  })
  ```

  

* `encode()`

  * æ¨¡å‹ type

    ä¸¤ç§æ¨¡å¼1. å¤„ç† userï¼›2. å¤„ç† item

  * è¾“å…¥

    è¿™é‡Œçš„ç¼–ç éƒ½æ˜¯é’ˆå¯¹ä¼ å…¥çš„ items éƒ½æ˜¯ list ç±»å‹æ¥è¿›è¡Œç¼–ç ï¼Œå¹¶ä¸”ä¼ å…¥çš„éƒ½æ˜¯ content ä¿¡æ¯

    è·å–ä¸€æ¡/å¤šæ¡æè¿°ä¿¡æ¯

    é’ˆå¯¹ item ä»»åŠ¡ å³ ty == item çš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ª batch ä¸‹åªæœ‰ä¸€æ¡ æ–‡æœ¬ä¿¡æ¯  ["sentence"]

    é’ˆå¯¹ user ä»»åŠ¡ å³ ty == user çš„æƒ…å†µä¸‹ï¼Œä¸€ä¸ª batch ä¸‹å¯èƒ½æœ‰å¤šæ¡æ–‡æœ¬ä¿¡æ¯ [["sentence1"], ["sentence2"], ..., ["sentence_N"]]

    

  * éœ€è¦å¤„ç†çš„ç¼–ç ä¿¡æ¯

    1. `input_ids`ï¼š

       `ty == 'item'`: [0, ä¸€ä»½æ–‡æœ¬å†…å®¹å¯¹åº”çš„ token_ids,  ç”¨æˆ·åŸå­å¡«å……ç¬¦ * sample_user_num, 1]

       `ty == 'user'`: [0, å¤šä»½æ–‡æœ¬å†…å®¹å¯¹åº”çš„ token_ids, 1]

       å½“ç„¶ï¼Œåœ¨å¡«å…¥ç»“æŸç¬¦ `1` ä¹‹å‰ï¼Œæ˜¯åšäº†æˆªæ–­å¤„ç†çš„ `input_ids = input_ids[:self.config.max_token_num-1]`

       å¦å¤– æ–‡æœ¬å†…å®¹å¯¹åº”çš„ token_ids ç”±ä¸¤éƒ¨åˆ†æ„æˆ `atom_pad_id` + `info_ids`ã€‚

       `atom_pad_id` æ˜¯**ç‰©å“åŸå­å¡«å……ç¬¦**ï¼ˆ**å…¶å®æ˜¯ T5 ä¸­çš„ `'<extra_id_0>' 32099`** ï¼‰ï¼Œç”¨äº**åˆ†éš”**ä¸åŒç‰©å“çš„åºåˆ—ï¼Œ**ä½œä¸ºè¾¹ç•Œè¯†åˆ«**

       `info_ids` å°±æ˜¯çº¯ç²¹çš„å¯¹æ–‡æœ¬ä¿¡æ¯åˆ†è¯åå¾—åˆ°çš„ token_ids

       **ç”¨æˆ·åŸå­å¡«å……ç¬¦**æ˜¯ `atom_user_pad_id`ï¼Œï¼ˆ**å…¶å®æ˜¯ T5 ä¸­çš„ `'<extra_id_1>'` 32098**ï¼‰

    2. `input_position`ï¼š

       **éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå…¶é•¿åº¦ä¸ `input_ids` ä¸€æ ·**

       `ty == 'item'`ï¼š[1, 3, 4, 5, ..., n, 2 * sample_user_num, 0]

       `ty == 'user'`ï¼š[1, 3, 4, 5, ..., n, 3, 4, 5, ..., m, ..., 0]

       1 æ˜¯å¼€å§‹ç¬¦å·ï¼Œ3åŠå…¶ä»¥åçš„è‡ªç„¶æ•°æ˜¯ä½œä¸ºæ–‡æœ¬å†…å®¹çš„ä½ç½®ç¼–ç ï¼Œ2æ˜¯ä¸ºç”¨æˆ·ç›¸å…³ token åˆ†é…ä½ç½®ç¼–ç ï¼Œ0 ä½œä¸ºç»“æŸç¬¦ã€‚

    3. `input_idx`ï¼šï¼ˆ**åç»­å¯ä»¥å»ç†è§£ä¸€ä¸‹å…·ä½“æ˜¯æ€ä¹ˆåˆ©ç”¨è¿™ä¸€æ•°æ®çš„**ï¼Œè¿™æ˜¯æ ¹æ®ä»»åŠ¡æ¥è¿›è¡Œé‡æ„çš„ä¸€éƒ¨åˆ†ï¼‰

       è®°å½• item åœ¨ input_ids ä¸­çš„**ä½ç½®**ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯ `atom_index`

       å¯ä»¥è®¤ä¸ºæ˜¯è®°å½•æ¯ä¸ª `item` åœ¨ `input_ids` ä¸­**é¦–æ¬¡å‡ºç°çš„ç´¢å¼•**

       é’ˆå¯¹ `ty == 'item'` ï¼Œåº”è¯¥å°±æ˜¯ [1] ï¼Œåœ¨æ‰¹å¤„ç†ä¸‹ï¼ˆ`batch_size = 4`ï¼‰åº”è¯¥æ˜¯ ï¼Œå› ä¸º 0 å·ç´¢å¼•å¯¹åº”çš„æ˜¯ padding

       ```python
       tensor([[1],
               [1],
               [1],
               [1]], device='cuda:0')
       ```

       

       é’ˆå¯¹ `ty == 'user'`ï¼Œ åº”è¯¥å°±æ˜¯ [1, pos_1, pos2, ...]

    4. `attention_mask`

       è¿™ä¸ªé•¿åº¦åŒæ ·ä¹Ÿæ˜¯ä¸ `input_ids` å’Œ `input_position` ä¸€æ ·çš„

    5. `user_index`

       åªé’ˆå¯¹ `ty == item` çš„æƒ…å†µï¼ŒæŒ‡ç¤ºçš„æ˜¯åœ¨ `input_ids` æˆ–è€…æ˜¯ `input_position` çš„æ•°æ®ä¸­ï¼Œ**é‚£äº›å‡ºç°ç”¨æˆ·ä¿¡æ¯çš„ç´¢å¼•**

       å¯ä»¥å‚è€ƒ

       `ty == 'item'`æ—¶çš„ `input_ids`ï¼š

       [0, ä¸€ä»½æ–‡æœ¬å†…å®¹å¯¹åº”çš„ token_ids,  ç”¨æˆ·åŸå­å¡«å……ç¬¦ * sample_user_num, 1]

       æˆ–è€… `input_position`ï¼š

       [1, 3, 4, 5, ..., n, 2 * sample_user_num, 0]

       ä¸Šé¢ä¸¤ä¸ªæ˜¯ä¸€ä¸€å¯¹é½çš„ï¼ï¼ï¼

  * è¾“å‡ºï¼šæ˜¯ä¸€ä¸ªå­—å…¸

    ```python
    # è¿™äº›è¿”å›çš„å­—æ®µå…±åŒæ„æˆæ¨¡å‹ç¼–ç å™¨çš„è¾“å…¥ï¼Œå®ç°äº†è®ºæ–‡ä¸­å¯¹ç”¨æˆ· / ç‰©å“è¾“å…¥åºåˆ—ï¼ˆX_u å’Œ X_iï¼‰çš„ç»“æ„åŒ–ç¼–# ç ï¼Œç”¨äºæ•è·å†…å®¹ä¿¡æ¯å’ŒååŒä¿¡å·ã€‚
    if ty == 'item':
        return {
            "content_input_ids": input_ids,
            "atom_index": input_index,
            "attention_mask": attention_mask,
            "input_positions":input_positions,
            "user_atom_index":user_index
        }
    else:
        return {
            "content_input_ids": input_ids,
            "atom_index": input_index,
            "attention_mask": attention_mask,
            "input_positions": input_positions,
        }
    ```

  

* `padding()`

  `encode` ä¹‹åè‚¯å®šè¦è¿›å…¥ `padding` æˆªæ–­

  è¿™é‡Œå…ˆå¯¹ `ty=='item'` å’Œ `ty == 'user'` å…±æœ‰çš„

  ```python
  "content_input_ids": input_ids,
  "atom_index": input_index,
  "attention_mask": attention_mask,
  "input_positions": input_positions,
  ```

  è¿™äº›æ•°æ®åš paddingã€‚ç›´æ¥çœ‹ä»£ç å°±è¡Œï¼Œé€»è¾‘éå¸¸çš„ç®€å•ï¼Œéƒ½æ˜¯ç”¨ 0 æ¥è¿›è¡Œå¡«è¡¥

  ```python
  def padding(self,item_batch,pad_to_max):
      # max_length æ˜¯é’ˆå¯¹ input_ids attention_mask input_positios çš„
      if pad_to_max:
          max_length = self.config.max_token_num
      else:
          max_length = max([len(items["content_input_ids"]) for items in item_batch])
  
      # max_index_length æ˜¯é’ˆå¯¹ input_index çš„
      max_index_length = max([len(items["atom_index"]) for items in item_batch])
  
      batch_input_ids = []
      batch_input_index = []
      batch_attention_mask = []
      batch_input_positions = []
  
      for items in item_batch:
          input_ids = items["content_input_ids"]
          input_index = items['atom_index']
          attention_mask = items["attention_mask"]
          input_positions = items["input_positions"]
  
          length_to_pad = max_length - len(input_ids)
          input_ids += [self.pad_token_id] * length_to_pad # input_ids
          attention_mask += [0] * length_to_pad # attention mask
          input_positions += [0] * length_to_pad
  
          index_length_to_pad = max_index_length - len(input_index)
          input_index += [0] * index_length_to_pad
  
          batch_input_ids.append(input_ids)
          batch_attention_mask.append(attention_mask)
          batch_input_index.append(input_index)
          batch_input_positions.append(input_positions)
  
      return {
          "content_input_ids":batch_input_ids,
          "atom_index":batch_input_index,
          "attention_mask":batch_attention_mask,
          "input_positions": batch_input_positions
      }
  ```

  







#### ç†è§£ä»£ç ä¹‹ç†è§£è£…é¥°å™¨ `@dataclass`

è¿™ä¸ªè£…é¥°å™¨æ¥è‡ª `dataclasses` æ¨¡å—ï¼ˆPython 3.7+ å¼•å…¥ï¼‰ï¼Œå®ƒå¯ä»¥**è‡ªåŠ¨**ä¸ºç±»**ç”Ÿæˆä¸€ç³»åˆ—æ–¹æ³•**ï¼Œ**åŒ…æ‹¬æœ€å¸¸ç”¨çš„ `__init__()`ã€‚**

æˆ‘ä»¬ä»¥ `DataProcessConfig()` è¿™ä¸ªç±»ä¸ºä¾‹ï¼š

æˆ‘ä»¬å‘ç°è¿™ä¸ªç±»ä¸­ï¼Œå®ƒæ˜¯æ²¡æœ‰å†™åˆå§‹åŒ–å‡½æ•° `__init__()` çš„

```python
from dataclasses import dataclass
@dataclass
class DataProcessConfig:
    atom_pad:str = '<extra_id_0>'
    atom_user_pad:str = '<extra_id_1>'
    cid_item_pad:str = '<extra_id_2>'

    total_item_num:int=0 # ä»valid datasetæ›´æ–°
    total_user_num: int = 0  # ä»valid datasetæ›´æ–°
    unknown_id:int=0
    sample_user_num:int=1
    mode:str = 'latest'     # æ•°æ®æŠ½æ ·æˆ–åˆ’åˆ†æ¨¡å¼ï¼Œæ¯”å¦‚ latest è¡¨ç¤ºç”¨æœ€æ–°çš„è¡Œä¸ºè®°å½•ã€‚
    seq_type:str = 'long'   # ç”¨æˆ·å†å²åºåˆ—ç±»å‹

    max_item_num: int = 40  # 20    # æœ€å¤šä½¿ç”¨å¤šå°‘ä¸ª itemï¼ˆå³å†å²è¡Œä¸º item æ•°é‡ï¼‰ã€‚è¶…è¿‡çš„å°†è¢«æˆªæ–­ã€‚
    max_token_num: int = 500  # 256     # æ•´ä¸ªè¾“å…¥æ–‡æœ¬åºåˆ—çš„æœ€å¤§ token æ•°é‡ï¼ˆåŒ…æ‹¬æ‰€æœ‰ item çš„ title/desc æ‹¼æ¥ä¹‹åï¼‰ï¼Œæ§åˆ¶è¾“å…¥é•¿åº¦ã€‚
    max_infor_len: int = 50				# å•ä¸ª item 
    sample_item_num: int = 30  # 10     # å¯¹äºæ¯ä¸ªç”¨æˆ·ï¼Œæœ€å¤šé‡‡æ ·è¿™ä¹ˆå¤šä¸ªç‰©å“æ¥åšè®­ç»ƒã€‚

    id_len: int = 3

    neg_p: float = 0.2
    neg_ty:int = 2

    consim_k:int = 500
    consim_file:str = 'similar_items_lam087.json'

    # è¯¥å‡½æ•°æ ¹æ® seq_typeï¼ˆåºåˆ—ç±»å‹ï¼‰åŠ¨æ€è°ƒæ•´ä¸€äº›é•¿åº¦ç›¸å…³çš„å‚æ•°ã€‚
    def update_for_type(self):
        if self.seq_type == 'mlshort':
            self.max_item_num: int = 40
            self.max_token_num: int = 256
            self.max_infor_len: int = 30   # 30
            self.sample_item_num: int = 20

        elif self.seq_type == 'micshort':
            self.max_item_num: int = 20
            self.max_token_num: int = 256
            self.max_infor_len: int = 35  #  30
            self.sample_item_num: int = 15
        elif self.seq_type != 'long':
            self.max_item_num: int = 20
            self.max_token_num: int = 256
            self.max_infor_len: int = 30
            self.sample_item_num: int = 10
```

äº‹å®ä¸Šï¼Œå½“æˆ‘ä»¬å†™ä¸Š

```python
from dataclasses import dataclass
@dataclass
class DataProcessConfig:
    ...

```

ç­‰ä»·äºåœ¨æ‰‹åŠ¨å†™ï¼š

```python
class DataProcessConfig:
    def __init__(self, atom_pad='<extra_id_0>', atom_user_pad='<extra_id_1>', ..., consim_file='similar_items_lam087.json'):
        self.atom_pad = atom_pad
        self.atom_user_pad = atom_user_pad
        ...

```

ä¹Ÿå°±æ˜¯è¯´

> `@dataclass` ä¼šè‡ªåŠ¨ä¸ºä½ æ ¹æ®ç±»ä¸­å®šä¹‰çš„å­—æ®µç”Ÿæˆä¸€ä¸ª `__init__()` æ–¹æ³•ï¼Œå¹¶è‡ªåŠ¨èµ‹å€¼ã€‚

é™¤äº† `__init__()`ï¼Œå®ƒè¿˜ä¼šè‡ªåŠ¨ç”Ÿæˆ

| æ–¹æ³•å       | ä½œç”¨                                                     |
| ------------ | -------------------------------------------------------- |
| `__init__()` | è‡ªåŠ¨åˆå§‹åŒ–å±æ€§                                           |
| `__repr__()` | æ‰“å°æ—¶è‡ªåŠ¨å±•ç¤ºå­—æ®µ                                       |
| `__eq__()`   | ä¸¤ä¸ªå®ä¾‹èƒ½æ¯”è¾ƒæ˜¯å¦ç›¸ç­‰                                   |
| `__hash__()` | å¯ä½œä¸º dict key ç­‰å“ˆå¸Œå¯¹è±¡ï¼ˆå¦‚æœä½ è®¾ç½®äº† `frozen=True`ï¼‰ |



å›åˆ°è¿™ä¸ªå…·ä½“çš„ç±»ï¼Œå®ƒå®ç°çš„åŠŸèƒ½å¾ˆæ˜ç¡®ï¼Œæˆ‘ä»¬è¿™ä¸ªç±»ç›¸å½“äºæ˜¯ä¸€ä¸ªé…ç½®å¯¹è±¡ï¼ˆConfig classï¼‰ï¼Œç”¨äº**é…ç½®åˆ†è¯å™¨çš„ç›¸å…³å‚æ•°ã€‚**



#### ç†è§£ä»£ç ä¹‹ç†è§£è£…é¥°å™¨ `@classmethod`

`@classmethod` æ˜¯ Python ä¸­ä¸€ç§ç‰¹æ®Šçš„ç±»æ–¹æ³•è£…é¥°å™¨ï¼Œç”¨æ¥æ ‡è®°==æŸä¸ªæ–¹æ³•**ä½œç”¨äºç±»æœ¬èº«ï¼ˆ`cls`ï¼‰è€Œä¸æ˜¯å®ä¾‹ï¼ˆ`self`ï¼‰**==ã€‚==å®ƒå¯ä»¥è®¿é—®**ç±»å±æ€§ï¼ˆï¼‰è¦æ³¨æ„åŒºåˆ†ç±»å±æ€§å’Œå®ä¾‹å±æ€§ï¼‰**æˆ–åˆ›å»º**ç±»çš„å®ä¾‹**ï¼Œä½†ä¸èƒ½ç›´æ¥è®¿é—®å®ä¾‹å˜é‡ã€‚==

| ç‰¹æ€§           | `@classmethod`                                  |
| -------------- | ----------------------------------------------- |
| ä½œç”¨å¯¹è±¡       | ç±»æœ¬èº«ï¼ˆ`cls`ï¼‰                                 |
| **ç¬¬ä¸€ä¸ªå‚æ•°** | `cls`ï¼ˆè¡¨ç¤ºå½“å‰ç±»ï¼‰                             |
| å¸¸ç”¨äº         | è‡ªå®šä¹‰æ„é€ å™¨ã€ä»é…ç½®/è·¯å¾„åˆå§‹åŒ–å¯¹è±¡ã€å·¥å‚æ–¹æ³•ç­‰ |
| ä¸èƒ½åšçš„       | è®¿é—®å®ä¾‹å±æ€§ï¼ˆå› ä¸ºæ²¡æœ‰ `self`ï¼‰                 |

æˆ‘ä»¬ä»¥ `class V4T5Tokenizer(T5TokenizerV1)` ä¸­çš„ç›¸å…³ä»£ç ä½œè¯´æ˜

```python
@classmethod
def from_pretrained(cls, pretrained_model_name_or_path,config=None,new_vob=None):
    # cls.config = config # ç›¸è¾ƒäºåŸæœ¬çš„tokenizerï¼Œä¼šæŠŠconfigåŠ è¿›æ¥
    # å¦‚æœæœ‰æ–°çš„å•è¯ï¼Œä¼šæ·»åŠ åˆ°tokenizerä¸­
    tokenizer = super().from_pretrained(pretrained_model_name_or_path,config=config)
    # å…³é”®ï¼šæ‰‹åŠ¨ç»‘å®š config åˆ°å®ä¾‹ä¸Š
    tokenizer.config = config
    tokenizer.atom_pad = config.atom_pad
    tokenizer.atom_pad_id = tokenizer.convert_tokens_to_ids(config.atom_pad)
    tokenizer.atom_user_pad = config.atom_user_pad
    tokenizer.atom_user_pad_id = tokenizer.convert_tokens_to_ids(config.atom_user_pad)
    if new_vob is not None:
        tokenizer.add_tokens(sorted(new_vob))
        return tokenizer
```

ä¸ªäººç†è§£ï¼š

> ä½¿ç”¨è¿™ä¸ª `@classmethod` æ˜¯åœ¨æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªç±»æ—¶å…ˆå¼ºè¡Œåˆ›é€ ä¸€ä¸ªç±»çš„å®ä¾‹ï¼Œæ ¹æ®ä¼ å…¥çš„æ•°æ®æ›´æ”¹è¿™ä¸ªä»çˆ¶ç±»ç»§æ‰¿çš„å®ä¾‹çš„ä¸€äº›å±æ€§ï¼Œæœ€åè¿”å›è¿™ä¸ªå®ä¾‹ï¼Œè¿™æ ·æˆ‘ä»¬æ‹¿åˆ°çš„å°±æ˜¯ä¸€ä¸ª**å¸¦æœ‰ç‰¹æ®Šè¡Œä¸ºçš„ tokenizer**

äº‹å®ä¸Šï¼Œæˆ‘ä»¬**å½“ç„¶å¯ä»¥ç”¨ `__init__()` + `super()` + `self` æ¥åšå®ä¾‹åˆå§‹åŒ–ï¼Œä½†è¿™ä¸æ¨è**ï¼Œå°¤å…¶åœ¨ HuggingFace çš„æ¡†æ¶ä¸­ã€‚

1. å› ä¸ºHuggingFace æ„é€ æ–¹å¼æœ¬èº«æ˜¯â€œåä¼ ç»Ÿâ€çš„ï¼

   HuggingFace å…¨å®¶æ¡¶ç»Ÿä¸€ç”¨ **`from_pretrained()` å·¥å‚æ–¹æ³•**ï¼Œä¸ç›´æ¥ç”¨ `__init__()` æ„é€ ï¼š

   æˆ‘ä»¬å†™ä»£ç çš„æ—¶å€™å¯ä»¥æ˜ç¡®æ„Ÿå—åˆ°ï¼Œ`tokenizer` å’Œ `model` çš„å®ä¾‹æ˜¯é€šè¿‡ `.from_pretrained()` è¿›è¡Œæ„é€ çš„ï¼Œè€Œéä¼ ç»Ÿçš„ `__init__()`

   ```python
   tokenizer = T5Tokenizer.from_pretrained("t5-small")
   model = T5ForConditionalGeneration.from_pretrained("t5-small")
   ```

2. ä½ ä¸çŸ¥é“ `__init__()` è¦ä¼ ä»€ä¹ˆå‚æ•°

   HuggingFace çš„ `__init__()` æ¥æ”¶çš„å‚æ•°éå¸¸å¤æ‚ï¼Œè€Œä¸”æ–‡æ¡£æ²¡æœ‰åˆ—å‡ºå…¨éƒ¨å‚æ•°ã€‚ä¾‹å¦‚ `T5Tokenizer.__init__()` æ¥æ”¶çš„å‚æ•°æœ‰ï¼š

   ```bash
   vocab_file, merges_file, errors, unk_token, bos_token, eos_token, pad_token, ...
   ```

   ä½ å¾ˆå¯èƒ½ä¸çŸ¥é“è¦ä¼ å“ªäº›ï¼Œæ¼ä¸€ä¸ªå°±å´©ã€‚

   è€Œ `from_pretrained()` å¸®ä½ **è‡ªåŠ¨ä»ç£ç›˜åŠ è½½ vocab.json / config.json / tokenizer_config.json**ï¼Œä½ åªéœ€è¦ç»™æ¨¡å‹åã€‚ï¼ˆå½“ç„¶ï¼ŒåŠ è½½çš„è¿™äº›æ–‡ä»¶å½“ç„¶ä¹ŸåŒ…æ‹¬ `__init__()` æ¥å—çš„ `vocab_file`, `merges_file`, `errors`, `unk_token` ç­‰è¿™äº›å‚æ•°ã€‚å¦‚æœæˆ‘ä»¬è‡ªå·±å†™ `__init__()` çš„è°ƒç”¨ï¼Œå¾ˆå®¹æ˜“æ¼ã€‚ï¼‰

   > `from_pretrained()` æ˜¯å®˜æ–¹æ¨èçš„æ ‡å‡†æ„é€ å…¥å£
   >
   > å®ƒè‡ªåŠ¨åŠ è½½é…ç½®ã€vocabã€æƒé‡ã€pad token ç­‰å¤æ‚å†…å®¹
   >
   > é‡å†™ `from_pretrained()` æ›´å®‰å…¨ã€æ›´ç®€æ´ã€æ›´ç¨³å®š

##### `from_pretrained()` ä¼šåšå“ªäº›äº‹æƒ…ï¼Ÿ

å…¶å®å…³äºè¿™é‡Œçš„**æ„é€ å®ä¾‹**ï¼Œæˆ‘ä»¬åªéœ€è¦ç†è§£ `from_pretrained()` ä¼šåšå“ªäº›äº‹æƒ…ï¼Ÿä»¥åŠå®ƒå’Œ `__init__()` çš„å…³ç³»å°±è¡Œäº†ã€‚

```python
tokenizer = T5Tokenizer.from_pretrained("t5-small")
```

**HuggingFace çš„ `from_pretrained()` ä¼šåšè¿™äº›äº‹ï¼š**

å®ƒä¼šè‡ªåŠ¨å» `cache_dir` æˆ– HuggingFace Hub åŠ è½½ä»¥ä¸‹è¿™äº›æ–‡ä»¶ï¼š

| æ–‡ä»¶å                        | å«ä¹‰                              | è¢«ä¼ ç»™å“ªä¸ªå‚æ•°                                       |
| ----------------------------- | --------------------------------- | ---------------------------------------------------- |
| `spiece.model` / `vocab.json` | è¯è¡¨æ–‡ä»¶                          | `vocab_file`                                         |
| `merges.txt`ï¼ˆç”¨äº BPEï¼‰      | mergeè§„åˆ™                         | `merges_file`                                        |
| `tokenizer_config.json`       | é¢å¤– tokenizer é…ç½®               | `errors`, `add_prefix_space`, `tokenizer_class`, ... |
| `config.json`                 | æ¨¡å‹ç»“æ„çš„ config                 | ä¼ ç»™æ¨¡å‹ `from_pretrained`                           |
| `special_tokens_map.json`     | å®šä¹‰ `[PAD]`, `[UNK]`, `[CLS]` ç­‰ | ä¼ ç»™ `unk_token`, `pad_token`, ...                   |

ç„¶åè‡ªåŠ¨**å¡åˆ° `__init__()` æ‰€éœ€è¦çš„å‚æ•°é‡Œ**ï¼Œå¸®ä½ å®Œæˆåˆå§‹åŒ–ã€‚

è‹¥æˆ‘ä»¬æ‰‹åŠ¨æ„é€  `__init__()` åˆ™æˆ‘ä»¬è¦è‡ªå·±å†™ï¼š

```python
tokenizer = T5Tokenizer(
    vocab_file="./xxx/spiece.model",
    pad_token="<pad>",
    eos_token="</s>",
    unk_token="<unk>",
    extra_ids=100,
    ...
)
```

> ä½†æˆ‘ä»¬ï¼š
>
> - å¯èƒ½æ¼æ‰å¿…é¡»ä¼ çš„å‚æ•°ï¼ˆæ¯”å¦‚ `unk_token`, `pad_token`ï¼‰
> - ä¸çŸ¥é“å“ªä¸ªè·¯å¾„æ˜¯ vocabï¼Œå“ªä¸ªæ˜¯ merge
> - ä¸çŸ¥é“è¦ä¸è¦è®¾ç½® `add_prefix_space`
> - ä¸èƒ½è‡ªåŠ¨åŠ è½½ `tokenizer_config.json`ï¼Œå¯¼è‡´è¡Œä¸ºé”™ä¹±
> - ä»¥åä¹Ÿä¸èƒ½ç”¨ `.save_pretrained()` å’Œ `.from_pretrained()` æ¢å¤è¿™ä¸ªå¯¹è±¡



##### å·¥å‚æ–¹æ³•

å·¥å‚æ–¹æ³•æ˜¯ç”¨æ¥â€œå°è£…å¯¹è±¡åˆ›å»ºè¿‡ç¨‹â€çš„ä¸€ç§è®¾è®¡æ¨¡å¼ï¼Œç›®çš„æ˜¯**é€šè¿‡ä¸€ä¸ªç±»æ–¹æ³•**ï¼ˆè€Œä¸æ˜¯ `__init__()`ï¼‰æ¥çµæ´»ã€å®‰å…¨åœ°**åˆ›å»ºç±»çš„å®ä¾‹**ã€‚

| ç‰¹å¾                    | è¯´æ˜                                       |
| ----------------------- | ------------------------------------------ |
| ä¸æ˜¯ç›´æ¥ç”¨ `__init__()` | è€Œæ˜¯å®šä¹‰ä¸€ä¸ª**ç±»æ–¹æ³•**æ¥åˆ›å»ºå¯¹è±¡           |
| ç”¨ `cls` ä»£æ›¿ `self`    | ç¬¬ä¸€ä¸ªå‚æ•°æ˜¯ `cls`ï¼Œå¯ä»¥åˆ›å»ºå½“å‰ç±»çš„å¯¹è±¡   |
| **å¯ä»¥åšé¢„å¤„ç†**        | åœ¨åˆ›å»ºå¯¹è±¡å‰åšå‡†å¤‡ï¼Œæ¯”å¦‚è¯»å–æ–‡ä»¶ã€å¤„ç†é…ç½® |
| è¿”å›å®ä¾‹                | æœ€ç»ˆè¿”å› `cls(...)` åˆ›å»ºçš„å¯¹è±¡             |
| å¯ç”¨äºç»§æ‰¿              | å­ç±»é‡å†™åè¿”å›å­ç±»å¯¹è±¡ï¼Œä¸ç ´åå¤šæ€         |

ä¸€ä¸ªæœ€ç®€å•çš„ä¾‹å­ï¼š

```python
class User:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    @classmethod
    def from_string(cls, s):
        name, age = s.split(',')
        return cls(name, int(age))

# ç”¨å·¥å‚æ–¹æ³•åˆ›å»ºå®ä¾‹
user = User.from_string("Alice,25")

print(user.name)  # Alice
print(user.age)   # 25
```

è¿™ä¸ª `from_string()` å°±æ˜¯ä¸€ä¸ªå…¸å‹çš„å·¥å‚æ–¹æ³•ï¼Œç”¨æ¥ **â€œè§£æå­—ç¬¦ä¸² -> åˆ›å»ºå¯¹è±¡â€**ï¼Œè€Œä¸æ˜¯ä½ æ‰‹åŠ¨ä¼ å…¥ name å’Œ ageã€‚

| æ„é€ æ–¹å¼                | ç‰¹ç‚¹                                                     |
| ----------------------- | -------------------------------------------------------- |
| `__init__()`            | åŸºç¡€æ„é€ ï¼Œå¿…é¡»ä¼ å…¥æ‰€æœ‰å‚æ•°                               |
| `@classmethod` å·¥å‚æ–¹æ³• | å°è£…æ„é€ é€»è¾‘ï¼Œæ›´çµæ´»ï¼Œæ¯”å¦‚ä»æ–‡ä»¶ã€é…ç½®ã€æ•°æ®åº“ä¸­åŠ è½½å‚æ•° |

##### HuggingFace ç”¨çš„æ˜¯å·¥å‚æ–¹æ³•

`from_pretrained()` æ˜¯ HuggingFace ä¸­çš„å·¥å‚æ–¹æ³•å…¸èŒƒï¼š

```python
model = T5ForConditionalGeneration.from_pretrained("t5-small")
tokenizer = T5Tokenizer.from_pretrained("t5-small")
```

å†…éƒ¨åšäº†ï¼š

- è‡ªåŠ¨ä¸‹è½½æ¨¡å‹/è¯è¡¨æ–‡ä»¶
- åŠ è½½ config
- åˆå§‹åŒ–ç‰¹æ®Š token
- è‡ªåŠ¨è°ƒç”¨ `__init__()` å¹¶è¿”å›å®ä¾‹

å¦‚æœä½ è¦å¤å†™ `from_pretrained()`ï¼Œå°±å¯ä»¥ï¼š

- åŠ å…¥è‡ªå®šä¹‰é€»è¾‘ï¼ˆå¦‚æ·»åŠ æ–°è¯ã€ç»‘å®š configã€è®¾ç½®ç‰¹å®šå‚æ•°ï¼‰
- åˆä¸ç ´ååŸæœ‰ç»“æ„



å¦å¤–æé†’ä¸€ç‚¹ï¼šæˆ‘ä»¬ä¹Ÿéœ€è¦åŒºåˆ†å®ä¾‹å˜é‡å’Œç±»å˜é‡ï¼Œå…³æ³¨è¿™ä¸¤è€…çš„åŒºåˆ«





#### ç†è§£æ•°æ®é›†ä¸æ•°æ®å¤„ç†å™¨å’Œæ•°æ®è£…è½½å™¨

##### æ•°æ®å¤„ç†æµç¨‹ `get_train_dataloader_augitem()`

é¦–å…ˆæˆ‘ä»¬ä½¿ç”¨çš„æ•°æ®ä¸º `corpus_512.json` è¿™ä¸ªæ–‡ä»¶ä¸­çš„æ•°æ®ï¼Œåœ¨ä»£ç ä¸­ä½“ç°ä¸º `item_corpus`ã€‚ï¼ˆè¿™é‡Œçš„ `atom_id` å’Œä¸‹æ–‡çš„ `item_id` æ˜¯ä¸€ä¸€å¯¹åº”èµ·æ¥çš„ï¼‰å…¶ä¸­ç¬¬ 2 æ¡æ•°æ®ä¸º

```json
  "2": {
    "atom_id": 2,
    "cid": [
      26,
      10,
      1
    ],
    "content": "title PowerBear&reg; Samsung Galaxy S4 Battery Case - White (Double Your Power) categories Accessories Batteries Battery Charger Cases External Battery Packs Cases Basic Cases"
  },
```

è¿™é‡Œçš„ `cid` å’Œæ–‡æ¡£ 5.4 èŠ‚ä¸­ â€œGID é•¿åº¦è®¾ä¸º 3â€ çš„å®éªŒè®¾ç½®ä¸€è‡´3ã€‚åŒæ—¶ï¼ŒGID ç”±å±‚æ¬¡åŒ– K-means èšç±»ç”Ÿæˆï¼ˆ4.2 èŠ‚ï¼‰ï¼Œè€Œ`cid`çš„æ•°å€¼åºåˆ—ç¬¦åˆç°‡ ID çš„ç‰¹å¾ï¼Œè¯´æ˜å…¶æ˜¯é€šè¿‡é¢„å¤„ç†æ­¥éª¤ï¼ˆå¦‚åŸºäº LightGCN çš„ç‰©å“è¡¨ç¤ºèšç±»ï¼‰å¾—åˆ°çš„ç”Ÿæˆå¼æ ‡è¯†ç¬¦

æ•°æ®ä¸­ä¹Ÿç»™å‡ºäº†åŸå­ id ï¼ˆ`atom_id`ï¼‰å”¯ä¸€æ ‡è¯† `item `ï¼Œä¹Ÿæä¾›äº†æ–‡æœ¬å±æ€§ `content`

* `train_time_inter.csv`

  ```bash
          user_id  item_id        time
  0         22512     7500  1396396800
  1         22512     9306  1396396800
  2         22512     5323  1386028800
  3         22512     9065  1396396800
  4          2016     4554  1371859200
  ...         ...      ...         ...
  137272    18431     2462  1343088000
  137273    18431     7891  1380758400
  137274    16255     5019  1392940800
  137275    16255     4008  1392595200
  137276    16255     1943  1392595200
  
  [137277 rows x 3 columns]
  ```

æˆ‘ä»¬ä¼šé¦–å…ˆè¯»å–è¿™ä¸ªæ•°æ®ï¼ˆ`train_time_inter.csv`ï¼‰ä½œä¸ºäº¤äº’æ•°æ®æ–‡ä»¶ `inter_file` å¹¶**ä»ä¸­**ä¾æ¬¡è·å–ä»¥ä¸‹ä¸‰ç±»æ•°æ®

1.  `user_seq`

   `{user1: [item11, item12, ..., item1n], user2: [...], userm: [...]}`

   è¿™é‡Œçš„ `item` æ˜¯**æŒ‰äº¤äº’æ—¶é—´æ’å¥½åºçš„**ï¼ï¼ï¼

2. `inter_list`

   å°±æ˜¯å¸¸è§çš„é€šè¿‡ `zip` å°†`user_id` å’Œ `item_id` ä» `inter_file` ä¸­æå–å‡ºæ¥ï¼Œå…¶å®å°±æ˜¯ä¸€ä¸ªåŸºäºå†å²ä¿¡æ¯çš„**ååŒçŸ©é˜µ**

   `[[user1, item1], [user2, item2], ..., [usern, itemn]]`

3. `item_seq`

   `{item1: [user11, user12, ..., user1n], item2: [...], ..., itemm: [...]}`



æ¥ä¸‹æ¥æˆ‘ä»¬ä¼šè·å– `cid_neg_dit` è¿™ä»½æ•°æ®ï¼Œå®ƒå¯ä»¥ç†è§£ä¸ºå­˜å‚¨ç‰©å“è´Ÿæ ·æœ¬ç´¢å¼•çš„å­—å…¸ï¼Œç”¨äº ColaRec æ¨¡å‹è®­ç»ƒä¸­çš„æŸå¤±è®¡ç®—ï¼ˆå¦‚ BPR æ’åºæŸå¤±å’Œå¯¹æ¯”æŸå¤±ï¼‰ï¼Œå…·ä½“è§£æå¦‚ä¸‹ï¼š

> - é”®ï¼ˆå¦‚ `"1"`ã€`"2"` ç­‰ï¼‰ï¼šä»£è¡¨ç›®æ ‡ç‰©å“çš„æ ‡è¯†ç¬¦ï¼ˆå¯èƒ½å¯¹åº”ç‰©å“çš„ `atom_id` æˆ–ç´¢å¼•ï¼‰ã€‚
> - `"fst"`å’Œ `"sec"`åˆ—è¡¨ï¼šå­˜å‚¨ä¸ç›®æ ‡ç‰©å“å¯¹åº”çš„è´Ÿæ ·æœ¬ç‰©å“çš„æ ‡è¯†ç¬¦ï¼ˆæ•°å­—åºåˆ—ï¼‰ï¼Œæ¨æµ‹åˆ†åˆ«å¯¹åº”ä¸¤ç§ä¸åŒæŸå¤±å‡½æ•°æ‰€éœ€çš„è´Ÿæ ·æœ¬ï¼š
>   - `"fst"`ï¼ˆfirst çš„ç¼©å†™ï¼‰ï¼šå¯èƒ½å¯¹åº” BPR æ’åºæŸå¤±ä¸­ä½¿ç”¨çš„è´Ÿæ ·æœ¬ã€‚æ–‡æ¡£ 4.5 èŠ‚æåˆ°ï¼ŒBPR æŸå¤±ä¸ºæ¯ä¸ªæ­£æ ·æœ¬å¯¹ `(u,i)` éšæœºé‡‡æ ·ç”¨æˆ· `u` æœªäº¤äº’è¿‡çš„ç‰©å“ `iâ»` ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œç›®çš„æ˜¯ä¼˜åŒ–ç‰©å“æ’åºï¼Œä½¿æ­£æ ·æœ¬è¯„åˆ†é«˜äºè´Ÿæ ·æœ¬ã€‚
>   - `"sec"`ï¼ˆsecond çš„ç¼©å†™ï¼‰ï¼šå¯èƒ½å¯¹åº”å¯¹æ¯”æŸå¤±ä¸­ä½¿ç”¨çš„è´Ÿæ ·æœ¬ã€‚æ–‡æ¡£ 4.5 èŠ‚æŒ‡å‡ºï¼Œå¯¹æ¯”æŸå¤±è¦æ±‚è´Ÿæ ·æœ¬ `iâ»` ä¸ç›®æ ‡ç‰©å“ `i` çš„ GID æ— é‡å å‰ç¼€ï¼Œä»¥ç¡®ä¿ GID ç›¸ä¼¼çš„ç‰©å“åœ¨å†…å®¹ç©ºé—´ä¹Ÿç›¸ä¼¼ï¼Œå› æ­¤è¿™äº›è´Ÿæ ·æœ¬éœ€æ»¡è¶³ä¸ç›®æ ‡ç‰©å“çš„ GID æ— å…³è”æ€§ã€‚



æˆ‘ä»¬å°†ä»¥ä¸Šæ•°æ®å°è£…åˆ°ä¸€ä¸ªæ•°æ®é›†ï¼Œå¹¶å°†å…¶è£…å…¥ä¸€ä¸ªæ•°æ®è£…è½½å™¨

```python
dataset = v7CL2TrainDataset(inter_list, user_seq,item_seq,item_corpus,
                                pro_config, tokenizer,cid_neg_dict)

dataloader = DataLoader(dataset, batch_size=batch_size,
                            collate_fn=dataset.collate_fn,shuffle=True,num_workers=num_workers)
```

è¿™é‡Œçš„æ ¸å¿ƒä»»åŠ¡æ˜¯==**ä¸ºå¤šä»»åŠ¡è®­ç»ƒæ„å»ºæ ·æœ¬**==ã€‚



##### `Dataset` ä¹‹ `BasedTrainDataset(Dataset)`

* `__init__(self)`

  1. è·å–äº¤äº’è¡¨ `inter_list` `self.dataset = linter_list`
  2. è·å–ç”¨æˆ·åˆ—è¡¨ `user_seq`
  3. è·å–è¯­æ–™åº“ `item_corpus`
  4. è·å–ä¸€äº›ç›¸å…³çš„é…ç½® `pro_config`
  5. è·å–åˆ†è¯å™¨ `tokenizer`

* `__len__(self)`

  è·å–çš„æ˜¯æ•´ä¸ªäº¤äº’è¡¨çš„é•¿åº¦

  `return len(self.dataset)`

* `__getitem__(self, idx)` ï¼ˆæ ¸å¿ƒï¼‰

  é¦–å…ˆéœ€è¦æ˜ç¡®çš„æ˜¯ï¼Œæˆ‘ä»¬æ˜¯ä¸ºå¤šä»»åŠ¡è®­ç»ƒæ„å»ºæ ·æœ¬ï¼å› æ­¤æˆ‘ä»¬åŠ¡å¿…è¦çŸ¥é“**è¿”å›é‚£äº›æ•°æ®**

  ```python
  return {
      'item_content': pos_item_content,       # æ­£æ ·æœ¬ item çš„æ–‡æœ¬
      'item_atomid': pos_item_atomid,         # æ­£æ ·æœ¬ item çš„ atom_id
      'neg_item_content': neg_item_content,   # è´Ÿæ ·æœ¬ item çš„æ–‡æœ¬
      'neg_item_atomid': neg_item_atomid,     # è´Ÿæ ·æœ¬ item çš„ atom_id
      # ç”¨æˆ·å†å²(è¿™é‡Œçš„å†å²è®°å½•å¯èƒ½ä¼šè¢«é‡‡æ ·æœ€å¤§é•¿åº¦æˆªæ–­)item æ–‡æœ¬ï¼ˆåœ¨è¿™é‡Œå…¶å®æ˜¯é€šè¿‡é™¤æ­£æ ·æœ¬ä¹‹å¤–å…¶ä»– item çš„æ–‡æœ¬å†…å®¹æ‹¼æ¥è€Œæˆï¼‰
      'user_content': user_content,           
      'user_atomid_list': user_atomid_list,   # ç”¨æˆ·å†å² item atom_id
      'neg_label_item': neg_label_item,       # è´Ÿæ ·æœ¬çš„ labelï¼ˆcidï¼‰
      'label_item': label_item                # æ­£æ ·æœ¬çš„ labelï¼ˆcidï¼‰
  }
  ```

  

* `collate_fn(self, batch_data)`

  è¿™äº›å…ˆä¸çœ‹äº†ã€‚ã€‚ç›´æ¥çœ‹æœ€ç»ˆç‰ˆæœ¬ `v7CL2TrainDataset`



##### `Dataset` ä¹‹ `v7CL2TrainDataset()`

* `__init__()`

  ```python
  def __init__(self,
               inter_list, user_seq, item_seq,
               item_corpus,
               process_config,
               tokenizer,cid_neg_dict):
      super(v7CL2TrainDataset, self).__init__(inter_list, user_seq,item_seq,
                                              item_corpus,process_config,
                                              tokenizer)
  
      self.cid_neg_dict = cid_neg_dict
  ```

  ç»§æ‰¿äº†ä»¥å‰çš„ä¸œè¥¿

* `__gititem__()`

  `idx` é’ˆå¯¹çš„æ˜¯äº¤äº’åˆ—è¡¨æ•°æ®ï¼Œå› ä¸ºæˆ‘ä»¬çš„ä»»åŠ¡æ˜¯==æ¨¡å‹åŸºäºçº¯ç²¹çš„å†å²äº¤äº’ä¿¡æ¯é¢„æµ‹ç›®æ ‡ç‰©å“==ã€‚æ‰€ä»¥å®é™…ä¸Šï¼Œå¯¹åº”çš„ `item` å…¶å®å°±æ˜¯æˆ‘ä»¬çš„ç›®æ ‡                                                                                                                                                                                                                                                                                    

  è¿”å›ä¸€ä¸ªå­—å…¸å½¢å¼ã€‚

  é‚£ä¹ˆæ¯ä¸€ä¸ª batch_data çš„å½¢å¼å°±æ˜¯ä¸€ä¸ªåˆ—è¡¨é‡Œé¢å¥—å­—å…¸ï¼Œä¹Ÿå°±æ˜¯è¿™æ ·

  `[dic_1, dic_2, ..., dic_B]`

  ```python
  return {
      # æ­£æ ·æœ¬ç‰©å“çš„æ–‡æœ¬å†…å®¹ä¿¡æ¯ï¼ˆå¦‚æ ‡é¢˜ã€å“ç‰Œç­‰ï¼‰ï¼Œå¯¹åº”è®ºæ–‡ä¸­ç‰©å“çš„å†…å®¹æè¿°c_i
      'item_content': pos_item_content,
      # æ­£æ ·æœ¬ç‰©å“çš„åŸå­IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰ï¼Œå¯¹åº”è®ºæ–‡ä¸­çš„iad
      'item_atomid': pos_item_atomid,
      # å¯¹æ¯”å­¦ä¹ ä¸­æ­£æ ·æœ¬ç‰©å“ï¼ˆä¸ç›®æ ‡ç‰©å“GIDå‰ç¼€é‡å ï¼‰çš„æ–‡æœ¬å†…å®¹ï¼Œç”¨äºæ„å»ºå†…å®¹è¯­ä¹‰ç›¸ä¼¼æ€§
      'aug_item_content': aug_item_content,
      # å¯¹æ¯”å­¦ä¹ ä¸­æ­£æ ·æœ¬ç‰©å“çš„åŸå­IDï¼Œå¯¹åº”è®ºæ–‡ä¸­ç”¨äºå¯¹æ¯”æŸå¤±è®¡ç®—çš„i+çš„æ ‡è¯†
      'aug_item_atomid': aug_item_atomid,
      # è´Ÿæ ·æœ¬ç‰©å“çš„æ–‡æœ¬å†…å®¹ä¿¡æ¯ï¼Œç”¨äºBPRæŸå¤±å’Œå¯¹æ¯”æŸå¤±ä¸­çš„è´Ÿä¾‹
      'neg_item_content': neg_item_content,
      # è´Ÿæ ·æœ¬ç‰©å“çš„åŸå­IDï¼Œå¯¹åº”è®ºæ–‡ä¸­BPRæŸå¤±çš„i-å’Œå¯¹æ¯”æŸå¤±çš„è´Ÿä¾‹æ ‡è¯†
      'neg_item_atomid': neg_item_atomid,
      'user_content': user_content,
      # ç”¨æˆ·å†å²äº¤äº’ç‰©å“çš„å†…å®¹èšåˆï¼ˆå·²å‰”é™¤å½“å‰ç›®æ ‡ç‰©å“ï¼‰ï¼Œç”¨äºè¡¨ç¤ºç”¨æˆ·åå¥½ï¼Œå¯¹åº”è®ºæ–‡ä¸­ç”¨æˆ·çš„å†…å®¹èšåˆè®¾è®¡
      'user_atomid_list': user_atomid_list,
      # è´Ÿæ ·æœ¬ç‰©å“çš„æ ‡ç­¾ä¿¡æ¯ï¼ˆå¦‚ç±»åˆ«ï¼‰ï¼Œè¾…åŠ©æŸå¤±è®¡ç®—
      'neg_label_item': neg_label_item,
      # æ­£æ ·æœ¬ç‰©å“çš„æ ‡ç­¾ä¿¡æ¯ï¼ˆå¦‚ç±»åˆ«ï¼‰ï¼Œä½œä¸ºè®­ç»ƒç›®æ ‡ä¹‹ä¸€
      'label_item': label_item,
      # ä¸æ­£æ ·æœ¬ç‰©å“äº¤äº’è¿‡çš„ç”¨æˆ·åŸå­IDï¼Œç”¨äºå¢å¼ºååŒä¿¡å·ï¼Œå¯¹åº”è®ºæ–‡ä¸­ç‰©å“ç´¢å¼•ä»»åŠ¡çš„äº¤äº’ç”¨æˆ·ä¿¡æ¯
      'item_user_atomids': pos_user_atomids,
      'aug_item_user_atomids': aug_user_atomids,
      # ä¸è´Ÿæ ·æœ¬ç‰©å“äº¤äº’è¿‡çš„ç”¨æˆ·åŸå­IDï¼Œç”¨äºå¼ºåŒ–è´Ÿä¾‹çš„åŒºåˆ†æ€§
      'neg_item_user_atomids': neg_user_atomids
  }
  ```

  è‡ªå·±åœ¨è„‘æµ·é‡Œè¿‡ä¸€éæ•´ä¸ªé€šè¿‡ç´¢å¼• `idx` è·å–ç›¸å…³æ•°æ®çš„æµç¨‹æ˜¯æ€æ ·çš„ï¼



* `collate_fn(self, batch)`

  ```python
  def collate_fn(self, batch_data):
      # é¦–å…ˆï¼Œå…ˆåˆ©ç”¨ çˆ¶ç±» çš„ `collate_fn` æ–¹æ³•è¿›è¡Œé¢„å¤„ç†
      user_input_dict, pos_input_dict, neg_input_dict, labels, neg_labels = super(v7CL2TrainDataset, self).collate_fn(
          batch_data)
  
      aug_input_dict = self.tokenizer([data['aug_item_content'] for data in batch_data],return_tensor=True,ty='item')
      aug_input_dict['atom_input_ids'] = torch.LongTensor([data['aug_item_atomid'] for data in batch_data])
      aug_input_dict['user_atom_ids'] = torch.LongTensor([data['aug_item_user_atomids'] for data in batch_data])
  
      return user_input_dict, pos_input_dict, neg_input_dict, labels, neg_labels,aug_input_dict
  ```

  çˆ¶ç±»æ–¹æ³•å¦‚ä¸‹ï¼š

  ```python
  ```

  





#### ç†è§£ä»£ç ä¹‹ç†è§£æ¨¡å‹

* å‰ç½®éœ€è¦ç†Ÿæ‚‰çš„
  * `T5PreTrainedModel`
  * `T5Stack`





é¦–å…ˆæ¥ç†è§£ä¸€ä¸‹æ¨¡å‹ç»“æ„çš„æ ¸å¿ƒ

> **è¾“å…¥å†…å®¹ï¼ˆç”¨æˆ·å†…å®¹ï¼‰**ï¼šè‹¥å¹²ä¸ª item çš„å†…å®¹+åŸå­ IDï¼ˆitem_idï¼‰ã€ä½ç½®åµŒå…¥ç­‰ã€‚
>
> **è¾“å‡ºåºåˆ—ï¼ˆç›®æ ‡ GIDï¼‰**ï¼šä½¿ç”¨ decoder é€ token ç”Ÿæˆã€‚
>
> **è®­ç»ƒç›®æ ‡**ï¼šåŒ…æ‹¬æ¨èæŸå¤± (`L_rec`)ã€ç´¢å¼•ä»»åŠ¡æŸå¤± (`L_index`)ã€BPR æ’åºæŸå¤± (`L_bpr`)ã€å¯¹æ¯”å­¦ä¹ æŸå¤± (`L_c`)ã€‚

ä¹Ÿå°±æ˜¯è¯´è®ºæ–‡ä¸­çš„ `4.3 User-Item Recommendation` éƒ¨åˆ†é’ˆå¯¹çš„æ˜¯**æ¨¡å‹çš„è¾“å…¥**ï¼Œè€Œ `4.4 Item-Item Indexing` è¿™ä¸€éƒ¨åˆ†ä»‹ç»çš„å†…å®¹è™½ç„¶ä¹Ÿæ˜¯ä½œä¸ºæ¨¡å‹çš„è¾“å…¥è¿›å…¥ï¼Œä½†æ˜¯å…¶æ˜¯ä½œä¸º**ç›®æ ‡æ ‡ç­¾æ¥ä½¿ç”¨çš„**ï¼Œæ˜¯ä¸ºçŸ«æ­£ä¸æŒ‡å¯¼è®­ç»ƒæä¾›å¸®åŠ©çš„ã€‚è¿™ä¸€å¯¹è¾“å…¥æ˜¯é€šè¿‡äº¤äº’åˆ—è¡¨ä¸­çš„äº¤äº’è¡Œä¸ºäº§ç”Ÿè”ç³»çš„ï¼å½“ç„¶ç”¨äºè®¡ç®—æŸå¤±çš„è´Ÿæ ·æœ¬å’Œå¢å¼ºæ ·æœ¬çš„ç›¸å…³ä¿¡æ¯ä¹Ÿéƒ½ä¸€å¹¶è¾“å…¥äº†ã€‚



* é¦–å…ˆç†è§£å¯¼å…¥çš„åŒ…

  ```python
  from transformers.models.t5.modeling_t5 import (
      T5Config,
      T5Stack,
      T5Block,
      T5LayerNorm,
      T5LayerSelfAttention,
      T5LayerFF,
      T5LayerCrossAttention,
      T5PreTrainedModel,
      T5ForConditionalGeneration,
  )
  ```

  è¿™æ®µä»£ç æ˜¯ä» `transformers` åº“ä¸­ **T5 æ¨¡å‹çš„==åº•å±‚==å®ç°æ–‡ä»¶ `modeling_t5.py`** ä¸­å¯¼å…¥å¤šä¸ªç±»ï¼Œè¿™äº›ç±»æ„æˆäº† **T5 æ¨¡å‹çš„ç»„ä»¶å’Œæ•´ä½“ç»“æ„**ã€‚

  | åç§°                           | è¯´æ˜                                                         |
  | ------------------------------ | ------------------------------------------------------------ |
  | **T5Config**                   | é…ç½®ç±»ï¼Œå­˜å‚¨æ¨¡å‹çš„è¶…å‚æ•°ï¼ˆå¦‚å±‚æ•°ã€éšè—ç»´åº¦ç­‰ï¼‰ï¼Œé€šå¸¸ä» checkpoint åŠ è½½ã€‚ |
  | **T5Stack**                    | è¡¨ç¤º T5 çš„ Encoder æˆ– Decoder å †å ç»“æ„ï¼ˆtransformer block çš„é›†åˆï¼‰ã€‚ |
  | **T5Block**                    | å•ä¸ª Transformer Blockï¼ŒåŒ…æ‹¬ Attention + FFN æ¨¡å—ã€‚          |
  | **T5LayerNorm**                | T5 ç‰¹æœ‰çš„ LayerNorm å®ç°ï¼ˆä¸åŒäºæ™®é€š LayerNormï¼Œä½¿ç”¨ RMSNormï¼‰ã€‚ |
  | **T5LayerSelfAttention**       | Transformer ä¸­çš„è‡ªæ³¨æ„åŠ›æ¨¡å—ã€‚                               |
  | **T5LayerCrossAttention**      | Decoder ä¸­çš„è·¨æ³¨æ„åŠ›æ¨¡å—ï¼ˆå¯¹ Encoder çš„è¾“å‡ºåš attentionï¼‰ã€‚  |
  | **T5LayerFF**                  | Feed-forward å±‚ï¼ˆMLPéƒ¨åˆ†ï¼‰ï¼ŒTransformer çš„æ ‡å‡†ç»„æˆä¹‹ä¸€ã€‚     |
  | **T5PreTrainedModel**          | æä¾›äº†åŠ è½½é¢„è®­ç»ƒæƒé‡ã€ä¿å­˜æ¨¡å‹ç­‰é€šç”¨åŠŸèƒ½çš„åŸºç±»ã€‚             |
  | **T5ForConditionalGeneration** | å®Œæ•´çš„ T5 æ¨¡å‹ï¼Œç”¨äº**æ–‡æœ¬ç”Ÿæˆä»»åŠ¡**ï¼ˆå¦‚ç¿»è¯‘ã€æ‘˜è¦ã€å¯¹è¯ç­‰ï¼‰ã€‚**è¿™æ˜¯æœ€ç»ˆç”¨äºè®­ç»ƒå’Œæ¨ç†çš„ç±»**ã€‚ |

  ä¸ºä»€ä¹ˆç›´æ¥ä» `modeling_t5` å¯¼å…¥è¿™äº›ï¼Ÿ

  > è¿™é€šå¸¸å‡ºç°åœ¨ä»¥ä¸‹åœºæ™¯ï¼š
  >
  > 1. **è‡ªå®šä¹‰æ¨¡å‹ç»“æ„**ï¼šä½ æƒ³åŸºäº T5 çš„å†…éƒ¨æ¨¡å—è‡ªå®šä¹‰ç»“æ„ï¼ˆæ¯”å¦‚ä¿®æ”¹ SelfAttention æœºåˆ¶ã€æ›¿æ¢ FFNï¼‰ã€‚
  > 2. **æ·±å…¥è°ƒè¯• / ç†è§£æºç **ï¼šå¯¹æºç ä¸­çš„æ¯ä¸€å±‚è¿›è¡Œæ”¹å†™æˆ–æ³¨å…¥ hookã€‚
  > 3. **ç»„åˆä¸åŒç»„ä»¶æ„å»ºæ–°æ¨¡å‹**ï¼šä¾‹å¦‚ä»…ç”¨ encoder éƒ¨åˆ†ï¼Œæˆ–æ’å…¥ä¸­é—´å±‚ç­‰ã€‚

  

  ```python
  from transformers.modeling_outputs import (
      Seq2SeqLMOutput,
      BaseModelOutput
  )
  ```

  Hugging Face å¹¶ä¸ç›´æ¥è®©æ¨¡å‹ `forward()` è¿”å›ä¸€ä¸ª `tuple` æˆ– `dict`ï¼Œ==è€Œæ˜¯è¿”å›ä¸€ä¸ªæ›´å¯è¯»ã€æ›´ç»“æ„åŒ–çš„ **dataclassï¼ˆæ•°æ®ç±»ï¼‰å¯¹è±¡**ã€‚==

  ä½œç”¨

  1. æ–¹ä¾¿ç»“æ„åŒ–è®¿é—®ï¼š`output.logits`, `output.hidden_states`, `output.attentions`...
  2. è‡ªåŠ¨æ”¯æŒè§£åŒ…ä¸º tupleï¼Œä¹Ÿæ”¯æŒç‚¹å¼è®¿é—®ã€‚
  3. æ›´æ˜“ç»´æŠ¤ã€å¤šä»»åŠ¡å…¼å®¹æ€§å¼ºã€‚

  

  * `Seq2SeqLMOutput`

    ç”¨äº **åºåˆ—åˆ°åºåˆ—è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼ˆå¦‚ T5, BARTï¼‰**ï¼Œæ¨¡å‹ç»“æ„ç±»ä¼¼ encoder-decoderã€‚

    å®ƒçš„ç»“æ„å¤§è‡´å¦‚ä¸‹ï¼ˆç®€åŒ–ç‰ˆï¼‰ï¼š

    ```python
    @dataclass
    class Seq2SeqLMOutput:
        loss: Optional[Tensor] = None
        logits: Tensor  # [batch_size, seq_len, vocab_size]
        past_key_values: Optional[Tuple] = None
        decoder_hidden_states: Optional[Tuple[Tensor]] = None
        decoder_attentions: Optional[Tuple[Tensor]] = None
        cross_attentions: Optional[Tuple[Tensor]] = None
        encoder_last_hidden_state: Optional[Tensor] = None
        encoder_hidden_states: Optional[Tuple[Tensor]] = None
        encoder_attentions: Optional[Tuple[Tensor]] = None
    ```

    é€‚ç”¨äº `T5ForConditionalGeneration`ã€`BartForConditionalGeneration` ç­‰ã€‚

  * `BaseModelOutput`

    è¿™æ˜¯ä¸€ä¸ªæ›´é€šç”¨çš„åŸºç¡€è¾“å‡ºç»“æ„ï¼Œç”¨äºä»…å« encoder æˆ–åŸºç¡€ transformer block çš„æ¨¡å‹ï¼Œæ¯”å¦‚ï¼š

    - `T5Stack`
    - `BertModel`
    - `GPT2Model`

    å®ƒçš„ç»“æ„ä¹Ÿæ›´ä¸ºç®€å•ï¼š

    ```python
    @dataclass
    class BaseModelOutput:
        last_hidden_state: Tensor                # é€šå¸¸æ˜¯ encoder æœ€åä¸€å±‚è¾“å‡º
        hidden_states: Optional[Tuple[Tensor]] = None
        attentions: Optional[Tuple[Tensor]] = None
    ```




##### `__init__(self, config)`

* ä¸»è¦è¿˜æ˜¯è¦å¼„æ‡‚æµç¨‹ä»¥åŠé‡Œé¢çš„ `cid_embed_list` ä¸ `centroids` æ¨¡å—ã€‚

  ä¸€ä¸ªæ˜¯åµŒå…¥ï¼Œä¸€ä¸ªæ˜¯çº¿æ€§å˜æ¢ï¼Œæ³¨æ„å®ƒä»¬è¦å„å¸å…¶èŒ
  
  ```python
  self.cid_embed_list = nn.ModuleList(
      [
          nn.Embedding(config.cid_token_num+1,config.d_model)
          for i in range(self.codebook_num)
      ]
  )
  ```
  
  ```python
  self.centroids = nn.ModuleList([
      nn.Linear(config.d_model,config.cid_token_num+1)
      for _ in range(self.codebook_num)
  ])
  ```

  å…¶ä»–ä¸»è¦åŒ…æ‹¬ä¸€äº›å¯¹é…ç½®æ–‡ä»¶çš„å¤„ç†
  
  ```python
  # éšè—å±‚ç»´åº¦
  self.model_dim = config.d_model
  # å…±äº«è¯åµŒå…¥å±‚
  self.shared = nn.Embedding(config.vocab_size, config.d_model)
  # ä»»åŠ¡æç¤ºåµŒå…¥å±‚ï¼Œåªæœ‰ 2 ä¸ª tokenï¼ˆ0 å’Œ 1ï¼‰ï¼Œç”¨äºåŒºåˆ†ç”¨æˆ·å’Œç‰©å“ç›¸å…³çš„ä»»åŠ¡ã€‚è¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„ä»»åŠ¡ç±»å‹ç¼–ç æ–¹å¼
  self.prompt = nn.Embedding(2,config.d_model)
  self.atomid_user_embed = nn.Embedding(config.user_num+1,config.d_model)
  if config.item_position:
      self.info_position = nn.Embedding(config.max_info_len+10,config.d_model)
  else:
      self.info_position = None
  
  # æˆ‘ä»¬åœ¨æ‰‹åŠ¨æ„é€  T5 çš„ encoder å’Œ decoder ä¸¤éƒ¨åˆ†ï¼Œå› ä¸º
  # Huggingface åŸå§‹ T5Model æ˜¯ä¸€ä¸ªEncoder-Decoderæ¨¡å‹çš„å°è£…ä½“ï¼Œä½†æˆ‘ä»¬ç°åœ¨æ‰‹åŠ¨åˆ†åˆ«æ„é€ äº† T5Stack çš„ encoder å’Œ decoderã€‚
  
  # è¿™é‡Œçš„è¿™ä¸ª encoder_config æ˜¯åªé’ˆå¯¹ ç¼–ç å™¨ encoder åšçš„é…ç½®
  encoder_config = copy.deepcopy(config)
  # å‘Šè¯‰ T5Stack å®ƒæ˜¯ encoder æ¨¡å—ï¼Œæ‰€ä»¥å°† decoder å…³é—­
  encoder_config.is_decoder = False
  # ä¸å¯ç”¨ç¼“å­˜æœºåˆ¶ï¼ˆdecoder æ¨ç†ä¸­æ‰ç”¨ï¼‰
  encoder_config.use_cache = False
  # è¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ª encoder-only æ¨¡å—ï¼ˆå¯¹ç»“æ„åšé™åˆ¶ï¼‰
  encoder_config.is_encoder_decoder = False
  self.encoder = T5Stack(encoder_config)
  
  decoder_config = copy.deepcopy(config)
  # å‘Šè¯‰ T5Stack å®ƒæ˜¯ä¸€ä¸ª decoder â†’ å¯ç”¨ cross-attention ç­‰é€»è¾‘
  decoder_config.is_decoder = True
  decoder_config.is_encoder_decoder = False
  # è®¾ç½® decoder ä½¿ç”¨å¤šå°‘å±‚ï¼ˆé˜²æ­¢å’Œ encoder å…±ç”¨ num_layersï¼‰
  decoder_config.num_layers = config.num_decoder_layers
  self.decoder = T5Stack(decoder_config)
  
  # è´å¶æ–¯ä¸ªæ€§åŒ–æ’åºæŸå¤±ï¼Œç”¨äºæ¨èç³»ç»Ÿï¼Œä¼˜åŒ–ç›®æ ‡æ˜¯æ­£ç¡®æ’åºç”¨æˆ·åå¥½çš„ç‰©å“
  self.bpr_loss = BPRLoss()
  
  # T5 æ¨¡å‹çš„è‡ªå®šä¹‰åˆå§‹åŒ–æ–¹æ³•ï¼Œé€šå¸¸ç”¨äºæƒé‡åˆå§‹åŒ–æˆ–åŠ è½½é¢„è®­ç»ƒå‚æ•°ã€‚
  self.post_init()
  # ç”¨äºæ¨¡å‹å¹¶è¡Œè®­ç»ƒçš„é…ç½®ï¼Œè¿™é‡Œè®¾ç½®ä¸ºå•è®¾å¤‡æ¨¡å¼ã€‚
  self.model_parallel = False
  self.device_map = None
  ```
  
  
  
  è¿™æ®µä»£ç å®Œæˆäº†ä»¥ä¸‹åŠŸèƒ½ï¼š
  
  | æ¨¡å—                             | åŠŸèƒ½                                      |
  | -------------------------------- | ----------------------------------------- |
  | è‡ªå®šä¹‰åµŒå…¥                       | æ„é€ ç”¨æˆ·ã€ç‰©å“ã€**codebook çš„åµŒå…¥ç©ºé—´**   |
  | T5ç»“æ„ï¼ˆæ„é€ ä¸€ä¸ªç¼–ç å™¨å’Œè§£ç å™¨ï¼‰ | æ‹†è§£ T5 æˆ encoder å’Œ decoderï¼Œåˆ†åˆ«åˆå§‹åŒ– |
  | codebook è¾“å‡º                    | å°† decoder è¾“å‡ºæ˜ å°„ä¸ºç¦»æ•£ token åˆ†å¸ƒ      |
  | æ¨èä»»åŠ¡é€‚é…                     | åŠ å…¥ BPR æŸå¤±ã€ä»»åŠ¡æç¤ºåµŒå…¥ã€ç”¨æˆ·åµŒå…¥ç­‰   |
  | æ¨¡å‹å¹¶è¡Œ                         | åˆå§‹åŒ–ç›¸å…³é…ç½®ï¼ˆé»˜è®¤å…³é—­ï¼‰                |



##### `get_encoder_state()`

åœ¨è¯¥ä»£ç ä¸­ï¼Œè¯¥ä»£ç ä¸»è¦æ˜¯ç”¨æ¥è·å–**è¾…åŠ©å¢å¼ºæ ·æœ¬**çš„çŠ¶æ€ã€‚

è¿™ä¸ª `get_encoder_state` å‡½æ•°çš„æ ¸å¿ƒä»»åŠ¡æ˜¯ï¼š
 **æ„å»ºç¬¦åˆè¯­ä¹‰è¦æ±‚çš„ `encoder` è¾“å…¥åµŒå…¥ `encoder_input_embed`ï¼Œå¹¶ä¼ å…¥ `T5Stack` çš„ç¼–ç å™¨ä¸­è¿›è¡Œè¡¨ç¤ºå­¦ä¹ ã€‚**

ä¼šæ ¹æ®å¯¹åº”çš„éœ€æ±‚ï¼Œè‡ªåŠ¨è°ƒæ•´å¤„ç† embeddingã€‚å³ç”¨è‡ªå®šä¹‰çš„æ¨¡å‹æ–¹æ³•æ¥æ„å»º  `encoder` çš„è¾“å…¥åµŒå…¥ï¼ˆè¿™é‡Œçš„æ˜¯å¯¹è·å¾—çš„åµŒå…¥**è¿›è¡Œæ‰‹åŠ¨çš„å¤„ç†**ï¼Œå› ä¸º `content_input_ids` çš„è¯­ä¹‰æ˜¯æœ‰ä¸åŒå†…å®¹çš„ï¼Œæˆ‘ä»¬å…ˆå°†å…¶å…¨éƒ¨å¯¹ç€æ–‡æœ¬çš„è¯å‘é‡åµŒå…¥è¡¨åµŒå…¥ï¼Œæœ€åå†æ ¹æ® `index` æ›¿æ¢æ‰å“ªäº› atom æˆ–è€… user ä½ç½®ä¸Šçš„åµŒå…¥ï¼ ï¼‰ï¼Œå¹¶å–‚ç»™ `encoder(T5Stack)` è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œæœ€ç»ˆè¾“å‡ºä¸€ä¸ª `Seq2SeqLMOutput`ã€‚

å…·ä½“æ¥è¯´ï¼Œç”±äº `content_input_ids` å®é™…ä¸ŠåŒ…å«äº†==**å¤šç§è¯­ä¹‰ä¸åŒçš„ä¿¡æ¯**==ï¼ˆå¦‚ï¼šprompt tokenã€atomï¼ˆitemï¼‰ã€userï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬ï¼š

1. **ç»Ÿä¸€ç”¨å…±äº«è¯åµŒå…¥è¡¨ `self.shared` å¯¹ content_input_ids è¿›è¡Œ embedding**ï¼›
2. ç„¶åé€šè¿‡ `index` ç²¾å‡†å®šä½ç‰¹å®šä½ç½®ï¼Œå¹¶ä½¿ç”¨é¢å¤–è¯­ä¹‰å‘é‡ï¼ˆå¦‚ atomã€user çš„åµŒå…¥ä»¥åŠä»»åŠ¡ token (prompt token)ï¼‰**æ›¿æ¢æ‰å¯¹åº” token çš„åˆå§‹ embedding**ï¼Œå®ç°è¯­ä¹‰å¯¹é½å’Œå®šåˆ¶åµŒå…¥ã€‚

å…¶å®å°±æ˜¯**ä¸åŒé¢†åŸŸçš„ä¿¡æ¯è¦ç”¨ä¸åŒçš„åµŒå…¥è¡¨**

> è¿™ä¸ª `get_encoder_state` æ–¹æ³•**ç»•è¿‡äº† T5 é»˜è®¤çš„ tokenizer + embedding è¾“å…¥æµç¨‹**ï¼Œè€Œæ˜¯ï¼š
>
> > åˆ©ç”¨ `content_input_ids` ä½œä¸ºé€šç”¨ç»“æ„éª¨æ¶ï¼Œç„¶å**æ‰‹åŠ¨æŒ‡å®šä½ç½® + è‡ªå®šä¹‰åµŒå…¥æ›¿æ¢**ï¼Œæœ€ç»ˆæ„é€ å‡ºè¯­ä¹‰ç²¾ç»†æ§åˆ¶çš„ `inputs_embeds`ã€‚
>
> è¿™ç§åšæ³•éå¸¸çµæ´»ï¼Œéå¸¸é€‚åˆå¤šæ¨¡æ€ã€å¤šæºç»“æ„ï¼ˆå¦‚ç”¨æˆ·ã€å•†å“ã€æç¤º token ç­‰ï¼‰å…±å­˜çš„è¾“å…¥ã€‚
>
> æœ€ç»ˆè®©æ¨¡å‹æ—¢èƒ½ä¿æŒ Transformer ç»“æ„ä¼˜åŠ¿ï¼Œåˆ**èåˆå®šåˆ¶åŒ–é¢†åŸŸä¿¡æ¯**ã€‚



å®Œæˆäº†ä»¥ä¸‹åŠŸèƒ½ï¼š

| ä¸»è¦åŠŸèƒ½                         | è¯´æ˜                                       |
| -------------------------------- | ------------------------------------------ |
| ç»„åˆå¤šç§åµŒå…¥ï¼ˆæ–‡æœ¬ã€itemã€userï¼‰ | æ•´åˆå†…å®¹è¯åµŒå…¥å’Œç»“æ„åŒ–çš„ item/user åµŒå…¥    |
| ä½¿ç”¨ä»»åŠ¡æç¤ºåµŒå…¥ï¼ˆprompt_embedï¼‰ | æ˜¾å¼å‘Šè¯‰æ¨¡å‹å½“å‰è¾“å…¥å±äºâ€œuserâ€æˆ–â€œitemâ€ä»»åŠ¡ |
| åŠ å…¥å¯é€‰ä½ç½®ç¼–ç                  | åŠ å¼ºåºåˆ—ä¸­ token çš„ä½ç½®æ„ŸçŸ¥                |
| è°ƒç”¨ T5 encoder å‰å‘æ¨ç†         | è¾“å‡ºç¼–ç å™¨çš„ä¸Šä¸‹æ–‡è¡¨ç¤º                     |
| è¿”å›ç»“æœå°è£…ä¸ºæ ‡å‡†è¾“å‡ºæ ¼å¼       | æ–¹ä¾¿åç»­è°ƒç”¨è§£ç å™¨æˆ–è®¡ç®—æŸå¤±ç­‰             |

éœ€è¦ç†è§£çš„æ˜¯ï¼šè¿™ç§èåˆäº†ä¸åŒâ€œé¢†åŸŸâ€ä¿¡æ¯çš„åµŒå…¥ï¼ŒçœŸçš„èƒ½è¢«æ¨¡å‹æ„ŸçŸ¥ä¸åˆ©ç”¨å—ï¼Ÿ

**æ³¨æ„åŠ›æœºåˆ¶**

> â‘  æ¨¡å‹èƒ½å¦â€œæ„ŸçŸ¥â€tokençš„ç±»å‹ï¼Ÿ
>
> > ğŸ”‘ **æ˜¯çš„ï¼Œä½†è¦æ˜ç¡®å‘Šè¯‰å®ƒï¼šè¿™æ˜¯ä¸åŒç±»å‹çš„ä¿¡æ¯ã€‚**
>
> åœ¨ä½ è¿™æ®µä»£ç ä¸­ï¼Œå…¶å®å·²ç»åœ¨â€œç»“æ„â€ä¸Šå¸®æ¨¡å‹åˆ’åˆ†äº†åŠŸèƒ½åŒºåŸŸï¼Œæ¯”å¦‚ï¼š
>
> - ç¬¬ 0 ä½æ˜¯ prompt token â†’ ç”¨ `prompt_embed` æ˜ç¡®æ³¨å…¥ï¼›
> - ç¬¬ atom_index ä½æ˜¯ item token â†’ ç”¨ `atomid_embed` æ›¿æ¢ï¼›
> - ç¬¬ user_index ä½æ˜¯ user token â†’ ç”¨ `user_atom_embed` æ›¿æ¢ï¼›
> - å…¶ä»–ä½æ˜¯è‡ªç„¶è¯­è¨€è¯å‘é‡ã€‚
>
> è™½ç„¶è¿™äº›éƒ½åœ¨ `encoder_input_embed` ä¸­ç»Ÿä¸€æˆäº†ä¸€ä¸ª `[B, L, D]` çš„å¼ é‡ï¼Œä½†ï¼š
>
> - å®ƒä»¬æ¥è‡ª**ä¸åŒçš„ embedding è¡¨**ï¼ˆå¦‚ `shared`ã€`atomid_embed`ã€`atomid_user_embed`ã€promptï¼‰
> - å®ƒä»¬åœ¨**åºåˆ—çš„ä½ç½®ä¸Š**æœ‰æ˜æ˜¾å·®å¼‚ï¼ˆå¦‚ prompt æ€»åœ¨ç¬¬ 0 ä½ï¼Œitem æ€»åœ¨ç¬¬ 1 ä½ï¼‰
>
> ğŸ’¡ **è¿™ç§ç»“æ„ä¸Šçš„å·®å¼‚ï¼ŒT5ï¼ˆæˆ– Transformerï¼‰æ˜¯å¯ä»¥â€œæ„ŸçŸ¥â€çš„ã€‚**
>
> â‘¡ æ¨¡å‹å¦‚ä½•å­¦ä¹ è¿™äº› token çš„ä¸åŒåŠŸèƒ½ï¼Ÿ
>
> > ğŸ”‘ **é€šè¿‡è®­ç»ƒæ•°æ®ä¸­çš„ä¸Šä¸‹æ–‡è¯­ä¹‰+ä½ç½®æ¨¡å¼ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨å­¦ä¹ å‡ºè¿™äº› token çš„â€œè§’è‰²â€ã€‚**
>
> ä¸¾ä¸ªä¾‹å­ï¼š
>
> - å¦‚æœæ¨¡å‹åœ¨è®­ç»ƒä¸­åå¤è§‚å¯Ÿåˆ°ï¼šç¬¬ 1 ä¸ª tokenï¼ˆitemï¼‰å†³å®šè¾“å‡ºä»€ä¹ˆæ ·çš„æ¨èç»“æœï¼›
> - ç¬¬ 2 ä¸ª tokenï¼ˆuserï¼‰å¯¹æ¨èåå¥½æœ‰å½±å“ï¼›
> - å‰©ä¸‹çš„ token æ¥è‡ªå•†å“æè¿°ã€è¯„è®ºæˆ–å…¶ä»–ä¸Šä¸‹æ–‡ï¼›
>
> é‚£ä¹ˆï¼Œ**æ³¨æ„åŠ›æœºåˆ¶**ä¼šè‡ªåŠ¨å­¦ä¼šä¸åŒ token çš„æƒé‡åˆ†é…æ–¹å¼ï¼Œä¹Ÿä¼šåœ¨ `FFN` å±‚ä¸­å­¦ä¹ åˆ°**ä¸åŒ token æ‹¥æœ‰ä¸åŒçš„è¯­ä¹‰è§’è‰²**ã€‚



##### `forward_train()`

ç›´æ¥ç”¨æ¥è·å–itemæ­£æ ·æœ¬ã€itemè´Ÿæ ·æœ¬ã€æ£€ç´¢ user çš„è¾“å‡º
