# 生成式推荐系统

## Content-Based Collaborative Generation for Recommender Systems



### 方法论

1. 模型总览
2. user-item推荐系统任务
3. item-item索引任务
4. 将上述任务的联合优化

#### 模型总览

图3显示了拟议的ColaRec的概述。ColaRec使用**基于图的CF模型**构建GID，该模型有效地捕获了协作信号。ColaRec的训练包括两个任务：用户项目推荐任务和项目索引任务。用户项目推荐旨在将用户历史交互项目的内容信息映射到推荐项目的GID中。项目索引任务的目标是从项目侧信息到项目GID的映射。这两个任务都是通过基于**共享编码器-解码器**的模型来实现的。推荐任务统一协作信号和项目内容信息以获得更好的推荐，而索引任务则执行协作信号和内容信息之间的对齐。【大概懂了：历史内容信息（协作信息）+具体项目信息（内容信息）->生成 GID（这是通过**推荐任务实现**的），并且通过**索引任务**来对齐协作信息与内容信息】

#### 生成标识符构造

GID的构建在生成推荐中是重中之重的。一般来说，GID应满足以下期望：

1. 需要包含写作信号和内容信息的知识
2. 相似的 item 应该拥有相似的 GID
3. 每一个 item 都应该有唯一的 GID，且每一个 GID 只对应一个特定的 item



考虑利用**分层聚类方法**从基于图的CF（协同过滤）模型构建GID（对象是 item 的表征向量）。以下是过程

1. 首先从预训练的LightGCN模型中提取项目表示。
2. 然后，基于 item 表示，分层调用约束K-means算法。（就是先聚类几个大类，然后再在大类中聚类成小类）对于$t \in [1, l - 1]$ 的第 $t$ 级聚类，每个聚类中的项目数量不超过 $K ^ {l-t}$。（其实就是一颗多叉树）
3. 建立一个 K-ary 树来组织 item 集。每个 item 对应一个叶子节点，而从根到叶子节点的路径是项目的GID。例如：GID = `[3, 1, 2]` 就表示该 item 从根节点出发，依次走到第3个子簇，再到第1个子簇，再到第2个子簇。

其他注意事项：

1. 因为 LightGCN 是在 user-item **交互图**（用 GNN 训练）上训练出来的，它的表示能捕捉协同信号，因此聚类形成的 GID 也**天然编码了协同过滤的信息**。

2. 此外，对于 GID 中的每个位置（例如路径中的每一级编号），该框架还设计了一个**编码向量表（codebook embedding）**，用于在索引任务中引入项目的内容信息。

   可以这样理解：GID = `[3, 1, 2]` → 我们分别为位置1的`3`、位置2的`1`、位置3的`2`查询对应的 embedding（这部分包含内容信息，可以理解为某个聚类编号的”语义表示“），然后拼接起来作为 item 的最终编码。

3. 综上，**GID + codebook embedding** 结合起来，就帮助推荐模型同时建模了：

   * 协同信号（通过 LightGCN 表示和聚类结构）；
   * 内容信息（通过 codebook 嵌入向量）。



#### User-Item 推荐

* 模型输入

  针对一条信息交互 $User_u-item_i$ ，我们可以这样表示 $item_i$ ，首先加入其原子令牌 $iad_i$ 来提高模型的保真度（即模型具体区分 item 的能力），其次，再以字典形式的键值对来表示一些内容信息（这里的内容信息可能是通过一些 raw data 比如 JSON 元数据获取的）

  $$
  c_i = [iad_i,k_1:v_1,k_2:v_2, \cdots]
  $$
  协同过滤的核心思想是：**用户的偏好可以通过他互动过的项目来推断**。

  因此，每个用户的输入就是他**所有互动项目的内容信息**之**集合**，这样也能保留协同信号。

  由于 ColaRec 训练阶段包含多个任务，为了告诉模型“当前是推荐任务”，我们会在输入的最前面加一个特殊的任务 token：`tasku`。

  因此，用户 $u$ 在推荐任务中的**完整输入**是：

  $$
  X_u = [task_u,\{c_i |i \in I^{+}_u\}]
  $$

* Item 生成

  本质上是一种**基于Encoder-Decoder Transformer结构的序列生成方式**，模型的目标是：**根据用户历史行为，逐步生成目标物品的“GID路径”**（也就是之前构造的那个分层路径式编号）。

  输入是之前构造的 `Xu = [task_token, c1, c2, ..., cn]`，即**用户 u 的历史交互内容信息。**
  
  Encoder 会提取这个输入序列的语义表示，输出一个隐藏状态向量，记作 `Encoder(Xu)`。
  
  $z^{<t}$ 是**之前生成过**的 token（比如前几个 GID 编号）
  $$
  \mathbf{d}_t = \text{Decoder}(\text{Encoder}(X_u),z ^ {<t})
  $$

  
  在每一步 t，我们将当前 decoder 生成的向量 $\mathbf{d}_t$，与一个**“第 t 位的 codebook embedding 矩阵”** $E_t$ 做 点积，然后通过 softmax 得到第 t 个 GID 编号的概率分布。
  $$
  p(z_t \mid z_{<t}, X_u) = \text{softmax}(d_t \cdot E_t^\top)
  $$
  采用交叉熵损失进行模型优化。模型训练目标是让它生成的 GID 路径尽可能接近真实目标项目的 GID 路径。所以，我们用**多步交叉熵损失**，一步一步地计算真实 token 的 log 概率；然后加起来，形成**完整的生成式推荐损失**。即最大化整个 GID 序列的生成概率。
  $$
  \mathcal{L}_{\text{rec}} = - \sum_{t=1}^{l} \log p(z_t^i \mid X_u, z_1^i, z_2^i, \dots, z_{t-1}^i).
  $$
  小总结一下，其实就是 Encoder 根据输入编码隐向量，Decoder 根据隐向量与历史信息（GID）编码向量 $\mathbf{d}$， 根据向量 $\mathbf{d}$ 与 code book embedding 矩阵的相关计算情况得到对应 GID 的概率分布。
  
  **其任务目标是：给定一个用户 $u$ 的历史行为（表示为 $X_u$），预测这个用户可能会点击/交互的 item。在这里是生成该用户最可能会交互的 item 的 GID 序列。**我们举个例子来说明这个损失函数的训练含义
  
  > 看到这个用户的 `X_u` 后，更倾向于先生成 token `"1"`，再是 `"5"`，最后是 `"9"`；
  >
  > 从而下次看到类似用户行为时，能够更容易推荐（概率变高）出这个商品 D（对应 GID = 159）。

#### Item-Item 索引

为了**对齐**协作信号和项目内容信息，我们引入了一个**项目索引任务**，该任务将基于内容的语义空间映射到基于交互的协作空间。

* 模型输入，其中这里的 $u$ 是和 $item_i$ 有过交互的用户集合
  $$
  X_i = \left[ \text{task}_i, c_i, \{uad_u \mid u \in U_i^+\} \right]
  $$

* Item 索引生成

  与上文基本同理
  $$
  \mathcal{L}_{\text{index}} = -\sum_{t=1}^{l} \log p(z_t^i \mid X_i, z_1^i, \dots, z_{t-1}^i)
  $$
  这么操作的本质是：**让模型学会根据 item 的内容 + 它的协同上下文（交互用户）来生成它的结构化 ID，这个 GID 结构既带协同语义，也带内容语义。**

  生成的目标是：当前 Item 自己的 GID

* **该阶段的任务目标是：给定一个 item 的内容信息 + 它的交互用户集合，预测它的 GID（即其语义 token 序列）。**

* User–Item 任务让 GID 更好地建模偏好；Item–Item 索引让 GID 更好地对齐内容；两者相辅相成，构建出可解释、可控制、结构良好的 item token 空间。



#### 多任务学习

除了上述两项任务外，我们还引入了**排名损失**来提高ColaRec的排名能力，并引入了**对比损失**来进行更好的对齐。

* Item 排名

  目标是：**让正样本（用户喜欢的物品）比负样本得分高**。

  对应文中的公式（9），BPR的核心思想是：用户喜欢的 item 应该比未点击的 item 更**匹配**他的兴趣，预测分更高。体现在公式上就是 $h(X_u) \cdot h(X_i) > h(X_u) \cdot h(X_i)$ 即，**用户与正样本的匹配得分 > 用户与负样本的匹配得分**。

* 对比学习

  设计这个损失是为了让**GID 结构相似的 item，也在语义空间上靠近**。

  这是为了增强 GID 编码结构和 item 内容之间的一致性（对齐 collaborative signal 和 content）。
  $$
  \mathcal{L_c}=-\ln \sigma(\mathbf{h}(X_i) \cdot(\mathbf{h}(X_{i+})-\mathbf{h}(X_{i-})))
  $$
  对应论文中的公式（10），注意与公式（9）区分开来。这里的想法是，具有相似GID的项目在基于内容的语义空间中也应该是相似的。

* 联合优化

  **将这些损失函数全部加起来，要深刻理解每一步的实际含义！！！**

* 其他注意事项（trick）：在推理过程中，为了避免推荐者生成无效的GID，我们采用约束波束搜索[6]来限制基于前缀令牌的当前令牌的生成范围。

#### 其他补充

* User-Item 与 Item-Item 的区别

  > 推荐任务（公式 6）：从用户历史行为 → 生成下一个商品 GID。
  >
  > 索引任务（公式 8）：从一个商品的内容 + 与它交互的用户 → 再现这个商品的 GID。
  >
  > 也就是说，**索引任务是从“商品视角”进行建模的，而推荐是从“用户视角”建模的。**
  >
  > **相当于先获得再纠正**

### 实验

进行实验来回答以下问题：

1. 与现有的推荐方法相比，拟议的ColaRec的表现如何？
2. 多任务的联合训练如何影响ColaRec的表现？
3. GID的设计如何影响推荐性能？

> 我们使用四个真实的公共数据集来评估 ColaRec 的性能。具体而言，实验在来自 Amazon 商品评论的三个子类别（“美容”、“运动与户外”以及“手机与配件”）和来自 Food.com 的“食谱”数据集上进行。对于用户和物品，若其交互次数少于五次，则会被过滤掉。表 1 展示了这四个数据集的统计信息。至于内容信息，我们使用 Amazon 商品元数据中的“标题”、“品牌”和“类别”作为物品的文本内容信息；对于食谱数据集，我们使用“名称”、“描述”和“标签”来描述物品内容。

#### 评估协议

* 交叉验证
* **通用推荐而非顺序推荐**（==也就是说这个框架模型并不直接支持时序任务，但是腾讯广告大赛是一个时序任务==）
* 采用两种指标
  1. `recall@n`
  2. `NDCG@n`



#### 性能比较

* 对整个用户的比较

  ColaRec在所有数据集上与这些CF方法相比都取得了具有竞争力的结果，证明了为协同生成推荐系统**注入内容信息**的潜力。

* 对长尾用户的比较

  在为长尾用户生成推荐时，ColaRec的表现明显优于所有基线。原因是ColaRec对用户-项目交互和项目内容信息都进行了建模。鉴于长尾用户的交互知识较少，ColaRec在**内容信息的帮助下获得了更好的性能**。总之，与现有基线相比，所提出的ColaRec可以有效地产生更好的性能。这种改进对长尾用户来说更为显著。



### 查漏补缺

#### bpr 损失

BPR（Bayesian Personalized Ranking）损失是一种专为推荐系统设计的排序优化目标函数，主要用于优化 **隐式反馈场景下的个性化排序推荐**。

**BPR 损失的目标是让用户更喜欢（更高评分/更常点击）的物品排在不喜欢的物品前面。**

* 隐式反馈是推荐系统中一种非常常见的用户行为数据类型，它**不直接表达用户是否喜欢某个项目**，而是通过用户的**行为痕迹**间接推测用户偏好。

  常见的隐式反馈举例：

  | 行为         | 系统如何理解             |
  | ------------ | ------------------------ |
  | 点击一个商品 | 可能感兴趣               |
  | 浏览页面     | 有一定注意力             |
  | 收藏、加购   | 偏好较强                 |
  | 播放视频     | 有意愿消费               |
  | 停留时长长   | 可能认真阅读             |
  | 重复访问     | 潜在高兴趣               |
  | 购买         | 最强隐式反馈，强兴趣信号 |

  显式反馈 vs 隐式反馈

  | 特点             | 显式反馈（Explicit Feedback）    | 隐式反馈（Implicit Feedback） |
  | ---------------- | -------------------------------- | ----------------------------- |
  | 用户是否主动表态 | ✅ 是（打分、点赞等）             | ❌ 否                          |
  | 信息准确度       | 高，但稀疏                       | 低，但丰富                    |
  | 可获取性         | 较难，大多在社交平台或评测类网站 | 很容易收集，如电商、App 里    |
  | 示例             | 评分 4 星、点赞、差评            | 点击、购买、浏览、加购、播放  |

* 背后的核心思想：在隐式反馈中，在隐式反馈中，我们只有用户的正向行为（如点击、购买），但没有明确的负反馈（不喜欢）。
   BPR 通过**“用户喜欢的 > 没点过的”**这个假设，设计了以下训练目标：

  对于每个三元组：$(u,i,j)$

  其中：

  $u$：用户

  $i$：用户 $u$ 喜欢/交互过的 item（正样本）

  $j$：用户没有交互过的 item（负样本）

  BPR 是**专为排序任务设计**的 loss，非常适合推荐系统。

* BPR损失公式

  BPR (Bayesian Personalized Ranking) 的损失函数可以表示为：

  $$
  \mathcal{L}_{\text{BPR}} = -\ln \sigma(\hat{y}_{ui} - \hat{y}_{uj})
  $$

  其中：  
  - $\hat{y}_{ui}$：用户 $u$ 对 item $i$ 的预测偏好得分  
  - $\hat{y}_{uj}$：用户 $u$ 对 item $j$ 的预测偏好得分  
  - $\sigma(\cdot)$：sigmoid 函数  

  损失的含义：  

  - 如果模型预测 $\hat{y}_{ui} > \hat{y}_{uj}$（即正样本的分数更高），则 $\sigma(\hat{y}_{ui} - \hat{y}_{uj})$ 趋近于 1，损失 $-\ln \sigma(\cdot)$ 趋近于 0。  
  - 如果预测相反（$\hat{y}_{ui} < \hat{y}_{uj}$，即负样本排前面），$\sigma(\hat{y}_{ui} - \hat{y}_{uj})$ 趋近于 0，损失 $-\ln \sigma(\cdot)$ 会变大，模型因此受到惩罚。

  

