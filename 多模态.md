# 多模态

## 入门

* 参考文章

  * [多模态学习综述(MultiModal Learning)](https://zhuanlan.zhihu.com/p/582878508)

* 初印象杂记

  * 对多源异构数据的挖掘分析可被理解为多模态学习。

  * 促使多模态研究发展的关键促成因素有4个：

    1）新的大规模多模态数据集

    2）GPU快速计算

    3）强大的视觉特征抽取能力

    4）强大的语言特征抽取能力。

  * 多模态遇到的挑战有以下几个方面：

    1. 表征Representation

       第一个基本挑战是学习如何以**利用多种模态的互补性和冗余性的方式表示和总结多模态数据**。多模态数据的异质性使得构建这样的表示具有挑战性。例如，语言通常是象征性的，而音频和视觉形式将被表示为信号。

       单模态的表征负责将信息表示为计算机可以处理的数值向量或者进一步抽象为更高层的特征向量，而多模态表征是指通过利用多模态之间的互补性，剔除模态间的冗余性，从而学习到更好的特征表示。

       **联合表征**（Joint Representation）将多个模态的信息一起映射到一个统一的多模态向量空间，Joint结构注重捕捉多模态的**互补性**，融合多个输入模态$x_1,x_2$获得多模态表征$x_m=f(x_1,...,x_n)$，进而使$x_m$完成某种预测任务。

       **协同表征**（Coordinated Representation）将多模态中的每个模态分别映射到各自的表示空间，但映射后的向量之间满足一定的相关性约束（例如线性相关）。Coordinated结构并不寻求融合而是建模多种模态数据间的**相关性**，它将多个(通常是两个)模态映射到协作空间，表示为：$f(x_1) ～ g(x_2)$，其中～表示一种协作关系。网络的优化目标是这种协作关系(通常是相似性，即最小化cosine距离等度量)。其**核心思想**：图像和文本仍保留自己的空间，但通过**对齐训练**（如对比学习），让它们在**各自空间中表达相似语义时距离更近**。

    2. 翻译Translation

       第二个挑战涉及**如何将数据从一种模式转化（映射）到另一种模式**。不仅数据是异构的，而且模态之间的关系通常是开放式的或主观的。例如，存在多种描述图像的正确方法，并且可能不存在一种完美的翻译。

    3. 对齐Alignment

       模态对齐（Multimodal Alignment）就是找出来自不同模态之间表达“相同语义”的部分，使它们在模型中能够相互对应、互相理解。

       举个例子理解，比如我们希望模型能对齐：

       | 图像区域     | 文本片段          |
       | ------------ | ----------------- |
       | 小女孩的脸部 | "girl", "smiling" |
       | 手里的冰淇淋 | "ice cream"       |

    4. 融合Fusion

       第四个挑战是**结合来自两个或多个模态的信息**来执行预测。例如，对于视听语音识别，将嘴唇运动的视觉描述与语音信号融合以预测口语。来自不同模态的信息可能具有不同的预测能力和噪声拓扑，并且可能在至少一种模态中丢失数据。