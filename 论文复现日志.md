## 论文复现日志

### 前言

立志成为会造轮子的掉包侠，会写丹方的炼丹师，全栈精通的开发者，会学更会玩的程序猿~



#### 如何想 idea？

[李沐分享](https://www.bilibili.com/video/BV1ea41127Bq?buvid=XYC6E55C7A1288F6E616688AAB8E564D963BF&from_spmid=main.space-contribution.0.0&is_story_h5=false&mid=zsw0awYQcKQ0Z8%2FLSPc5OQ%3D%3D&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=01e2a6f7-c6e5-4a5a-98ee-d4f813b3639d&share_source=COPY&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1723199264&unique_k=d7FYToH&up_id=1567748478&vd_source=56ba8a8ec52809c81ce429c827dc30ab)

$\text{研究价值} = \text{新意度} \times \text{有效性} \times \text{问题大小}$

* 写论文要追求什么？

1. 深刻，你是否揭示了一些比较本质的东西
2. 优美，你的论文的证明与描述是否有美感

* 如何定义有新意

1. 不要去堆砌无谓的复杂性，模型可以越简单越好
2. 论文的作者必须要呕心沥血才能发表文章？

##### 随便想想的 idea

idea：在对比学习的基础上，考虑将网络做深，从多个GNN模型中学习知识并通过，结合 cka 以及蒸馏的方法不断对上游目标进行矫正



#### 临时补充

* `self.training`

> `self.training` 是 **PyTorch 模块（nn.Module）自带的布尔属性**，用于指示当前模型是否处于“训练模式（training mode）”。
>
> 它的值由以下两个方法控制：
>
> | 方法            | 作用                                        |
> | --------------- | ------------------------------------------- |
> | `model.train()` | 将模型设为训练模式（`self.training=True`）  |
> | `model.eval()`  | 将模型设为评估模式（`self.training=False`） |

我们可以在我们的训练模型中这样设置代码来更好地处理损失

```python
class My_Model(nn.Module):
	'''
    处理的具体内容
    '''

    if self.training:
        '''
        ...
        '''
       return logits, loss
    else:
        return logits
```

#### 项目结构的设置

* 项目结构：一般都是工程上的最佳实践，需要多看别人的代码自己总结。可以参考知乎的[这篇](https://www.zhihu.com/question/406133826)
  常用的一个结构可以是这样

  ```
  --project_name/
  ----data/：数据
  ----checkpoints/：保存训练好的模型
  ----logs/：日志
  ----model_hub/：预训练模型权重
  --------chinese-bert-wwm-ext/：
  ----utils/：辅助模块，可以是日志、评价指标计算等等
  --------utils.py
  --------metrics.py
  ----models/：模型
  --------model.py
  ----configs/：配置文件
  --------config.py
  ----datasets/：加载数据
  --------data_loader.py
  ----main.py：主程序，包含训练、验证、测试和预测
  
  作者：西西嘛呦
  链接：https://www.zhihu.com/question/406133826/answer/2898344659
  来源：知乎
  著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
  ```

  若项目比较简单，也可以是这样
  ```
  --project_name/
  ----data/：数据
  ----checkpoints/：保存训练好的模型
  ----logs/：日志
  ----model_hub/：预训练模型权重
  --------chinese-bert-wwm-ext/：
  ----utils/：辅助模块，可以是日志、评价指标计算等等
  --------utils.py
  --------metrics.py
  ----model.py
  ----config.py
  ----data_loader.py
  ----main.py：主程序，包含训练、验证、测试和预测
  
  作者：西西嘛呦
  链接：https://www.zhihu.com/question/406133826/answer/2898344659
  来源：知乎
  著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
  ```

### 总结

#### 读取与存放文件

* 理解序列化与反序列化

  `pickle` 是一个**用于序列化和反序列化 Python 对象的模块**。**序列化是将 Python 对象转换为字节流（例如，存储在文件中），而反序列化是将字节流重新转换为 Python 对象。**

* `pickle.load()` 与 `pickle.dump()`

> `pk.load`（通常是 `pickle.load` 的简写）是与 `pickle.dump` 对应的操作，它用于从文件中**反序列化数据**，**将存储在文件中的字节流转换回 Python 对象。**
>
> 具体来说，`pickle.load` 从一个已经打开的文件中读取数据，并返回反序列化后的 Python 对象。示例如下：
>
> ```python
> with open('file.pkl', 'rb') as f:
>     obj = pickle.load(f)
> ```
>
> 在这个例子中，`file.pkl` 是一个包含序列化数据的文件，`pickle.load(f)` 会将文件中的字节流读取并转换为原来的 Python 对象，保存在 `obj` 中。这里 `rb` 表示以二进制读取模式打开文件。
>
> ___
>
> 
>
> `pk.dump` 是 `pickle.dump` 的简写，它将一个对象序列化并写入一个文件或类似文件的对象中。语法如下：
>
> ```python
> import pickle
> 
> with open('file.pkl', 'wb') as f:
>     pickle.dump(obj, f)
> ```
>
> 在这个例子中，`obj` 是你想要序列化的 Python 对象，`f` 是一个已经打开的文件对象（以**二进制写模式** `'wb'` 打开）。`pickle.dump` 会将 `obj` 写入文件 `file.pkl` 中。
>
> `pickle` 模块通常用于**将模型、数据结构等保存在磁盘上，以便后续加载和使用。**



* 关于 `.pt` 文件与 `.pkl` 文件

> **区别总结**
>
> 1. **用途**：
>    - `.pt` 主要用于 PyTorch **模型和张量**的保存与加载。
>    - `.pkl` 用于 Python 中广泛的对象序列化，包括非 PyTorch 对象。
> 2. **文件格式和方法**：
>    - `.pt` 是通过 `torch.save` 和 `torch.load` 保存和加载的，**专为 PyTorch 对象设计。**
>    - `.pkl` 是通过 `pickle.dump` 和 `pickle.load` 保存和加载的，**通用于 Python 对象。**
> 3. **兼容性**：
>    - `.pt` 适用于 PyTorch 环境，更能保证 PyTorch 模型的兼容性。
>    - `.pkl` 是更通用的文件格式，适用于任何 Python 对象，但不专门优化处理 PyTorch 模型。
>
> 简而言之，`.pt` 是 PyTorch 特有的文件格式，而 `.pkl` 是 Python 的通用序列化格式。

#### 设置随机种子

在 `PyTorch` 及 `DGL` 相关的代码中，为了确保实验的可复现性，一般需要在以下几个地方设置随机种子

（1）python 内置库（2）Numpy（3）Pytorch（4）PyTorch 计算相关（5）DGL（6）操作系统

```python
def set_random_seed(seed=0):
    '''
    设置随机种子，以保证实验的可复现性
    :param seed: int, 要使用的随机种子
    :return: None
    '''
    # Python 内置随机库
    random.seed(seed)

    # NumPy 随机种子
    np.random.seed(seed)

    # 设置 Python 运行时的哈希种子（影响某些哈希操作的随机性）
    os.environ['PYTHONHASHSEED'] = str(seed)

    # PyTorch CPU 端随机数
    torch.manual_seed(seed)

    if torch.cuda.is_available():
        # 设置当前 GPU 的随机数种子
        torch.cuda.manual_seed(seed)
        # 设置所有可用 GPU 的随机数种子
        torch.cuda.manual_seed_all(seed)

        # 让 CuDNN 以确定性方式执行计算，以确保结果可复现
        torch.backends.cudnn.deterministic = True
        # 关闭 CuDNN 的自动优化算法，以防止影响结果可复现性
        torch.backends.cudnn.benchmark = False
        # 禁用 CuDNN 加速，以最大程度保证实验可复现
        torch.backends.cudnn.enabled = False

    # DGL 相关随机种子
    dgl.random.seed(seed)

```

#### 设置最佳模型路径

* 需要用到的函数

```python
os.path.join()
os.path.exists()
'_'.join([f'{k}{v}' for k, v in parameters_dic.items()])
```



一般最佳模型都是保存在 `ckpt` 文件夹下，比如说 `project_name/ckpt/...` ，若有预训练模型，则保存在对应的预训练的文件夹下则 `preject_name/pretrain/ckpt/...`。若要训练多个模型，则可以这样 `project_name/ckpt/mode1/...` 或者 `project_name/pre_train/ckpt/model1/...`

```
--project_name
----ckpt
------model1
------model2
```

```
--project_name
----pretrain
------ckpt
--------model1
--------model2
```

后面的路径可以根据自己的超参数自己添加，比如早停忍耐轮次，重要性节点的采样比率等等。最后一层可以放上最后的数据集，如下所示

```
--project_name
----pretrain
------ckpt
--------model1
----------imp_ratio_0.1
------------patience_20
--------------fb15k
```

使用字符串配合 `args.` 解析命令参数来创建文件夹。具体上实现的思路是：分别写出每一层的**相对目录**，**最后拼接上去**，以我们上述举的例子为例

比如我们现在要保存预训练的模型 `model1` , 重要性节点的采样比率`imp_ration` 设置为0.1，早停忍耐轮次`patience` 设定为20。那么我们可以这样
`pretrain_root = 'pretrain/ckpt/'`  **（0）先设置根目录**

`model_path = str(args.model) + '/'`		**（1）设置模型相对路径**

`imp_ratio_path = 'imp_ratio_' + str(args.imp_ratio) + '/'`		**（2）设置节点重要性相对路径**

`patient_path = 'patience_' + str(args.patience) + '/'`				**（3）设置早停忍耐轮次相对路径**

`dataset_path = dataset_name + '/'` 			**（4）设置数据集相对路径**

最后将整个路径拼接起来：

```python
out_save_path = os.path.join(pretrain_root, model_path, imp_ratio_path, patience_path, dataset_path)
if not os.path.exists(out_save_path):
    os.makedirs(out_save_path, exist_ok = True)
```



这种方法，当参数过多是可能会很长。因此，此基础上，我们可以将其他的超参数（比如 `lr`， 交叉验证的轮次 `cross_id`， 损失 `loss` 的系数）添加到最终的模型名中为模型命名如：

`tmp = dataset_name + '_struct_pregat_pretrained_lr' + str(args.lr) + '_loss_' + str(args.eta) + '_' + str(cross_id) + '.pkl' `

`out_pretrained_path = os.path.join(out_save_path, tmp)`

上述这种方法较为冗长，我们可以**使用字典管理参数**

```python
# 定义模型文件名的关键参数
model_name_parts = {
    "dataset": dataset_name,
    "model": "pregat_pretrained",
    "lr": args.lr,
    "loss": args.eta,
    "cross": cross_id
}

# 生成文件名（去掉值为 None 或空字符串的参数）
model_filename = "_".join([f"{k}{v}" for k, v in model_name_parts.items() if v is not None]) + ".pkl"

# 最终模型保存路径
out_pretrained_path = os.path.join(out_save_path, model_filename)
```



#### 设置 cuda 并将数据传到 cuda

* 需要用到的函数

```python
# 设置 GPU 编号
torch.cuda.set_device()	# 这里可以填 cuda = 0, cuda = 1, 是说用机器的第几块 GPU

# 将张量移动到 cuda 上
.cuda()		# 只能移到默认 GPU（cuda:0） 或你手动指定的 GPU。
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
.to(device)	# 更加通用
```

* 需要思考有哪些数据要放到 cuda 上

  * 模型的参数：模型的参数（如权重、偏置等）应该放在 GPU 上进行计算和更新。尤其在训练过程中，这些参数会经过反向传播并需要在 GPU 上更新。
    ```python
    model.to(device)  # 将模型移到 GPU 或 CPU，device 是 "cuda" 或 "cpu"
    ```

    

  * 训练数据：训练数据（例如**输入特征、标签**等）也需要放到 GPU 上，特别是当训练过程需要频繁地在 GPU 和 CPU 之间传输数据时，可能会成为性能瓶颈。**所有输入数据（如图片、文本数据）和对应的标签都应被放在 GPU 上**，以提高训练效率。

    ```python
    inputs = inputs.to(device)  # 使用 .to() 更通用
    labels = labels.to(device)  # 使用 .to() 更通用
    ```

    还有比如说与我目前方向相关的图数据：

    ```python
    g = g.int().to(device)
    ```

    

  * 损失函数中的相关数据：损失函数中的相关数据（例如，模型预测的输出和真实标签）也应放在 GPU 上进行计算。否则，如果损失函数中的数据仍然在 CPU 上，PyTorch 会自动将它们传输到 GPU，但这会导致性能损失。

  * 优化器的状态（通常由优化器自动管理）：优化器（如 `Adam`, `SGD`）本身的参数通常不会显式地放到 GPU 上，因为它会自动跟踪模型参数的梯度。然而，**如果你自己实现了优化器，或优化器的状态变量需要与模型参数一起计算，** 这些状态（例如动量等）也需要放到 GPU 上。例如，在使用 `torch.optim` 时，优化器会**自动处理 GPU 迁移**：
    ```python
    optimizer = torch.optim.Adam(model.parameters())  # 优化器会自动使用模型所在设备的参数
    ```

#### 交叉验证

* 框架如下

```python
for cross_id in range(args.cross_num):
    '''
    中间处理
    包括预处理、模型保存路径设置、其他提取数据、数据分割
    cuda 设置
    '''
   if cross_id == 0:
            print('---------Dataset Statistics---------')
            print('一些数据信息')
            print('-------------Pretraining------------') # (或者这里提示 training)
        
    print(f'cross: {cross_id}')
    print('------------')

   	print('Model Pretraining')
    '''
    其他处理
    '''
```

#### 早停机制（用类实现）

* 最基础的需要记录 7 项

  (1) early_stop (2) patience (3) counter (4) best_score (5) best_epoch (6) save_path (7) min_epoch

* 具体实现

```python
class EarlyStopping_simple:
    def __init__(self, patience=50, save_path=None, min_epoch=-1):
        self.patience = patience
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_epoch = None
        self.save_path = save_path
        self.min_epoch = min_epoch

    def step(self, acc, epoch, model):
        score = acc
        if epoch < self.min_epoch:
            return self.early_stop
        if self.best_score is None:
            self.best_score = score
            self.best_epoch = epoch
            self.save_checkpoint(model)
        elif score < self.best_score:
            self.counter += 1         
            if self.counter >= self.patience:
                self.early_stop = True
                print()
                print(f'EarlyStop at Epoch {epoch} with patience {self.patience}')
        else:
            self.best_score = score
            self.best_epoch = epoch
            self.save_checkpoint(model)
            self.counter = 0
        return self.early_stop

    def save_checkpoint(self, model):
        '''Saves model when validation loss decrease.'''
        torch.save(model.state_dict(), self.save_path)
```



#### 损失函数与模型之间的代码组织

我们可以先观察一下 `licap` 之间对损失函数以及模型之间的代码处理

```python
class Predicate_GAT(nn.Module):
    def __init__(self, args, g, in_dim, hidden_dim , out_dim, num_heads, rel_num, rel_dim, 
                 loss_function=None,
                 loss_1_fcn=None,
                 loss_2_fcn=None,
                 train_important_idx=None,
                 train_normal_idx=None,
                 imp_bin_idx2node_idx=None,
                 imp_node_idx2bin_idx=None,
                 imp_node_coeff=None):
        super(Predicate_GAT, self).__init__()
        self.layer1 = MultiHead_Predicate_GAT_Layer(g , in_dim, hidden_dim, rel_dim, num_heads)
        self.layer2 = MultiHead_Predicate_GAT_Layer(g, hidden_dim*num_heads, out_dim, rel_dim, 1)

        self.loss_fn = loss_function
        self.loss_1_fcn = loss_1_fcn
        self.loss_2_fcn = loss_2_fcn
        

        self.train_important_idx = train_important_idx
        self.train_normal_idx = train_normal_idx
        
        self.imp_bin_idx2node_idx = imp_bin_idx2node_idx
        self.imp_node_idx2bin_idx = imp_node_idx2bin_idx
        self.imp_node_coeff = imp_node_coeff

        self.loss_eta1 = args.loss_eta1
        self.loss_eta2 = args.loss_eta2

        # Relation Embedding
        self.rel_emb = nn.Embedding(rel_num, rel_dim) 


    def forward(self, node_feats, edge_types, idx=None):

        edge_feats = self.rel_emb(edge_types) # [num_edges, rel_dim]

        h = self.layer1(node_feats, edge_feats)
        h = F.elu(h)
        h = self.layer2(h, edge_feats)

        # caculate_loss            
        embed_all = h # [N_node, dim]
                     
        imp_bin_centroids, bin2centroids = return_centroids(embed_all, self.imp_bin_idx2node_idx, self.train_important_idx) # [bin_num, dim]
                
        imp_node_centroid = return_imp_node_centroid(self.imp_node_idx2bin_idx, bin2centroids, self.train_important_idx) # [imp_num, dim]    
        embed_normal = embed_all[self.train_normal_idx] ### mod sample by constant
                
        loss_1 = self.loss_eta1 * self.loss_1_fcn(embed_all[self.train_important_idx], embed_normal)

        loss_2 = self.loss_eta2 * self.loss_2_fcn(embed_all[self.train_important_idx], imp_bin_centroids, imp_node_centroid, self.imp_node_coeff)

        loss = loss_1 + loss_2

        return h, loss, loss_1, loss_2
```

我们可以一码多用

* `self.training`

> `self.training` 是 **PyTorch 模块（nn.Module）自带的布尔属性**，用于指示当前模型是否处于“训练模式（training mode）”。
>
> 它的值由以下两个方法控制：
>
> | 方法            | 作用                                        |
> | --------------- | ------------------------------------------- |
> | `model.train()` | 将模型设为训练模式（`self.training=True`）  |
> | `model.eval()`  | 将模型设为评估模式（`self.training=False`） |

我们可以在我们的**训练模型（`model`）**中**这样设置代码来更好地处理损失**

```python
class My_Model(nn.Module):
	'''
    处理的具体内容
    '''

    if self.training:
        '''
        ...
        '''
       return logits, loss
    else:
        return logits
```













对于比较复杂的损失，我们直接写一个类对其进行封装处理

这段代码将损失的计算直接搬到了模型的 `forward` 函数中，也就是说，模型每一次前向传播计算处理完数据之后，直接进行了损失计算，即我们在 `Predicate_GAT` 类中封装了损失计算逻辑，对于比较复杂的损失计算，这种设计时合理的。

同时我们需要在**定义模型实例时**传入计算损失函数**需要用到的辅助数据**如 `imp_bin_idx2node_idx` 等），这些是与任务特定信息相关的参数。将这些数据封装在模型的类中，是一种常见的做法，可以在整个训练过程中**保持一致性**。损失函数的计算依赖于其 `forward` ，而 `forward` 需要使用的数据则是在定义模型实例时**传入的辅助数据**



==事实上，我个人认为，将损失函数的计算写在外部是更好的选择==

> 将损失计算移到外部进行，是一种常见的做法，尤其适用于那些**损失函数较复杂**或者需要灵活调整的情况。它有助于代码的模块化、灵活性和复用性，并且使得模型的实现更加专注于核心任务，即图数据的处理和嵌入计算，放在外面可以减小这个类的实例的**调入调出的开销，提高内存的使用率**。我们可以根据任务需求选择是否采用这种结构化的方式。

即，我们可以直接在训练循环中，使用模型的输出（`embed_all`）来计算损失，如下所示

```python
# 假设已经实例化了模型 Predicate_GAT 和损失函数
model = Predicate_GAT(args, g, in_dim, hidden_dim, out_dim, num_heads, rel_num, rel_dim)

# 训练过程
for epoch in range(num_epochs):
    model.train()
    
    # 获取节点特征和边特征
    node_feats = ...
    edge_types = ...
    
    # 前向传播得到嵌入表示
    embed_all = model(node_feats, edge_types)
    
    # 损失计算
    imp_bin_centroids, bin2centroids = return_centroids(embed_all, imp_bin_idx2node_idx, train_important_idx)
    imp_node_centroid = return_imp_node_centroid(imp_node_idx2bin_idx, bin2centroids, train_important_idx)
    embed_normal = embed_all[train_normal_idx]
    
    loss_1 = loss_eta1 * loss_1_fcn(embed_all[train_important_idx], embed_normal)
    loss_2 = loss_eta2 * loss_2_fcn(embed_all[train_important_idx], imp_bin_centroids, imp_node_centroid, imp_node_coeff)
    
    loss = loss_1 + loss_2
    
    # 反向传播和优化
    loss.backward()
    optimizer.step()

```

#### 网络搭建

* 个人感觉，一般来讲，新框架的搭建一般要写三个类（1）最底层的就是一个卷积层（2）第二个类作用在第一个类的基础上，一般用来控制层数或者是头数（3）第三个类作用在第二个类的基础上，会添加一些其他的组件（比如说优化的部分，损失函数，协同注意力融合等模块）



#### 如何在图上进行采样



### 经验与造轮子

#### 损失函数

* 最终得到的这个标量损失最后一步**一般是由一组向量推来**，**一般情况下我们使用 `.mean` 来得到损失而不是用 `.sum` 得到损失**（注意，我们一般情况下不对向量进行反向传播，即我们要门对其做 `.mean` 处理，要么对其做 `.sum` 处理）

  * 思考为什么

  > （1）保持梯度稳定性
  >
  > 如果使用 `.sum()`，那么损失的大小会随 batch size 增大而增大，导致梯度也变大。例如：
  >
  > ```python
  > import torch
  > 
  > x = torch.randn(10, requires_grad=True)  # 10个样本
  > loss = x**2  # 每个样本的损失
  > loss_sum = loss.sum()  # 直接求和
  > loss_mean = loss.mean()  # 计算均值
  > 
  > loss_sum.backward()  # 计算梯度
  > print(x.grad)  # 梯度较大
  > 
  > x.grad.zero_()  # 清空梯度
  > 
  > loss_mean.backward()  # 计算梯度
  > print(x.grad)  # 梯度较小，数值稳定
  > ```
  >
  > **现象：** `loss_sum` 的梯度比 `loss_mean` 大 **10 倍** （即 `batch_size` 倍），因为 `.sum()` 直接把所有样本的损失加起来，导致梯度变大。
  >
  > 如果 batch size 变化，梯度的大小也会变得不稳定，而 `.mean()` 可以保持梯度在一个稳定的范围内，使得学习率不需要调整。
  >
  > （2）与学习率无关
  >
  > 在梯度下降中，学习率 (`lr`) 决定了参数更新的步长。如果我们使用 `.sum()`，梯度的数值会随着 batch size 改变，导致学习率需要调整：
  >
  > - 用 `.sum()`，如果 batch size 变大，梯度变大，可能导致梯度爆炸，**需要手动缩小学习率**。
  > - 用 `.mean()`，梯度大小不变，学习率可以保持一致，不需要频繁调整。
  >
  > 因此，`.mean()` 使得**同样的学习率适用于不同的 batch size**，从而提高了模型的稳定性和可移植性。
  >
  > （3）使不同 batch 的损失具有可比性
  >
  > 假设我们有两个 batch，batch size 分别是 32 和 16，如果使用 `.sum()`，那么 batch1 的总损失比 batch2 的损失大了一倍，这不合理，因为两个 batch 的样本**平均损失是一样的**。但如果使用 `.mean()`，尽管两个 `batch` 的 `batch_size` 不一样，但是它们的梯度却没有与 `batch_size` 产生强线性关系，使得模型训练更稳定。
  
* 自己写了一个同构图上的多头谓词 `GAT` （更加并行）==**核心是理解注意力系数的更新操作（需要一点线代的洞察力！！）**==

```python
class GAT(nn.Module):
    def __init__(self, g, in_dim, out_dim, num_heads, rel_dim):
        super(GAT, self).__init__()
        self.g = g
        self.fc = nn.Linear(in_dim, num_heads * out_dim)
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.num_heads = num_heads

        self.attn_l = nn.Parameter(torch.empty(1, num_heads, out_dim))
        self.attn_mid = nn.Parameter(torch.empty(1, num_heads, rel_dim))
        self.attn_r = nn.Parameter(torch.empty(1, num_heads, out_dim))
        self.reset_parameters()

        
    def reset_parameters(self):
        gain = nn.init.calculate_gain('relu')
        nn.init.xavier_normal_(self.fc.weight, gain = gain)
        nn.init.xavier_normal_(self.attn_l, gain = gain)
        nn.init.xavier_normal_(self.attn_mid, gain = gain)
        nn.init.xavier_normal_(self.attn_r, gain = gain)

        
    def edge_attention(self, edges):
        return {'e': F.leaky_relu(edges.src['e_l'] + edges.edata['e_mid'] + edges.dst['e_r'])}  # (E, num_heads, 1)
    
    
    def message_func(self, edges):
        return {'e': edges.data['e'], 'z': edges.src['z']}

    
    def reduce_func(self, nodes):
        h = torch.sum(nodes.mailbox['e'] * nodes.mailbox['z'], dim = 1) # (N, num_heads, out_dim)
        return {'h': h}


    def forward(self, h, p):
        z = self.fc(h).view(-1, self.num_heads, self.out_dim)   # (N, num_heads, out_dim)
        p = p.unsqueeze(dim = 1).repeat(1, self.num_heads, 1)   # (E, num_heads, out_dim)
        e_l = (z * self.attn_l).sum(dim = -1, keepdim = True)  # (N, num_heads, 1)
        e_mid = (p * self.attn_mid).sum(dim = -1, keepdim = True)  # (E, num_heads, 1)
        e_r = (z * self.attn_r).sum(dim = -1, keepdim = True)  # (N, num_heads, 1)
        g.ndata.update({'e_l': e_l, 'e_r': e_r, 'z': z})
        g.edata.update({'e_mid': e_mid})
        g.apply_edges(self.edge_attention)

        e = g.edata['e']    # (E, num_heads, 1)
        g.edata['e'] = dgl.ops.edge_softmax(g, e)

        g.update_all(
            self.message_func,
            self.reduce_func
        )

        return g.ndata.pop('h') # (N, num_heads, out_dim)
    

class MultiHeadGAT(nn.Module):
    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads, rel_dim, rel_num, merge = 'cat'):
        super(MultiHeadGAT, self).__init__()
        self.layer1 = GAT(g, in_dim, hidden_dim, num_heads, rel_dim)
        self.layer2 = GAT(g, num_heads * hidden_dim, out_dim, 1, rel_dim)
        self.p_embed = nn.Embedding(rel_num, rel_dim)

    def forward(self, node_feats, edge_types):
        edge_feats = self.p_embed(edge_types)
        h = self.layer1(node_feats, edge_feats) # (N, num_heads, out_dim)
        h = h.view(-1, self.layer1.num_heads * self.layer1.out_dim)
        h = F.elu(h)
        h = self.layer2(h, edge_feats)  # (N, num_heads, out_dim) (N, 1, out_dim)
        h = torch.mean(h, dim = -1)
        return h
```



### 	LICAP

==在进行训练时，为了公平比较，**语义特征和结构特征被连接起来**（~~之前的实验并没有做到这一点，而是只只选取了语义特征或者结构特征~~）作为节点输入特征==

与以往知识图谱上的 NIE 方法不同，这项工作引入了现实世界中对重要节点（即具有高重要性分数的节点）偏好的潜在先验知识。**为了注入这种先验知识，提出了一种新颖的采样策略，结合对比学习，利用可用的节点重要性分数预训练节点嵌入**。还需注意的是，所提出的 LICAP 是一种**插件式方法**，可以集成到以前的 NIE 方法中，而不是一种新的特定 NIE 方法。

创新点：

1. 提升了 `embedding` 的质量

2. label 感知分组将连续分数划分成有序区间以**生成对比样本**；分箱机制，**顶层节点优先 分层采样机制**

   这么做的其中一个原因是，我们完全不需要在预训练阶段就估计节点重要性，这一任务将在下游实现；我们在预训练阶段的目的仅是为了得到更好的嵌入表

   这样一来，原本并非为回归问题设计的对比学习，现在可以采用对比样本对嵌入进行预训练。

3. 谓词 GNN
4. 通过联合最小化两个对比损失优化节点嵌入。



细节：

1. 顶层节点优先，分层采样机制

   top-bin 与 non-top-bin 根据 `important ratio`  $\gamma$ 划分，代码中是取 0.1

   ==理解一下 InfoNCE 损失函数==

2. 划分为第一级对比样本与第二级对比样本（分别对应 $L_1$ 和 $L_2$ 的 loss）

   在顶层区间中，将每个节点与顶层原型（即图 3 中的三角形）进行正对比。顶层原型是通过对所有顶层节点的嵌入进行元素级平均得到的。对于负对比，我们将从非顶层区间中随机采样的非顶层节点，作为每个顶层节点的负样本对。

   对于更细区间中的每个顶级节点（这里的更细区间是指将**顶层区间**划分为更细区间），其正对比样本被定义为该更细区间的原型（例如，图 4 中包含红色节点的更细区间的红色三角形），这同样是通过对该更细区间内节点的嵌入进行元素级平均得到的。至于负对比样本，它们分别也是其余更细区间的原型，我们设计了一种重新加权负采样机制，以保持这些更细区间之间的相对顺序。这种重新加权负采样机制基于这样一种直觉：来自距离更远区间的样本更不相似（或更不接近）。因此，我们引入一个接近系数 $\beta$ 来对负对比对进行重新加权，使得接近系数越大，相应的负样本对项在分母中的影响就越大。

   第一级对比样本和 $L_1$ 损失旨在更好地将顶层节点与非顶层节点区分开来，而第二级对比样本和 $L_2$ 损失则试图通过保持更细区间之间的相对顺序，来更好地区分顶层区间内的顶层节点。





疑惑点：

1. 这么做对比学习的目的是什么？

2. 这个接近系数 $\beta$ 到底有什么用？为什么要引入它，是用来区分什么的
   个人感觉是，正样本对都在同一层，所以正样本对之间是没有差异的，但是负样本对在不同层，要体现层与层之间的差异，用一个接近系数 $\beta$ 来衡量

3. 为什么要设计 $L_1$ 和 $L_2$ 损失，如果只是想找更优质的节点，直接降序排序得到不就行了吗？这么做的意义是什么？其更深层的原理和机制是什么。论文中提到要通过使用InfoNCE损失来结合对顶级节点偏好的先验知识来预训练节点嵌入，如何理解？我到现在还是无法理解这种损失到底是在做什么？？（还是得还之前 `deepwalk` 的账啊）

   突然之间秒懂，是要根据损失去调整嵌入特征 $\mathbf{h}_i$， 获得更优质的嵌入特征！比如获得的特征能够更好地区分 top-bin 中地节点和 non-top-bin 中的节点；同时也能更好地区分 top-bin 中其他不同层之间的节点，**通过对比学习和结合先验知识，生成更优质的节点嵌入，为后续的节点重要性估计任务提供更好的基础。**



#### 预备知识点

* 预训练范式

  * > 预训练范式（Pre-training Paradigm）是深度学习领域的一种模型训练方法，核心思想是通过**分阶段训练**来提升模型性能：
    > **先在大规模通用数据上进行无监督或自监督的预训练**，学习通用特征表示；**再在特定任务的小规模数据上进行微调**（Fine-tuning），适应下游任务。这一范式显著降低了数据标注成本，推动了自然语言处理（NLP）、计算机视觉（CV）等领域的突破。

* 对比学习，无监督学习包括对比式学习与生成式学习，**对比学习是无监督学习的一种**

  * > 在重要节点识别任务中，对比学习的主要思想是：
    >
    > 1. **构造正样本（Positive Sample）**：通常是**同一节点的不同视图**，或者**同类别的重要节点**。
    > 2. **构造负样本（Negative Sample）**：通常是**普通节点**，或者**不同类别的节点**。
    > 3. **优化目标**：让重要节点的表示尽可能靠近，而普通节点远离它们，以便更好地区分节点的重要性。
    >
    > 常见的方法包括：
    >
    > - **基于全局结构的对比**：让重要节点在全局网络中保持一致性。
    > - **基于局部子图的对比**：让重要节点的局部结构与其重要性保持一致。
    > - **基于动态变化的对比**：在动态图中，学习重要节点随时间变化的稳定性。
    
  * InfoNCE 将一个正样本与多个负样本进行区分，已成为更受欢迎的对比学习损失函数。该文章在节点重要性估计（NIE）问题中采用对比学习，通过使用 InfoNCE 损失函数，融入对重要节点（top nodes）偏好的先验知识，来预训练节点嵌入。

* 二项分布概率质量函数

* 相较于之前的相关工作，licap 这个工作使用了新的数据集 `GA16K` 和额外的回归度量作为基准

#### 理解数据

##### `fe15k_rel.pk`

* `fb15k_rel.pk`：这是一个知识图谱数据，表示**图谱的结构特征**，以字典的形式保存，涵盖了 `edges: tuple`， `edge_type: tensor`, `labels: tensor`, `feature: tensor`, `invalid_masks: tensor`

  具体的形式如下
  ```python
  {'edges': (tensor([ 345, 9796,  848,  ..., 5338, 4277, 1098]),
    tensor([10667,  1985,  6425,  ..., 12077, 11101, 13898])),
   'edge_types': tensor([  0,   1,   2,  ...,   9,  26, 166]),
   'labels': tensor([ 9504., 10199.,  9030.,  ..., 41222., 31642., 44935.]),
   'features': tensor([[-0.2106,  0.3095,  0.6127,  ..., -0.0039, -0.2529,  0.1002],
           [-0.2618,  0.6114, -0.2634,  ...,  0.3543, -0.0417, -0.0791],
           [ 0.1157,  0.0885, -0.1008,  ...,  0.1172,  0.3553, -0.1994],
           ...,
           [ 0.2731,  0.4277,  0.4038,  ...,  0.4685,  0.4484,  0.4826],
           [-0.2515, -0.2345,  0.9372,  ..., -0.1647,  0.3712, -0.0693],
           [ 0.2306, -0.1211, -0.1945,  ...,  0.5564,  0.0363, -0.1344]]),
   'invalid_masks': tensor([0, 0, 0,  ..., 0, 0, 0])}
  ```

  * 节点数量为 14,951，边的数量为 592,213，谓词种类为 1,345，有将近 14,105 (94.3%) 的节点是有节点特征的（64维嵌入）
  * `edges`: `tuple` ，表示源点与汇点的索引
  * `edge_types: tensor`，表示每条边的**谓词种类**
  * `labels: tensor`，表示节点重要性（node importance）的得分，通过从维基百科对收集到的真实世界重要性值（如FB15K的页面浏览量）进行对数转换来获得。（有时间去了解一下具体是怎么收集的）
  * `features：tensor  (num_nodes, 64)`，表示每个节点的词嵌入特征 ，通过 `node2vec` 算法得到节点特征
  * `invalid_masks`, 指示哪些**节点**或边需要被忽略或排除在计算之外。经过验证 `invalid_masks` 为 `1` 的节点其 `labels` 为 `0`, 我们不使用这些数据进行训练

##### `fb_lang.pk`

* `fb_lang.pk` ：这是一个仅关于节点的数据，表示**图谱节点的语义特征**，是一个二维 `np.array` 
  具体形式如下

  ```python
  array([[-0.07588089, -0.15141135, -0.13396032, ..., -0.08600746,
          -0.17194201,  0.53592861],
         [-0.02278661, -0.29997835, -0.0073817 , ...,  0.02436821,
          -0.02998137,  0.46098486],
         [-0.15221825, -0.06115236, -0.34801662, ..., -0.12346848,
          -0.14316572,  0.39701506],
         ...,
         [ 0.01512893,  0.186928  , -0.18825455, ..., -0.17741039,
          -0.02106529,  0.62954003],
         [-0.21668366, -0.01483662, -0.10437213, ...,  0.15704495,
          -0.13830011,  0.55147076],
         [-0.05817803,  0.12917031, -0.13514727, ..., -0.02458374,
          -0.02240661,  0.38673902]])
  ```

  论文中提到其通过 Transformer-XL 生成，维度为 **128**。但是实际数据上却是**768 维**？语义信息通常通过自然语言处理技术（如Transformer-XL）从节点的文本描述中提取，用于补充知识图谱的结构信息（如节点间的连接关系）。例如，在电影知识图谱（TMDB5K）中，语义信息可能包括电影的剧情简介、演员或导演的文本描述；在学术知识图谱（GA16K）中，可能是论文的标题或摘要。

  **语义信息和结构信息被作为两个独立的输入通道（例如在 RGTN 模型中），共同用于节点重要性估计任务。**



#### 理解预处训练过程

* 可能需要用到的函数

```python
np.round()
np.where()		# 注意返回的是一个 `tuple` 需要使用 [0] 进行索引
np.intersect1d(arr1, arr2, assume_unique = True)	# assume_unique = True 表示假设arr1和arr2都是唯一的，可以加速计算
np.random.choice(arr, size)

torch.sort()	# 两个返回值，分别是值和索引
```



* 我将学习到交叉验证、早停机制、划分正例样本与负例样本、分桶机制

* 设置参数与超参数，设置随机种子

* 设置各种保存路径，一般都会保存在 `checkpoints` 中

* 开始进入交叉验证大循环：
  * 进入 `load_data()` 函数开始装载与提取数据（涉及三种情况（1）只提取节点语义特征（2）提取两者特征并将它们拼接（3）提取两者特征但不将它们拼接）
    * 提取出对应的特征、掩码等数据
    * 处理节点的入度：对其进行 norm 处理（归一化因子），然后将归一化因子保存到**图的节点数据中**（`g.ndata['norm'] = norm`），并使用 `g.apply_edges()` 将每一个汇点的 `norm` 添加到对应的边上。
    * 标签的对数变换
    * 数据集划分（70% for train, 10% for val, 20% for test）
      * 五折交叉验证，==**这个操作手法需要学习一下（交叉验证）**==
    * 返回 `hg, edge_types, edge_norm, rel_num, node_feats, labels, train_idx, val_idx, test_idx`

  * 进入 `find_imp_idx()` 函数寻找重要节点（这是该论文 `LICAP` 的核心概念，用于指导**对比学习**的样本生成策略）。==**这里的操作手法需要学习一下（划分正负例样本）**==

    * 这里最后刻意将 `normal` 按照节点 50 % 采样。（从代码中看， normal 节点的数量大概是 important 节点数量的两倍）

  * 进入 `et_imp_bin_idx2node_idx()` 函数，根据节点标签的数值范围，将目标节点 `target_idx` 分桶，并记录哪些桶是有效的。其主要作用是**对重要节点进行分段索引**，可能用于后续的分析或采样。==**这里的操作手法需要学习一下（分桶操作）**==

  * 进入 `return_bin_idx2bin_coeff()` 函数**计算每个 bin（桶）的权重系数**，并存储在 `bin_coeff` 字典中。其核心逻辑是使用**二项分布概率质量函数（PMF，Probability Mass Function）**来计算不同 bin 之间的权重。

    * 理解其原理，理解 $k$ 和 $n$ 是如何选取的

    * 应用场景如下：
  
      **在重要节点识别中**，可能用于**根据 bin 的位置，为不同 bin 赋予不同的加权系数** 即衡量不同 bin 之间的**相对影响力**。
  
      **在对比学习或采样任务中**，可以作为权重分布，引导模型更关注某些 bin。
  
      通过利用二项分布的 **概率质量函数** 来衡量节点间（当然这里是 bin ）的相关性和影响力，尤其在一些 **图神经网络** 或 **基于距离的加权策略** 中得到广泛应用。
  
  * 进入 `return_imp_node_coeff()` 函数，**提取重要节点对应的系数**：根据 `imp_idx` 中的节点索引，找到每个节点对应的 bin 索引，进而提取每个节点所属 bin 的系数。**拼接系数**：将所有提取的系数拼接成一个大张量，并返回。
  
  * 处理自环问题并且更新 `edge_types` ，`rel_num` `n_edges`
  
  * 开始进行 模型 的预训练
  
    * 创建三个损失模块
  
    * 隐藏层维度为8，头为8，谓词嵌入的维度为10
  
    * 进入谓词嵌入 GAT 模型 `Predicate_GAT`（==**这个一定要掌握！！**==）
  
      * `in_dim = 64`, `hidden_dim = 8`, `out_dim = 64`, `rel_dim = 10`
  
    * 进入早停模块初始化
  
    * 进入 `return_centroids()` 函数: **计算一组节点嵌入（embeddings）的质心（centroid）**,之所以被称之为质心是因为它会分别计算每个 `bin` 中对应节点特征的均值，即为该 `bin` 的质心
  
      > **计算 bin 内所有节点的质心**（均值）。
      >
      > **存入 `bin2centroids`**，用于单独查询每个 bin 的质心。
      >
      > **拼接 `imp_bin_centroids`**，形成所有 bin 质心的矩阵。
      >
      > **跳过空 bin**，避免计算错误。
  



#### 理解 `downstream` 过程

* 代码中首先传入未处理过的数据（嵌入向量），即默认不使用经过 `pretrain` 的数据进行训练

* 接着传入经过预处理之后的嵌入向量。

  * 其中若针对 `rgtn` 进行下游任务的训练，则会使用结构和语义两种被预处理过的信息进行训练

  * 若针对其他模型进行下游任务的训练，那么代码是无法跑通的，因为它的 `features` 在使用之前并没有进行定义，疑似作者每轮都是手动去操控的（这个地方我们可以修改一下）

    添加这一行 `features = semantic_feat if args.pretrain_model == 'pregat_semantic' else struct_feat`

* 加载模型正常训练然后评估



#### 理解两个损失函数

* 自己尝试写一下，要很熟悉矩阵以及张量操作
* 太猛了，大概懂了，**先从损失函数入手**，在训练时处理损失函数需要的数据
* 思考一下 $\text{Loss}_2$ 中的系数设置从直觉上以及数学上设计的合理性
  * 数学上和哲学上都是合理的，首先 $\text{Loss} = -\log \frac{A}{A+B}$ 就是一个恒大于 0 的数，当 $A >> B$ 的时候，损失越接近 $0$ ，系数 $\beta_{m,n}$ 的出现使得物理上距离更远的两个 `bin` 在数值得出的 `B`相较于 `A` 会更小，符合损失函数所要传达的意思。

#### 理解 licap 的时间复杂度





#### 理解实验 base line 的选取设置以及具体的超参设置

有三种方法

* 无监督方法：核心是 **PageRank（PR）**和**个性化 PageRank（PPR）**算法，它们在不依赖训练标签的情况下评估节点重要性。
  * 使用 `NetworkX` 包
* 非 GNN 的监督方法：**线性回归（LR）**和**多层感知机（MLP）**是两种经典的机器学习模型。由于节点重要性估计实际上是一个回归问题，所以它们可被应用于该任务。
  * 使用 `scikit-learn` 包
* 基于图神经网络（GNN）的监督方法包含两个子集，这些方法能够同时利用图的拓扑结构和节点特征。
  - **第一类：通用 GNN 模型**：是经过修改以适用于节点重要性估计问题的通用 GNN 模型。其中，选择 GCN（图卷积网络）作为谱域 GNN 模型的代表，它通过对图的拉普拉斯矩阵进行谱分解来学习节点表示；GraphSAGE（图采样与聚合编码器）作为空域 GNN 模型的代表，它通过采样和聚合邻居节点特征来生成节点嵌入；RGCN（关系图卷积网络）作为处理关系图数据的 GNN 模型代表，专门用于处理具有多种关系类型的图数据，能够更好地捕捉关系信息。
    - 使用 `DGL` 包并设置一个 64 维的 隐藏层
  - **第二类：特定于 NIE 的 GNN 模型**：采用 GENI 和 RGTN 这两种在知识图谱节点重要性估计任务中达到当前最优性能的模型进行比较和基准测试。GENI 利用图注意力机制和邻居分数聚合来推断节点重要性；RGTN 则使用关系图变压器，在学习过程中融入节点语义信息（即节点的文本描述）来进行节点重要性估计 。
    - 使用这个[仓库](https://github.com/GRAPH-0/RGTN-NIE)中的代码实现

| 超参数                | 取值范围或具体值             | 备注                                                        |
| --------------------- | ---------------------------- | ----------------------------------------------------------- |
| 重要比率 $\gamma$     | [0.01, 0.05, 0.1, 0.2]       | 用于LICAP中对节点进行分层采样（important-ratio）            |
| 损失平衡比率 $\eta_2$ | [0.5, 1, 10, 50]             | 与 $\eta_1$（值为1）一起平衡两种对比损失（loss-eta2）       |
| InfoNCE温度参数 $T$   | 0.05                         | 用于计算对比损失                                            |
| PreGAT或GAT隐藏层维度 | 8                            | 设置模型隐藏层维度                                          |
| PreGAT或GAT头数       | 8                            | 采用多头注意力机制的头数                                    |
| PreGAT谓词维度        | 10                           | 设置谓词嵌入的维度                                          |
| 学习率                | [0.0005, 0.001, 0.005, 0.01] | 对LICAP增强的NIE方法和原始NIE方法均进行搜索（weight-decay） |



| 数据集处理及评估相关设置 | 详情                                                         |
| ------------------------ | ------------------------------------------------------------ |
| 结构特征提取方法         | 使用Node2Vec从输入图中提取每个节点的结构特征                 |
| 语义特征获取方式         | FB15K和TMDB5K语义特征从RGTN GitHub库克隆；GA16K语义特征通过运行Transformer-XL获取 |
| 预训练结构特征维度       | 64                                                           |
| 预训练语义特征维度       | 128（实际上代码中给出的是768，好奇怪）                       |
| 分组箱长度               | FB15K：1.0；TMDB5K：0.5；GA16K：1.0                          |
| 评估方式                 | 五折交叉验证，报告回归指标和排序指标                         |



#### 理解实验的评估指标

在节点重要性估计的评估中，需要同时考虑重要性得分预测和重要性得分排序。因此，我们同时使用回归指标和排序指标，其正式定义如下。

-  **回归指标**：由于节点重要性估计问题的真实标签是非负实数，因此使用回归指标进行评估是很自然的。我们使用两个常用的回归指标，即均方根误差（RMSE）和平均绝对误差（MedianAE），来量化预测的重要性得分与相应真实标签的接近程度。值越低表示性能越好。    
  - RMSE衡量预测得分与真实得分之间的平均距离。假设有$n$个样本，用$s^{*}$和$s$分别表示预测得分和实际得分，其正式公式为：$RMSE =\sqrt{\frac{\sum_{i = 1}^{n}(s_{i}^{*} - s_{i})^{2}}{n}}$   
  - MedianAE衡量预测得分与真实得分之间绝对差异的中位数。与RMSE相比，它对异常值更具鲁棒性，因为它关注的是中位数预测误差，而不是所有样本的总体误差。MedianAE的正式定义如下：$MedianAE = median(|s_{1}^{*} - s_{1}|, \cdots, |s_{n}^{*} - s_{n}|)$ 
-  **排序指标**：为了从另一个角度评估性能，我们遵循文献[4]，额外采用两个排序指标：归一化折损累计增益（NDCG）和斯皮尔曼等级相关系数（SPEARMAN）。值越高表示性能越好。    
  - NDCG衡量排序列表的质量，它是折损累计增益（DCG）的扩展。DCG同时考虑了项目的相关性及其在排序中的位置。在根据预测得分$s^{*}$对具有真实得分$s$的项目列表进行排序后，用$s_{r}$表示第$r$个项目的真实得分。位置$k$处的DCG（DCG@k）[4]可以定义为：$DCG @ k=\sum_{r = 1}^{k} \frac{s_{r}}{\log _{2}(r + 1)}$    
  -  NDCG通过将DCG除以理想DCG（IDCG）进一步进行归一化。位置$k$处的IDCG（IDCG@k）是前$k$个位置中可能的最大DCG。根据这些定义，位置$k$处的NDCG（NDCG@k）可以通过以下公式计算：$NDCG @ k=\frac{DCG @ k}{IDCG@ k}$   
  -  SPEARMAN是衡量预测得分$s^{*}$与真实得分$s$之间等级相关系数的指标。在将得分$s^{*}$和$s$分别转换为相应的等级$r^{*}$和$r$后，我们将$r^{*}$和$r$的平均值定义为$\bar{r}^{*}$和$\bar{r}$。SPEARMAN可以表示为：$SPEARMAN =\frac{\sum_{r}(r^{*}-\overline{r^{*}})(r-\overline{r})}{\sqrt{\sum_{r}(r^{*}-r^{*})^{2}} \sqrt{\sum_{r}(r-\overline{r})^{2}}}$    
  -  OVER是预测的重要节点与真实重要节点之间的重叠率。用$S_{top - k }^{*}$表示预测的前$k$个重要节点的集合，$S_{top - k}$表示真实的前$k$个重要节点的集合。$|·|$表示集合的基数。OVER@k的计算公式为：$OVER @ k=\frac{|S_{top - k}^{*} \cap S_{top - k}|}{k}$ 





#### 理解实验的具体内容

**研究问题设定**  
提出7个研究问题，涵盖LICAP对提升最先进NIE方法性能的作用、关键组件的有效性、预训练不同特征的效果、超参数影响、对高重要性节点的感知能力以及对其他NIE方法性能的提升效果等方面。这些问题为后续实验和分析提供了明确方向。

**知识图谱上的节点重要性估计**  
对比LICAP与多种基线方法的性能。结果显示，LICAP与RGTN结合在所有指标上均优于基线方法。  

- 无监督方法（如PR和PPR）由于无法利用标签进行监督，性能较差；  
- GNN-基于方法能够同时利用节点特征和图结构，表现更优。  
在基线方法中，RGTN表现突出，但LICAP能显著提升RGTN在回归指标上的性能，充分展现了LICAP的优势。

**消融研究：LICAP对比损失的影响**  
通过构建基于RGTN的LICAP变体进行对比实验，验证了两个对比损失的有效性。  
实验结果表明，同时包含 $L_1$ 和 $L_2$ 损失的LICAP - $L_1 + L_2$ 表现最佳。  

- 进一步分析发现，$L_1$ 单独作用时效果通常优于 $L_2$，这是因为 $L_2$ 单独使用时过于关注细节，使得学习过程困难。  
- 此外，随机采样的LICAP - r.d.方法效果较差，这证明了顶部节点优先采样策略的有效性，突出了利用先验知识对提升NIE方法性能的重要性。

**消融研究：谓词感知GAT的影响**  
比较LICAP - PreGAT、LICAP - GAT和原始RGTN的性能。  
研究发现LICAP - PreGAT性能最优，尤其在具有更多谓词的FB15K数据集上优势更为明显。这表明谓词感知机制能够有效区分不同的谓词，捕捉其中有意义的信息，从而提升模型性能。如果在谓词数量较少的知识图上，则 PreGAT 将近退化为 GAT，效果可能并不好（**但事实上，我发现即便在谓词数量更多的 fb15k 数据集上，PreGAT的提升也并不明显...**）

**预训练不同输入通道**  
探究LICAP对不同输入通道（结构特征、语义特征、两者结合）的预训练效果。  

RGTN明确地将**结构特征**和**语义特征**视为两个单独的通道。

研究结果显示，单独预训练结构或语义特征通常比同时预训练两者效果好。这可能是因为RGTN的两个输入通道需要一定的差异性，以更好地利用多源特征。  

这表明按照相同的 LICAP 架构同时预训练结构和语义嵌入，可能会损害模型的学习能力。原因可能在于，RGTN 的两个输入通道需要在一定程度上具有差异性，**这样才有利于模型充分利用多源特征**。而使用相同的 LICAP 架构对两者进行预训练，**可能导致两个通道的嵌入特征过于相似，无法有效发挥多源特征的优势**，进而影响模型学习效果。

尽管如此，与原始方法相比，三种变体都能提升性能，说明LICAP在不同输入通道设置下均能发挥积极作用。

**超参数分析**  
分析损失平衡比率 $\eta_{2}/\eta_{1}$ 和 重要比率 $\gamma$ 对模型性能的影响。  
研究发现，排序指标 SPEARMAN 比回归指标 RMSE 对超参数更鲁棒。  

- **排序对预测异常值相对不敏感**，而RMSE作为回归指标受异常值影响较大。  
- 此外，不同数据集的最佳 $\gamma$ 值不同，**这是由于各数据集在图结构和知识图谱主题等方面存在差异。**

**可视化LICAP预训练嵌入**  
通过可视化LICAP预训练前后的节点嵌入，**直观地发现预训练后高重要性节点在空间中更聚集。这一现象表明LICAP能更好地感知高重要性节点，实现了研究的预期目标，进一步证明了LICAP的有效性。**

**LICAP应用于多种方法**  
将LICAP与更多NIE方法结合进行实验。结果显示，**LICAP能提升MLP的性能，但对LR的效果不稳定**，可能是因为LR的线性假设与知识图谱上的NIE问题兼容性不佳，而MLP的非线性激活函数能更好地与LICAP协作。  
对于GNN-基于的方法（如GCN、RGCN、GraphSAGE和GENI），LICAP也有不同程度的性能提升。  （==个人感觉这里说得太牵强了，实验效果其实并没有那么好==）

- 其中，RGCN和GENI与LICAP结合后在不同数据集上的表现相对更优，**这是因为LICAP考虑了关系信息，与同样关注关系的RGCN和GENI更适配。**  
- 此外，LICAP对非GNN方法的性能提升幅度相对更大，但结合LICAP的GNN方法凭借GNN骨干网络在图数据处理上的优势，最终仍取得更好的结果。



#### 作者对未来工作的展望

对于未来的工作

* 将 LICAP 扩展到动态图上的 NIE 问题是一个有趣的研究方向。
* 此外，研究标签分布如何影响 LICAP 和 NIE 方法的性能也很有价值。
* 另一个有前景的方向是将 LICAP 的思想迁移到其他与图相关的回归或排名问题中。



#### 实验的复现

* 感觉是数据造假
* 难以置信，怎么跑出来的效果这么差！！！
* 针对 FB15K，我们这样进行超参数设置 $\gamma = 0.1$， $\eta_2 / \eta_1=2(\eta_1=1, \eta_2 =2)$
* 发现应该是调参的问题，调参的效果还是很显著的

##### FB15K

* $\gamma =0.1, \eta_2 / \eta_1 =1$

| Methods    | RMSE ↓               | MedianAE ↓           | NDCG@100 ↑           | SPEARMAN ↑           | OVER@100 ↑           |
| ---------- | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |
| PR         |                      |                      |                      |                      |                      |
| PPR        |                      |                      |                      |                      |                      |
| LR         |                      |                      |                      |                      |                      |
| MLP        |                      |                      |                      |                      |                      |
| GCN        | 1.2111±0.0287        | 0.7070±0.0137        | 0.9350±0.0108        | 0.6321±0.0283        | 0.3700±0.0544        |
| RGCN       | 2.0204±1.1747        | 0.6622±0.0171        | 0.9055±0.0113        | 0.6889±0.0200        | 0.3120±0.0354        |
| GraphSAGE  | 1.0828±0.0194        | 0.6462±0.0124        | 0.9049±0.0084        | 0.6832±0.0095        | 0.2700±0.0210        |
| GENI       | 0.9829±0.0206        | <u>0.5778±0.0145</u> | 0.9079±0.0078        | 0.7396±0.0101        | 0.3240±0.0356        |
| RGTN       | **0.8979±0.0305**    | **0.5282±0.0206**    | <u>0.9420±0.0123</u> | **0.7879±0.0141**    | <u>0.4060±0.0771</u> |
| RGTN+LICAP | <u>0.9646±0.0463</u> | 0.5973±0.0459        | **0.9421±0.0077**    | <u>0.7832±0.0120</u> | **0.4100±0.0510**    |



* 这张表格对 GENI 与 RGTN + LICAP 进行了调参，但是 $\eta_2$ 仍旧为 1

* 发现不对劲了，因为貌似参数没有保持一致（我们现在考虑测试 RGTN 与 RGTN + LICAP，超参数使用 RGTN 的那篇论文进行实现，这样的话， **pretrain的超参数也要对应着改动**）

  * ```shell
    # rgtn 论文中的 rgtn 模型参数
    python two_branch/two_branch_train.py --dataset FB15k_rel_two --data_path datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 \
    --save-path gtran-list-3-100_checkpoint.pt --gpu 0
    
    ```

  * ```shell
    # pretrain 中对应的修改参数
    # pretrain_pregat_struct_FB15k.sh
    
    # 训练结构信息
    python pretrain/pregat_pretrain_struct.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --num-hidden 8 --num-heads 8
    
    # 训练语义信息
    python pretrain/pregat_pretrain_struct.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --num-hidden 8 --num-heads 8
    ```
    
  * ```shell
    # down_stream 中的 shell 文件
    # downstream_struct_FB15k.sh
    
    # 仅 rgtn
    python downstream/rgtn_downstream.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 --pretrain-model 'null'
    
    # rgtn + licap
    python downstream/rgtn_downstream.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 --pretrain-model 'pregat_struct'
    ```
  
    

| Methods    | RMSE ↓               | MedianAE ↓            | NDCG@100 ↑           | SPEARMAN ↑           | OVER@100 ↑           |
| ---------- | -------------------- | --------------------- | -------------------- | -------------------- | -------------------- |
| PR         |                      |                       |                      |                      |                      |
| PPR        |                      |                       |                      |                      |                      |
| LR         |                      |                       |                      |                      |                      |
| MLP        |                      |                       |                      |                      |                      |
| GCN        | 1.2111±0.0287        | 0.7070±0.0137         | 0.9350±0.0108        | 0.6321±0.0283        | 0.3700±0.0544        |
| RGCN       | 2.0204±1.1747        | 0.6622±0.0171         | 0.9055±0.0113        | 0.6889±0.0200        | 0.3120±0.0354        |
| GraphSAGE  | 1.0828±0.0194        | 0.6462±0.0124         | 0.9049±0.0084        | 0.6832±0.0095        | 0.2700±0.0210        |
| GENI       | 1.2506±0.4130        | 0.7107±0.2596（异常） | 0.9110±0.0261        | 0.7167±0.0752        | 0.3340±0.0855        |
| RGTN       | **0.8565±0.0176**    | **0.4896±0.0120**     | **0.9506±0.0102**    | **0.8115±0.0058**    | **0.4440±0.0634**    |
| RGTN+LICAP | <u>0.8967±0.0427</u> | <u>0.5264±0.0391</u>  | <u>0.9429±0.0092</u> | <u>0.7915±0.0255</u> | <u>0.3920±0.0435</u> |

* 这组数据主要是针对 RGTN 与 RGTN + LICAP 这一模型。超参数选取的是让 RGTN 效果最好的那一组（参考的是 RGTN 的代码）。结果发现和 RGTN 那篇代码相比，NDCG@100 与 NDCG@100 这两项指标差了1个百分点左右，而 OVER@100 则差了4个百分点。

  但是在此基础上，添加了 LICAP 模块。有几点让我比较郁闷

  （1）发现每项指标都被秒杀了

  （2）论文中给的数据是 添加了 RGTN 的效果更好，但是它们并没有用到 RGTN 那篇论文的 SOTA。这是为什么？是因为如果使用 SOTA 的配置反而跑的不好？于是用了一些能降低 RGTN 性能的超参数训练一个比较差的 RGTN ，然后让 LICAP 发挥作用？

  （3）有点烦躁了



$\eta_2 = 2.0$

| RGTN+LICAP | 0.9053±0.0193 | 0.5323±0.0194 | 0.9397±0.0047 | 0.7907±0.0151 | 0.3900±0.0395 |
| ---------- | ------------- | ------------- | ------------- | ------------- | ------------- |



##### **TMDB5K**

| **Methods**    | **RMSE ↓**               | **MedianAE ↓**    | **NDCG@100 ↑**           | **SPEARMAN ↑**           | **OVER@100 ↑**           |
| -------------- | ------------------------ | ----------------- | ------------------------ | ------------------------ | ------------------------ |
| **PR**         |                          |                   |                          |                          |                          |
| **PPR**        |                          |                   |                          |                          |                          |
| **LR**         |                          |                   |                          |                          |                          |
| **MLP**        |                          |                   |                          |                          |                          |
| **GCN**        | **0.7946±0.0316**        | **0.5370±0.0136** | **0.8765±0.0175**        | **0.7677±0.0139**        | **0.4820±0.0248**        |
| **RGCN**       | **1.1699±0.7719**        | **0.7592±0.4501** | **0.8487±0.0582**        | **0.6648±0.1562**        | **0.4280±0.0964**        |
| **GraphSAGE**  | **0.7399±0.0147**        | **0.4815±0.0198** | **0.9003±0.0017**        | **0.7587±0.0197**        | **0.5320±0.0407**        |
| **GENI**       | **0.7194±0.0137**        | **0.4809±0.0431** | **0.9130±0.0117**        | **0.7860±0.0157**        | **0.5880±0.0240**        |
| **RGTN**       | **0.7458±0.0596**        | **0.4809±0.0431** | **0.9055±0.0105**        | **0.7934±0.0083**        | **0.5440±0.0356**        |
| **RGTN+LICAP** | **<u>0.7220±0.0428</u>** | **0.4766±0.0386** | **<u>0.9092±0.0138</u>** | **<u>0.7902±0.0086</u>** | **<u>0.5680±0.0496</u>** |





#### **一些工具或者技巧**

* 针对真实世界KG的标签（如FB15K的页面浏览量和GA16K的引用计数），作者对其进行了对数转换（猜测是数据太大了，后面的损失函数与生成嵌入要直接用到它，不能使用过大的数据？？）==这个要深刻理解==

* 在计算 $L_1$ 损失的时候，代码中将 `embed_important` 与 `embed_normal`  （分别对应了论文中公式（1）的 $h_i$ 与 $h_j$）进行了归一化操作，即 

  ```python
  embed_important = F.normalize(embed_important)
  embed_normal = F.normalize(embed_normal)
  ```

  这是为了防止后续在进行 `torch.exp()`  操作的同时指数爆炸，经过实验直接变成 `nan` 了（这是因为分母或分子为 `inf` 导致结果为 `nan`）


* 设置随机种子

* 简单早停模块

* 梯度裁剪

  * 防止梯度爆炸（在反向传播时使用！！），用于提高训练稳定性，常用于深度网

    * 需要在 `loss.backward()` 之后、`optimizer.step()` 之前执行，而不是在 `forward` 里执行。

  * **`torch.nn.utils.clip_grad_norm_(parameters = model.parameters(), max_norm = 10, norm_type = 2)`**

    > **梯度裁剪的缩放公式如下：**
    >
    > **$g_i = g_i \times \frac{\text{max\_norm}}{\|\mathbf{g}\|_2}$**
    >
    > **其中：**
    >
    > * **$g_i$ 是梯度的某个分量。**
    >   
    > * **$\|\mathbf{g}\|_2$ 是所有梯度的 L2 范数（即欧几里得范数）：**
    >   
    >   **$\|\mathbf{g}\|_2 = \sqrt{\sum_i g_i^2}$**
    >
    > * **如果 $\|\mathbf{g}\|_2 \leq \text{max\_norm}$，则不进行缩放。**
    >
    > * **如果 $\|\mathbf{g}\|_2 > \text{max\_norm}$，则所有梯度按照这个比例缩放，使得梯度范数不会超过 `max_norm`。**



### **RGTN**

* ==这个图的 `transform` 也只是利用了局部的信息，并没有像 `LLM` 那样利用全局的信息，针对这一点感觉可以进行创新做一下实验？==

  * 破案了，是我学识浅薄了，之前讨论的是自注意力，所以只需要关注自己就行了。交叉注意力部分才是关注~~全局信息~~（==还是自己的信息，只不过是自己的结构和语义信息！！！==）

* 我是不是应该使用网格搜索来找到最佳模型？

* 表征学习

  其实就是学习低维的、嵌入的向量

* 究竟什么是节点重要性？一言以蔽之

  ==节点重要性估计（NIE）是一项根据图的结构和属性信息推断图中节点重要性或受欢迎程度的任务。==

* 度中心性、介数中心性与PageRank（通过计算与节点相连的边的数量和质量来大致估计节点的重要性。）然而，这些方法不能直接用于评估复杂知识图谱中节点的重要性，因为它们只考虑了图的拓扑结构，而忽略了繁杂的节点和边中所包含的丰富结构和语义信息。

* GENI  和 MULTIIMPORT。GENI 将通过 node2vec [9] 获得的节点特征映射为重要性值，并以图注意力网络的方式自适应地聚合来自不同边类型的这些值。得益于监督学习框架和图注意力机制，GENI 比手工设计的方法表现更优。在 GENI 的基础上，MULTIIMPORT 进一步探索如何利用外部输入的重要性信号来学习潜在的节点重要性。尽管它们在准确估计节点重要性方面取得了成功，但它们忽略了可能与节点重要性相关的节点描述。

#### **预备知识点**

* FFN： 

  FFN（Feed Forward Network），即前馈神经网络，是一种由全连接层（Dense Layer）和非线性激活函数组成的简单神经网络模块。它在Transformer架构（如论文中的RGTN）中扮演重要角色，通常用于对注意力机制输出的特征进行进一步变换和增强。

  * 一般需要满足以下几个条件
    * 扩展维度，**非线性激活**函数，恢复维度，正则化（可选），添加残差连接（可选），当然后面还能失活 `Dropout`

  * $\text{FFN}(x) = W_2 \cdot \text{ReLU}(W_1 \cdot x + b_1) + b_2$

  * 在论文中 FFN 的输入是经过注意力聚合以及残差相加处理之后的数据

  * 其作用是：
    1. 特征增强：对注意力层输出的节点特征进行非线性变换，捕捉更复杂的模式（**之前的操作并没有进行非线性变换**）。
    
    2. 维度恢复：虽然中间层会扩展维度，但最终输出维度与输入一致，确保后续层的兼容性。
    
       （1）先扩展维度，**在高维空间中进行非线性变换，让模型学习更丰富的特征表示**。（类似“放大镜”，先放大细节再聚焦关键信息）
    
       （2）再压缩回原维度：避免维度膨胀导致**计算量过大**，**同时保留最重要的特征**。
    
       （3）**深化局部特征（单个词的语义表示）**，即它在处理的时候是**单独处理每个词的嵌入特征**，下面是与自注意力阶段的对比，**自注意力阶段更关注全局关系，FFN 特征更关注局部特征**
    
       > 1. **自注意力阶段**：
       >    - 决定哪些词需要重点关注（例如“苹果”与“吃”的关系更强）。
       >    - 输出：一组经过**全局调制**的特征向量（每个词包含上下文信息）。
       > 2. **FFN 阶段**：
       >    - 对每个词向量单独处理，**深化其语义表示**。
       >    - 例如：将“苹果”从“一种水果”进一步细化为“可食用的甜味水果”。
    
    3. 与残差连接配合：FFN的输出会与输入相加（公式6），缓解深层网络的梯度消失问题。

* 残差连接

* 层归一化与批归一化

  和我想得一样，看笔记

* 协同注意力模块

* Learning-to-Rank（LTR）损失：核心思想是：不仅要预测准确的节点重要性值，还要确保节点之间的相对排序关系与真实情况一致。

#### 本文贡献

- 本文提出了一种基于表示学习的节点重要性估计框架，该框架能够全面利用各类节点和关系中蕴含的丰富结构和语义信息。
- 设计了一种关系图变换器，利用可学习的谓词表示来传播节点嵌入，从而区分谓词语义对节点重要性传播的影响。
- 引入学习排序损失来指导表示学习过程，以获得具有相对位置感知的节点表示，进而提高节点重要性估计的整体质量。

#### **这项工作的应用前景**

节点重要性估计有许多潜在的应用。以电影知识图谱为例，我们可以预测新添加的电影实体的重要性，以帮助优化资源分配。我们还可以改变一部电影与不同演员之间的联系，获取各种重要性值，为电影选角提供参考。

ps：以前都没有想到过有这些应用场景

#### 理解文中的公式

公式（1）究竟是标量还是向量！！！

* 理论上应该是标量，但是实际上根据作者给的公式明显就是一个向量。破案了就是标量，边的每个头的特征维度为1 

公式（3）

* 其中的 $W^l_o$ 是什么意思

  > 在论文的公式（3）中，$W^l_o$ 是第 $l$ 层 Relational Graph Transformer 中的一个可学习的线性变换矩阵，其作用是对多头注意力（Multi-Head Attention）输出的拼接结果进行降维和整合。以下是详细解析：
  >
  > 公式（3）的上下文
  > $$
  > M_v^l = W_o^l \Bigg\|_{k=1}^H \left( \sum_{u \in \mathcal{N}_v} a_{(u,v)}^{k,l} \cdot W_V^{k,l} h_u \right)
  > $$
  >
  > 其中：
  >
  > - $M_v^l$ 是节点 $v$ 在第 $l$ 层聚合后的消息。
  > - $\|$ 表示向量拼接（concatenation）。
  > - $H$ 是注意力头的数量。
  > - $a_{(u,v)}^{k,l}$ 是第 $k$ 个注意力头计算的权重（由公式1-2得到）。
  > - $W_V^{k,l}$ 是第 $k$ 个头对应的值（Value）变换矩阵。
  > - $h_u$ 是邻居节点 $u$ 的表示。
  >
  > $W^l_o$ 的具体作用
  >
  > 1. 多头注意力的输出整合：
  >    - 每个注意力头会生成一个维度为 $d$ 的向量（$d$ 是隐层维度），拼接后得到 $H \times d$ 维的向量。
  >    - $W_o^l \in \mathbb{R}^{d \times (H \cdot d)}$ 将拼接后的高维向量投影回 $d$ 维，保持各层维度一致。
  >
  > 2. 可学习的参数：
  >    - 它是与层数相关的矩阵（上标 $l$ 表示第 $l$ 层），允许不同层学习不同的整合模式。
  >    - 类似于标准Transformer中的 $W_O$ 矩阵（见原始Transformer论文[1]），但这里适配了图结构的多关系特性。
  >
  > 3. 与经典GNN的对比：
  >    - 在GAT中，多头注意力的输出直接拼接或平均，而本文通过 $W_o^l$ 显式学习整合方式，增强了表达能力。
  >
  > 设计动机
  >
  > - 降维需求：避免多头注意力拼接后维度膨胀（$H \cdot d$），维持模型效率。
  > - 关系感知：在知识图谱中，不同层的节点表示可能需要不同的信息聚合策略，$W_o^l$ 通过层特异性参数实现这一点。
  >
  > 与其他公式的关联
  >
  > - 后续处理：公式（4）-（6）中，$M_v^l$ 会经过残差连接、FFN和归一化，生成下一层的节点表示 $h_v^{l+1}$。
  > - 与RGCN/GAT的区别：RGCN为不同关系类型设计独立矩阵，而本文的 $W_o^l$ 统一处理所有关系，但通过注意力权重 $a_{(u,v)}^{k,l}$ 隐含关系差异。
  >
  > 总结
  >
  > $W_o^l$ 是关系图Transformer的核心组件之一，负责将多头注意力的异构信息压缩为统一的节点表示，同时保留语义和结构特征。其设计体现了对知识图谱中复杂关系的建模能力，也是模型性能优越的关键之一。

公式（7）~公式（10）

见下文的 **理解协同注意力模块（即 cross attention）**



**公式（11）~公式（13）**

此部分是论文中提出的重要性预测模块（Importance Prediction Module）的核心部分，用于将节点的结构和语义表示融合并映射为最终的重要性值。以下是对这些公式的详细说明及补充细节：

> 以下是经过完整LaTeX公式渲染后的内容：
>
> ---
>
> 公式（11）~（13）是论文中提出的重要性预测模块（Importance Prediction Module）的核心部分，用于将节点的结构和语义表示融合并映射为最终的重要性值。以下是对这些公式的详细说明及补充细节：
>
> **公式（11）：注意力权重计算**
> $$
> \gamma^{(s)} = \frac{\exp(h_v^{(s)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}, \quad \gamma^{(c)} = \frac{\exp(h_v^{(c)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}
> $$
>
> **说明：**
> 1. **输入**：
>    - $h_v^{(s)}$：节点 $v$ 的结构表示（来自结构编码器）。
>    - $h_v^{(c)}$：节点 $v$ 的语义表示（来自语义编码器）。
>    - $\lambda$：可训练的注意力向量，用于将节点表示映射为标量值。
>
> 2. **操作**：
>    - 通过点积 $h_v^{(s)} \lambda^T$ 和 $h_v^{(c)} \lambda^T$，将结构和语义表示分别映射为标量。
>    - 使用 softmax 函数计算两者的注意力权重 $\gamma^{(s)}$ 和 $\gamma^{(c)}$，确保权重之和为 1。
>
> **补充细节**：
> - **注意力机制的作用**：动态调整结构和语义信息对最终重要性预测的贡献。例如，在电影知识图谱中，某些节点（如知名导演）的结构关系可能更重要，而其他节点（如剧情新颖的电影）的语义描述可能更关键。
> - **可训练参数**：$\lambda$ 是模型通过反向传播学习的参数，其维度与节点表示维度一致（如 64 维）。
>
> **公式（12）：重要性值投影**
> $$
> s_v^{(s)} = W_s^1 h_v^{(s)}, \quad s_v^{(c)} = W_s^2 h_v^{(c)}
> $$
>
> **说明：**
> 1. **输入**：
>    - $h_v^{(s)}$ 和 $h_v^{(c)}$ 同上。
>    - $W_s^1$ 和 $W_s^2$：可训练的投影矩阵，将节点表示映射为 1 维重要性值。
>
> 2. **操作**：
>    - 分别将结构和语义表示通过线性变换（矩阵乘法）映射为标量重要性值 $s_v^{(s)}$ 和 $s_v^{(c)}$。
>
> **补充细节**：
> - **投影矩阵的维度**：假设 $h_v^{(s)}$ 和 $h_v^{(c)}$ 的维度为 $d$，则 $W_s^1$ 和 $W_s^2$ 的维度为 $1 \times d$。
> - **分离投影的目的**：允许结构和语义信息独立地贡献重要性值，避免两者在融合前相互干扰。
>
> **公式（13）：重要性值融合**
> $$
> s_v^* = \text{LeakyReLU}(\gamma^{(s)} s_v^{(s)} + \gamma^{(c)} s_v^{(c)})
> $$
>
> **说明：**
> 1. **输入**：
>    - $\gamma^{(s)}$ 和 $\gamma^{(c)}$：来自公式（11）的注意力权重。
>    - $s_v^{(s)}$ 和 $s_v^{(c)}$：来自公式（12）的投影重要性值。
>
> 2. **操作**：
>    - 使用注意力权重对 $s_v^{(s)}$ 和 $s_v^{(c)}$ 进行加权求和。
>    - 通过 LeakyReLU 激活函数引入非线性，确保输出为非负值（重要性值通常为非负）。
>
> **补充细节**：
> - **LeakyReLU 的作用**：避免梯度消失问题，同时允许小幅度的负值输入（虽然重要性值通常为正，但激活函数的设计可能为模型提供额外的灵活性）。
> - **加权求和的意义**：动态结合结构和语义信息。例如，若 $\gamma^{(s)}$ 接近 1，则结构信息主导重要性预测；反之则语义信息主导。
>
> **整体流程总结**
>
> 1. **表示分离**：通过结构和语义编码器分别生成节点表示 $h_v^{(s)}$ 和 $h_v^{(c)}$。
> 2. **注意力权重计算**：动态学习两种表示的贡献比例（公式 11）。
> 3. **重要性值投影**：将两种表示独立映射为重要性值（公式 12）。
> 4. **融合与激活**：加权融合并应用非线性激活，输出最终重要性值 $s_v^*$（公式 13）。
>
> **补充重要细节**
>
> 1. **损失函数的配合**：
>    - 公式（13）的输出 $s_v^*$ 会与真实重要性值 $s_v$ 通过 RMSE 损失（公式 16）和 LTR 损失（公式 15）联合优化，确保预测值既准确又保持正确的排名关系。
>    
> 2. **模块设计的动机**：
>    - 知识图谱中节点的重要性可能依赖于多种因素（如链接数量、文本描述质量等），因此需要灵活融合多源信息。
>    - 分离结构和语义编码器避免了特征混淆，而注意力机制提供了自适应的融合能力。
>
> 3. **实际应用示例**：
>    - 在电影知识图谱中，若某电影的导演很知名（结构信息重要），则 $\gamma^{(s)}$ 可能较高；若剧情描述独特（语义信息重要），则 $\gamma^{(c)}$ 可能较高。
>
> 通过这一模块，RGTN 能够充分利用知识图谱的多模态信息，实现更精准的节点重要性估计。



#### 理解协同注意力模块（即 cross attention）

==我们发现，代码中的结构信息对其中一个点也只是关注了图中的很局部的信息（邻居节点）==

**节点结构信息**和**语义信息**对最终节点重要性的贡献在不同的场景中可能不同。例如，在电影知识图中，如果情节设计流行，即使主要创作者不那么出名，一些电影也可能会流行起来。相反的情况是，有几个大师参与，即使情节看起来不受欢迎，一些电影也可能会受到关注。因此，**自适应地融合**结构和语义信息中的节点表示将有利于节点重要性估计的性能。

即这一部分应该是要思考利用这两个特征达到 $1 + 1 > 2$ 的效果而非 $1 + 1 < 2$

* 文章使用**相互交流**来增强它们

* 公式（7）为什么又要用 $W_F$ 进行依次线性变换？明明结构表示 $h^{(s)}_v$ 和语义表示 $h^{(c)}_v$ 已经维度一致，为什么还要乘一个线性变换矩阵 $W_F$？不能直接拿来做 co-attention 吗？

  * 1. 表示空间对齐

       虽然 $h^{(s)}_v$ 和 $h^{(c)}_v$ 维度一致，比如都是 64 维，但：

       - 它们来自**不同的 encoder（结构 & 语义）**；
       - 所在的**语义空间分布差异很大**。
       - 它们不在同一个空间，就是不可比的
    
       📌 举个比喻：同样是 64 维，但一个是图结构抽象出来的向量，一个是 Transformer-XL 编出来的语言语义特征，这两个向量的“含义”完全不同，就像“画风不同”的两组图片。
    
       🔧 所以需要一个统一的投影（$W_F$），**将它们映射到一个“对齐后”的共同空间**，这样 attention 才有“可比性”。即将**不同来源的信息**映射到**同一个表示空间，以便它们可以在该空间中相互比较和交互**，若不加以处理那么即使它们的维度相同（例如都是 64 维），它们表达的“内容”在数学空间中是**完全不同的**，因此不能直接进行比较或交互。
    
       比如，在多模态领域中，将不同模态的向量（如 ResNet 图像特征和 BERT 文本特征）投影到同一空间；通常 ==**共享映射矩阵**== 是一种防止过拟合且强制对齐的手段。$W_F$ 的共享意味着**它会学到一种“折中”的映射方式**，让来自结构与语义的表示在同一空间中“尽可能协调”；从训练角度来看，损失函数会驱动模型去**调节 $W_F$**，使得结构和语义的融合表示对下游任务（如节点重要性估计）是有效的。
    
       
    
       很多网络都有这样的操作：==**先各自提取，再统一映射对齐再交互。**==
    
       | 角度     | 回答                                                         |
       | -------- | ------------------------------------------------------------ |
       | 理论支撑 | 间接有：来自多模态对齐与注意力机制的一致性设计思路，但**不是定理级别** |
       | 实验支撑 | 有：共享 $W_F$ 在众多模型中效果好；消融通常性能下降          |
       | 概念本质 | **不是“强制相同语义”，而是“训练中逼近协同语义空间”**         |
    
    2. 为注意力机制提供 Query / Key 表达能力
    
       可以把这个 $W_F$ 理解为 embedding standardizer
    
       * 把来自结构/语义两个来源的表示统一后，再送去做 $Q/K$；
    
       * 如果不做这个步骤，可能造成注意力值失真，训练不稳定。
    
    3. 提供更多参数容量（更强的表达能力）
    
       哪怕两个向量维度一样，如果直接拿来算注意力，其实是把整个学习过程限制住了（即 attention 只能依据原始向量之间的点积来衡量关系）。
    
       引入这些线性变换之后，相当于告诉模型：
    
       > “你不仅可以考虑原始的结构和语义特征，还能**自由组合它们的不同维度**，以学习到最合适的注意力打分方式。



#### 理解 LTR（Learning-To-Rank） 排名损失与损失函数

如何跳出节点嵌入的局部性？这个是怎么理解的？

> ### Learning-to-Rank Loss（学习排序损失）
>
> #### **核心思想**
> 传统的回归损失（如RMSE）仅关注节点重要性值的绝对误差，而忽略了节点间的相对排名关系。因此，作者引入**列表式学习排序损失（Listwise LTR Loss）**，直接优化节点的重要性排名。
>
> #### **公式解析**
> 1. **标准化重要性值**：
>    $$
>    s_v' = \frac{\exp(s_v)}{\sum_{j \in \mathcal{N}_v^{(r)}} \exp(s_j)}, \quad s_v^{*'} = \frac{\exp(s_v^*)}{\sum_{j \in \mathcal{N}_v^{(r)}} \exp(s_j^*)}
>    $$
>    - 对真实重要性值 $s_v$ 和预测值 $s_v^*$ 进行softmax归一化。
>
> 2. **交叉熵损失**：
>    $$
>    \mathcal{L}_v^{(r)} = -\sum_{i \in \mathcal{N}_v^{(r)}} s_i' \log(s_i^{*'})
>    $$
>
> #### **设计动机**
> 1. **全局排名感知**：通过比较节点间的相对重要性，从全局视角优化模型。
> 2. **竞争机制**：softmax函数引入节点间的竞争，区分重要与非重要节点。
>
> ---
>
> ###  Training Process（训练过程）
>
> #### **损失函数组成**
> 总损失函数：
> $$
> \mathcal{L} = a\mathcal{L}_0 + b\frac{\mathcal{L}_1 + \mathcal{L}_2}{2} + c \left( \frac{1}{|\mathcal{V}_s|} \sum_{j \in \mathcal{V}_s} \mathcal{L}_j^{(r)} \right)
> $$
>
> 1. **主回归损失**：
>    $$
>    \mathcal{L}_0 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^* - s_i)^2
>    $$
>
> 2. **辅助回归损失**：
>    $$
>    \mathcal{L}_1 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^{(s)} - s_i)^2, \quad \mathcal{L}_2 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^{(c)} - s_i)^2
>    $$
>
> #### **超参数设计**
> - 权重设置为 $a=0.3$, $b=0.7$, $c=0.5$，平衡多任务学习。
>
> #### **训练策略**
> 1. **分阶段训练**：先预训练单模态编码器，再联合优化。
> 2. **动态采样**：计算LTR损失时随机采样参考节点（20~200个）。
> 3. **早停机制**：监控验证集NDCG指标。
>
> ---
>
> ### **关键创新点**
> 1. 多任务学习框架联合优化RMSE和LTR损失
> 2. 通过辅助损失约束单模态预测
> 3. 结合GNN的局部消息传递与LTR的全局排名优化
>
> ---
>
> ### **完整内容补充**
>
> #### **公式（11）~（13）：重要性预测模块**
> 1. **注意力权重计算**：
>    $$
>    \gamma^{(s)} = \frac{\exp(h_v^{(s)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}, \quad \gamma^{(c)} = \frac{\exp(h_v^{(c)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}
>    $$
>
> 2. **重要性值投影**：
>    $$
>    s_v^{(s)} = W_s^1 h_v^{(s)}, \quad s_v^{(c)} = W_s^2 h_v^{(c)}
>    $$
>
> 3. **重要性值融合**：
>    $$
>    s_v^* = \text{LeakyReLU}(\gamma^{(s)} s_v^{(s)} + \gamma^{(c)} s_v^{(c)})
>    $$
>
> ---
>
> ### **总结**
> 本文提出的RGTN模型通过：
> 1. 分离式编码器捕获结构和语义信息
> 2. 注意力机制动态融合多模态特征
> 3. 创新性地结合LTR损失优化全局排名
>
> 所有数学公式均已严格按您的要求使用 `$$...$$` 或 `$...$` 进行渲染。我已牢记这一格式要求，后续所有回复中的公式都会按此规范呈现。
>
> 如需对内容或格式进行任何调整，请随时告知！



#### 理解实验

* 文中在 `transfrom` 这个架构中，针对谓词边与起点与汇点之间的注意力，选取了几种结合的模式，包括 `mul` `dot` `add` ，代码中默认使用 `mul` 





#### **疑问点**

##### 为什么公式（2）针对的是对汇点的入边进行归一化而不是源点的出边

* **因为最后的语义特征要归到节点上，而汇点接收信息，将语义特征归到汇点上而非源点上更加符合直观感觉**

* > **1. 公式（2）的数学形式**
  >
  > **公式（2）的归一化是针对目标节点（汇点）的所有入边进行的：**
  >$$
  > a_{(u,v)}^{k,l} = \sum_{m} \frac{\exp(w_{(u,v),m}^{k,l})}{\sum_{u' \in \mathcal{N}_v} \sum_{m'} \exp(w_{(u',v),m'}^{k,l})}
  > $$
  > - **分子：计算源节点 $u$ 通过边 $m$ 对目标节点 $v$ 的注意力权重 $w_{(u,v),m}^{k,l}$（由公式1计算）。**
  > - **分母：对目标节点 $v$ 的所有入边邻居 $u' \in \mathcal{N}_v$ 和所有可能的边类型 $m'$ 进行归一化。**
  > 
  > **2. 为什么归一化针对汇点（而非源点）？**
  >
  > **（1）任务需求：节点重要性估计**
  >
  > - **目标：预测目标节点 $v$ 的重要性，而非评估邻居节点 $u$ 的重要性。**
  >- **信息聚合方向：需要将邻居节点 $u$ 的信息（结构和语义）汇聚到目标节点 $v$ 上，因此归一化需保证所有入边对 $v$ 的贡献总和合理（例如加权和为1）。**
  > 
  > **（2）数学合理性**
  >
  > - **概率解释：注意力权重 $a_{(u,v)}^{k,l}$ 可视为“邻居 $u$ 对目标 $v$ 的重要性概率”，需满足 $\sum_{u} a_{(u,v)}^{k,l} = 1$。**
  >- **梯度稳定性：归一化针对汇点能避免不同目标节点 $v$ 的注意力权重尺度差异，使训练更稳定。**
  > 
  > **（3）与经典模型的对比**
  >
  > - **GAT/GCN：归一化也是针对目标节点的邻居（即汇点的入边），但本文进一步扩展到了多关系边（通过 $m$ 区分边类型）。**
  >- **PageRank：类似地，PageRank的权重归一化也是针对“被链接的网页”（汇点），而非“链接出去的网页”。**
  > 
  > **3. 你的解释的修正**
  >
  > **你的直观理解（“语义特征归到汇点”）是正确的，但需要补充：**
  >- **更深层原因：这是由节点重要性估计的任务目标决定的。模型需要学习“哪些邻居对目标节点更重要”，而非“目标节点对邻居的影响”。**
  > - **边方向的物理意义：在知识图谱中，边通常表示“源节点对目标节点的某种关系”（如“导演-电影”），重要性应从邻居（导演）传递到目标（电影）。**
  > 
  > **4. 反例思考**
  >
  > **如果归一化针对源点（即 $\sum_{v} a_{(u,v)}^{k,l} = 1$）：**
  >- **问题1：一个邻居节点 $u$ 的重要性会被均摊到所有连接的 $v$ 上，无法区分它对不同目标节点的贡献差异。**
  > - **问题2：与任务目标脱节，因为我们需要的是“目标节点的重要性”，而非“邻居的重要性分布”。**
  > 
  > **总结**
  >
  > **你的直觉是对的，但更本质的原因是：**
  >1. **任务驱动：节点重要性估计需要聚合邻居信息到目标节点。**
  > 2. **数学约束：归一化针对汇点符合概率建模和梯度优化的需求。**
  > 3. **知识图谱特性：多关系边的语义需要通过目标节点中心的注意力机制捕获。**
  > 
  > **这种设计与GAT、Transformer等模型一致，但通过显式建模关系类型（谓词）进一步增强了表达能力。**



##### Q1：为什么交叉注意力机制要设置 `temp` 温度，而自注意力机制则没有 Q2：为什么交叉注意力机制的 `FFN` 和自注意力机制的 `FFN` 不一样，前者先降维后升维，后者反之。这是为什么？

* 因为交叉部分相当于是多模态情况，两个领域的特征不一样，需要温度来进行平滑

* 就是一个更加关注泛化能力一个更加关注表达能力

  > 总的来说，这两种设计反映了处理数据时不同的 FFN 设计策略，分别侧重于模型的泛化能力和复杂关系的学习。**`CrossAttention`** 设计侧重于通过先降维后升维来减少复杂度，强调泛化能力；而 **`GTLayer`** 的设计则通过先增大维度再缩小维度，提供了更多的表达能力和灵活性。每种设计都有其优势和权衡，影响模型的计算成本、容量以及学习到的表示。



##### 在计算LTR时，为什么要对节点进行采样，而不是直接运用所有节点进行计算

> 在计算Learning-to-Rank (LTR)损失时对节点进行采样（而不是使用全部节点）主要基于以下几个关键原因：
>
> 1. **计算效率的考量**
>    - 知识图谱通常包含大量节点（如IMDB数据集有超百万节点）
>    - 计算所有节点对的softmax归一化：
>    $$
>    s_v' = \frac{\exp(s_v)}{\sum_{j \in \mathcal{V}} \exp(s_j)}
>    $$
>    时间复杂度为O(|V|^2)，在大规模图上不可行
>
> 2. **训练稳定性的需要**
>    - 全量计算会导致：
>      - 梯度被大量不重要节点稀释（**因为分母变大了，会被其他炮灰给稀释。采样节点的话没准信号强度能提升十几倍几十倍，这种情况可能也会导致梯度消失**）
>      - 容易陷入局部最优（主要优化头部重要节点）
>    - 采样可控制对比强度：
>    
>    $$
>    \mathcal{N}_v^{(r)} = \text{Sample}(V, n) \quad (n \ll |V|)
>    $$
>    
> 3. **课程学习(Curriculum Learning)效应**
>    - 动态采样模拟了"由易到难"的学习过程：
>      - 初期：更多随机采样探索全局结构
>      - 后期：侧重难例采样（如重要性相近的节点对）
>
> 4. **负采样策略的延伸**
>    - 类比知识图谱嵌入中的负采样：
>      - 真实场景中不重要节点远多于重要节点
>      - 采样相当于自动进行难负例挖掘
>
> 5. **防止过平滑(Over-smoothing)**
>    - 在GNN中，全量计算会使所有节点重要性得分趋同
>    - 采样保持了一定的区分度，如对电影节点：
>    
>    $$
>    \mathcal{N}_v^{(r)} \subset \{\text{同类型电影}\} \cup \{\text{关联导演作品}\}
>    $$
>    
> 6. **实际效果验证**
>    - 论文实验显示：
>      - 采样n=100时效果最佳
>      - 全量计算反而使NDCG@100下降约2-3%
>      - 训练时间可缩短5-10倍
>
> 技术实现上，作者采用了动态分批次采样策略：
> ```python
> def sample_nodes(batch_nodes, full_graph, n_samples=100):
>     # 混合采样：当前batch节点 + 随机节点 + 难例节点
>     return torch.cat([
>         batch_nodes,
>         random.sample(full_graph.nodes, n_samples//2),
>         find_hard_negatives(batch_nodes)
>     ])
> ```
>
> 这种设计在保持排序质量的同时，显著提升了大规模知识图谱上的训练效率。



#### 自己瞎想的创新点

* 从 `figure-4` 得到的启发，

  - **Structure/Semantic**：仅优化单一特征分支的 RMSE 和 LTR 损失。
  - **Concatenation**：直接优化拼接后的特征，缺乏对结构和语义信息的差异化处理。
  - **RGTN**：通过协同注意力动态融合两种特征，并利用多任务损失（RMSE + LTR）联合优化。

  这种设计验证了 RGTN 的优越性：**简单拼接无法充分利用异构特征，而 RGTN 的融合机制能更灵活地平衡结构和语义信息。**

  那么我们能否根据谓词的种类（用聚类的方法得到语义相近的谓词种类），分别设置损失函数，根据图的拓扑结构（比方说强连通分量为一组。。）分别设置损失函数？

##### `deepseek` 的回答

> 你的想法非常有创新性，并且符合知识图谱（KG）中**异构特征**和**复杂关系**的处理需求。通过**基于谓词语义的聚类**或**基于图拓扑的分组**来设计差异化的损失函数，确实可以进一步提升模型对异构信息的利用能力。以下是对这一思路的详细分析和可行性探讨：
>
> ---
>
> ### **1. 基于谓词语义的差异化损失函数**
> #### **方法**
> - **谓词聚类**：  
>   使用聚类算法（如层次聚类、GMM、或基于KG嵌入的聚类）将语义相似的谓词分组（例如，"directed_by" 和 "written_by" 可能属于“创作关系”簇）。
> - **分组损失函数**：  
>   为每个谓词簇设计独立的损失函数（如不同权重的 RMSE 或 LTR 损失），以反映不同关系类型对节点重要性传播的差异。
>
> #### **优势**
> - **语义感知**：  
>   相似谓词（如“导演”和“编剧”）对节点重要性的影响可能类似，分组损失可以强化这种共性。
> - **缓解稀疏性**：  
>   低频谓词可通过聚类共享同一组损失参数，避免过拟合。
>
> #### **挑战**
> - **聚类质量依赖**：  
>   需要高质量的谓词嵌入（如通过TransE、CompGCN等生成）或领域知识指导聚类。
> - **动态调整**：  
>   某些谓词可能在不同上下文中作用不同（如“合作”关系在科学合作网络 vs. 电影网络中的重要性不同），静态分组可能不够灵活。
>
> #### **改进方向**
> - **自适应聚类**：  
>   在训练过程中动态调整谓词分组（如通过在线聚类或注意力机制）。
> - **混合损失**：  
>   保留全局损失的同时，为特定簇添加正则化项（例如，对“关键关系”簇加大 LTR 损失权重）。
>
> ---
>
> ### **2. 基于图拓扑结构的差异化损失函数**
> #### **方法**
> - **强连通分量（SCC）分组**：  
>   将节点按 SCC 划分（例如，一个紧密合作的科学家群体 vs. 孤立的节点），为不同 SCC 设计损失函数。
> - **中心性分组**：  
>   根据节点中心性（如度、Betweenness）分组，对核心节点和边缘节点采用不同的损失权重。
>
> #### **优势**
> - **结构感知**：  
>   强连通区域内的节点重要性可能高度相关，分组损失可以捕捉这种局部一致性。
> - **处理长尾分布**：  
>   对稀疏子图（如孤节点）采用更宽松的损失，避免模型过度拟合密集子图。
>
> #### **挑战**
> - **计算复杂度**：  
>   实时计算 SCC 或中心性会增加训练开销（尤其是动态图）。
> - **边界模糊性**：  
>   节点可能属于多个重叠社区（如演员同时参与多个电影系列），硬分组可能不合理。
>
> #### **改进方向**
> - **层次化损失**：  
>   全局损失 + 局部损失（如为每个 SCC 添加辅助 RMSE 损失）。
> - **图划分技巧**：  
>   使用 Louvain 等社区发现算法替代 SCC，更灵活地捕捉模块化结构。
>
> ---
>
> ### **3. 结合异构特征的通用框架建议**
> 若要系统化实现上述思路，可以扩展 RGTN 的架构如下：  
> 1. **谓词聚类分支**：  
>    - 在关系图变换层（Equation 1）中，为每个谓词簇分配独立的注意力头。  
>    - 每个簇的损失函数加权聚合（如关键簇权重更高）。  
> 2. **拓扑感知分支**：  
>    - 通过预处理（如 SCC 检测）或在线聚类（如 GNN 生成的节点嵌入）动态分组。  
>    - 在损失函数中为不同组添加正则化项（例如，强连通区域内的节点排名需更严格）。  
> 3. **动态融合模块**：  
>    - 使用元学习（如 HyperNetwork）或门控机制，根据当前输入调整不同分组的损失权重。
>
> ---
>
> ### **可行性结论**
> 你的想法**完全可行**，且已有部分研究支持类似方向（如关系聚类在 KG 嵌入中的应用、图结构感知的损失设计）。但需注意：  
> - **平衡复杂度与收益**：附加的聚类和分组可能增加计算成本，需通过实验验证提升效果。  
> - **避免过工程化**：优先验证简单分组（如基于谓词频次的粗聚类）的效果，再逐步细化。  
>
> 如果实现得当，这种异构感知的损失设计有望进一步提升节点重要性估计的精度，尤其是在复杂知识图谱（如多领域、动态演化）的场景中。



##### `gpt` 的回答

> 你的这个想法其实很有潜力，尤其是和 RGTN 这样的结构结合起来，可以更进一步发挥异构图中“谓词多样性”和“图结构信息”的优势。我们来详细分析一下你的两个核心想法的可行性：
>
> ------
>
> ### **想法一：根据谓词种类进行聚类，并分组设置损失函数**
>
> **核心动机：** RGTN中已经考虑了不同谓词（predicate）在重要性传递中有不同的作用，它们用独立的可学习表示（predicate embedding）参与注意力权重计算。
>
> **你扩展的思路：** 聚类这些谓词的embedding（或语义）得到语义相近的谓词类簇，对不同类簇引入不同的损失函数或加权机制，体现出不同类型关系对节点重要性的不同影响力。
>
> **可行性分析：**
>
> - ✅ **优点**：
>   - 利用谓词间语义相似性增强建模的语义感知能力；
>   - 可适配“强主导关系”和“辅助关系”之间的作用差异；
>   - 聚类结果可以辅助调节学习过程中的损失重点（类似Focal Loss思想）。
> - ⚠️ **挑战**：
>   - 谓词聚类后的类簇数量和划分质量会影响最终效果，**可能需要先训练出较稳定的谓词embedding；**
>   - 设计 group-wise loss 时要考虑不同组之间的“协同性”，避免模型对某组过拟合。
>
> **初步实现路径建议：**
>
> 1. 使用 K-Means 或 Spectral Clustering 对谓词embedding（训练中或预训练）进行聚类；
> 2. 每一组谓词对应一套 attention 或 loss scaling 参数（例如加权RMSE/LTR loss）；
> 3. 实验验证每一类关系对最终预测的重要程度，调节其 loss 权重。
>
> ------
>
> ### **想法二：根据图的拓扑结构进行分组，例如以强连通分量为单位**
>
> **核心动机：** 图中某些子结构，如强连通分量（SCC）或社区结构，可能内部节点影响力具有高度耦合性，从局部结构角度设置损失可能更合理。
>
> **你扩展的思路：** 将图划分为若干结构区域（如SCC、K-core、社区等），为每个结构区域单独设置损失函数或训练策略，例如分区域做局部排序或加权学习。
>
> **可行性分析：**
>
> - ✅ **优点**：
>   - 对重要性排序更具局部结构敏感性；
>   - 能在训练时控制不同结构子图的梯度贡献，有利于模型泛化；
>   - 对于低连接度区域（long-tail）可提高关注度。
> - ⚠️ **挑战**：
>   - 某些图划分方式（如SCC）在异构图中未必直接适用，可能要结合关系类型；
>   - 在 mini-batch 训练下，如何划分结构并动态保持子图信息是技术难点。
>
> **实现路径建议：**
>
> 1. 对原图进行结构划分（比如 Louvain 算法做社区发现，或计算 K-core/SCC）；
> 2. 在训练中，采用结构区域内的 **局部对比损失（local LTR）**，或者为不同区域设置 loss 权重；
> 3. 可考虑引入“结构感知注意力”机制，让模型学习到“哪些区域更重要”。
>
> ------
>
> ### **最终评估：想法是否靠谱？**
>
> **我觉得：非常靠谱。**
>
> 这两个方向实际上是对现有模型的**精细化建模思路的强化**，能更好地挖掘：
>
> - 谓词之间的语义层次结构；
> - 图拓扑下的信息耦合关系。
>
> 如果你能设计出合理的结构（尤其是分组策略与损失协同机制），这个方向是**非常有创新性和发表潜力**的。RGTN 本身已经为这个任务打下了良好基础，你的扩展可以看作是更进一步的“语义/结构引导的目标分组学习”。



