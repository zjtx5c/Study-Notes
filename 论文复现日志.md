## 论文复现日志

### 前言

立志成为会造轮子的掉包侠，会写丹方的炼丹师，全栈精通的开发者，会学更会玩的程序猿~



#### 如何想 idea？

[李沐分享](https://www.bilibili.com/video/BV1ea41127Bq?buvid=XYC6E55C7A1288F6E616688AAB8E564D963BF&from_spmid=main.space-contribution.0.0&is_story_h5=false&mid=zsw0awYQcKQ0Z8%2FLSPc5OQ%3D%3D&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=01e2a6f7-c6e5-4a5a-98ee-d4f813b3639d&share_source=COPY&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1723199264&unique_k=d7FYToH&up_id=1567748478&vd_source=56ba8a8ec52809c81ce429c827dc30ab)

$\text{研究价值} = \text{新意度} \times \text{有效性} \times \text{问题大小}$

* 写论文要追求什么？

1. 深刻，你是否揭示了一些比较本质的东西
2. 优美，你的论文的证明与描述是否有美感

* 如何定义有新意

1. 不要去堆砌无谓的复杂性，模型可以越简单越好
2. 论文的作者必须要呕心沥血才能发表文章？

##### 随便想想的 idea

idea：在对比学习的基础上，考虑将网络做深，从多个GNN模型中学习知识并通过，结合 cka 以及蒸馏的方法不断对上游目标进行矫正



#### 临时补充

* `self.training`

> `self.training` 是 **PyTorch 模块（nn.Module）自带的布尔属性**，用于指示当前模型是否处于“训练模式（training mode）”。
>
> 它的值由以下两个方法控制：
>
> | 方法            | 作用                                        |
> | --------------- | ------------------------------------------- |
> | `model.train()` | 将模型设为训练模式（`self.training=True`）  |
> | `model.eval()`  | 将模型设为评估模式（`self.training=False`） |

我们可以在我们的训练模型中这样设置代码来更好地处理损失

```python
class My_Model(nn.Module):
	'''
    处理的具体内容
    '''

    if self.training:
        '''
        ...
        '''
       return logits, loss
    else:
        return logits
```

* `feat_drop` 到底要实行几次？大层小层都要 drop 吗？还是说 drop 一次即可？

#### 项目结构的设置

* 项目结构：一般都是工程上的最佳实践，需要多看别人的代码自己总结。可以参考知乎的[这篇](https://www.zhihu.com/question/406133826)
  常用的一个结构可以是这样

  ```
  --project_name/
  ----data/：数据
  ----checkpoints/：保存训练好的模型
  ----logs/：日志
  ----model_hub/：预训练模型权重
  --------chinese-bert-wwm-ext/：
  ----utils/：辅助模块，可以是日志、评价指标计算等等
  --------utils.py
  --------metrics.py
  ----models/：模型
  --------model.py
  ----configs/：配置文件
  --------config.py
  ----datasets/：加载数据
  --------data_loader.py
  ----main.py：主程序，包含训练、验证、测试和预测
  
  作者：西西嘛呦
  链接：https://www.zhihu.com/question/406133826/answer/2898344659
  来源：知乎
  著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
  ```

  若项目比较简单，也可以是这样
  ```
  --project_name/
  ----data/：数据
  ----checkpoints/：保存训练好的模型
  ----logs/：日志
  ----model_hub/：预训练模型权重
  --------chinese-bert-wwm-ext/：
  ----utils/：辅助模块，可以是日志、评价指标计算等等
  --------utils.py
  --------metrics.py
  ----model.py
  ----config.py
  ----data_loader.py
  ----main.py：主程序，包含训练、验证、测试和预测
  
  作者：西西嘛呦
  链接：https://www.zhihu.com/question/406133826/answer/2898344659
  来源：知乎
  著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
  ```

### 总结

#### 读取与存放文件

* 理解序列化与反序列化

  `pickle` 是一个**用于序列化和反序列化 Python 对象的模块**。**序列化是将 Python 对象转换为字节流（例如，存储在文件中），而反序列化是将字节流重新转换为 Python 对象。**

* `pickle.load()` 与 `pickle.dump()`

> `pk.load`（通常是 `pickle.load` 的简写）是与 `pickle.dump` 对应的操作，它用于从文件中**反序列化数据**，**将存储在文件中的字节流转换回 Python 对象。**
>
> 具体来说，`pickle.load` 从一个已经打开的文件中读取数据，并返回反序列化后的 Python 对象。示例如下：
>
> ```python
> with open('file.pkl', 'rb') as f:
>    	obj = pickle.load(f)
> ```
>
> 在这个例子中，`file.pkl` 是一个包含序列化数据的文件，`pickle.load(f)` 会将文件中的字节流读取并转换为原来的 Python 对象，保存在 `obj` 中。这里 `rb` 表示以二进制读取模式打开文件。
>
> ___
>
> 
>
> `pk.dump` 是 `pickle.dump` 的简写，它将一个对象序列化并写入一个文件或类似文件的对象中。语法如下：
>
> ```python
> import pickle
> 
> with open('file.pkl', 'wb') as f:
>    	pickle.dump(obj, f)
> ```
>
> 在这个例子中，`obj` 是你想要序列化的 Python 对象，`f` 是一个已经打开的文件对象（以**二进制写模式** `'wb'` 打开）。`pickle.dump` 会将 `obj` 写入文件 `file.pkl` 中。
>
> `pickle` 模块通常用于**将模型、数据结构等保存在磁盘上，以便后续加载和使用。**



* 关于 `.pt` 文件与 `.pkl` 文件

> **区别总结**
>
> 1. **用途**：
>    - `.pt` 主要用于 PyTorch **模型和张量**的保存与加载。
>    - `.pkl` 用于 Python 中广泛的对象序列化，包括非 PyTorch 对象。
> 2. **文件格式和方法**：
>    - `.pt` 是通过 `torch.save` 和 `torch.load` 保存和加载的，**专为 PyTorch 对象设计。**
>    - `.pkl` 是通过 `pickle.dump` 和 `pickle.load` 保存和加载的，**通用于 Python 对象。**
> 3. **兼容性**：
>    - `.pt` 适用于 PyTorch 环境，更能保证 PyTorch 模型的兼容性。
>    - `.pkl` 是更通用的文件格式，适用于任何 Python 对象，但不专门优化处理 PyTorch 模型。
>
> 简而言之，`.pt` 是 PyTorch 特有的文件格式，而 `.pkl` 是 Python 的通用序列化格式。

#### 设置随机种子

在 `PyTorch` 及 `DGL` 相关的代码中，为了确保实验的可复现性，一般需要在以下几个地方设置随机种子

（1）python 内置库（2）Numpy（3）Pytorch（4）PyTorch 计算相关（5）DGL（6）操作系统

```python
def set_random_seed(seed=0):
    '''
    设置随机种子，以保证实验的可复现性
    :param seed: int, 要使用的随机种子
    :return: None
    '''
    # Python 内置随机库
    random.seed(seed)

    # NumPy 随机种子
    np.random.seed(seed)

    # 设置 Python 运行时的哈希种子（影响某些哈希操作的随机性）
    os.environ['PYTHONHASHSEED'] = str(seed)

    # PyTorch CPU 端随机数
    torch.manual_seed(seed)

    if torch.cuda.is_available():
        # 设置当前 GPU 的随机数种子
        torch.cuda.manual_seed(seed)
        # 设置所有可用 GPU 的随机数种子
        torch.cuda.manual_seed_all(seed)

        # 让 CuDNN 以确定性方式执行计算，以确保结果可复现
        torch.backends.cudnn.deterministic = True
        # 关闭 CuDNN 的自动优化算法，以防止影响结果可复现性
        torch.backends.cudnn.benchmark = False
        # 禁用 CuDNN 加速，以最大程度保证实验可复现
        torch.backends.cudnn.enabled = False

    # DGL 相关随机种子
    dgl.random.seed(seed)

```

#### 设置最佳模型路径

* 需要用到的函数

```python
os.path.join()
os.path.exists()
'_'.join([f'{k}{v}' for k, v in parameters_dic.items()])
```



一般最佳模型都是保存在 `ckpt` 文件夹下，比如说 `project_name/ckpt/...` ，若有预训练模型，则保存在对应的预训练的文件夹下则 `preject_name/pretrain/ckpt/...`。若要训练多个模型，则可以这样 `project_name/ckpt/mode1/...` 或者 `project_name/pre_train/ckpt/model1/...`

```
--project_name
----ckpt
------model1
------model2
```

```
--project_name
----pretrain
------ckpt
--------model1
--------model2
```

后面的路径可以根据自己的超参数自己添加，比如早停忍耐轮次，重要性节点的采样比率等等。最后一层可以放上最后的数据集，如下所示

```
--project_name
----pretrain
------ckpt
--------model1
----------imp_ratio_0.1
------------patience_20
--------------fb15k
```

使用字符串配合 `args.` 解析命令参数来创建文件夹。具体上实现的思路是：分别写出每一层的**相对目录**，**最后拼接上去**，以我们上述举的例子为例

比如我们现在要保存预训练的模型 `model1` , 重要性节点的采样比率`imp_ration` 设置为0.1，早停忍耐轮次`patience` 设定为20。那么我们可以这样
`pretrain_root = 'pretrain/ckpt/'`  **（0）先设置根目录**

`model_path = str(args.model) + '/'`		**（1）设置模型相对路径**

`imp_ratio_path = 'imp_ratio_' + str(args.imp_ratio) + '/'`		**（2）设置节点重要性相对路径**

`patient_path = 'patience_' + str(args.patience) + '/'`				**（3）设置早停忍耐轮次相对路径**

`dataset_path = dataset_name + '/'` 			**（4）设置数据集相对路径**

最后将整个路径拼接起来：

```python
out_save_path = os.path.join(pretrain_root, model_path, imp_ratio_path, patience_path, dataset_path)
if not os.path.exists(out_save_path):
    os.makedirs(out_save_path, exist_ok = True)
```



这种方法，当参数过多是可能会很长。因此，此基础上，我们可以将其他的超参数（比如 `lr`， 交叉验证的轮次 `cross_id`， 损失 `loss` 的系数）添加到最终的模型名中为模型命名如：

`tmp = dataset_name + '_struct_pregat_pretrained_lr' + str(args.lr) + '_loss_' + str(args.eta) + '_' + str(cross_id) + '.pkl' `

`out_pretrained_path = os.path.join(out_save_path, tmp)`

上述这种方法较为冗长，我们可以**使用字典管理参数**

```python
# 定义模型文件名的关键参数
model_name_parts = {
    "dataset": dataset_name,
    "model": "pregat_pretrained",
    "lr": args.lr,
    "loss": args.eta,
    "cross": cross_id
}

# 生成文件名（去掉值为 None 或空字符串的参数）
model_filename = "_".join([f"{k}{v}" for k, v in model_name_parts.items() if v is not None]) + ".pkl"

# 最终模型保存路径
out_pretrained_path = os.path.join(out_save_path, model_filename)
```



#### 设置 cuda 并将数据传到 cuda

* 需要用到的函数

```python
# 设置 GPU 编号
torch.cuda.set_device()	# 这里可以填 cuda = 0, cuda = 1, 是说用机器的第几块 GPU

# 将张量移动到 cuda 上
.cuda()		# 只能移到默认 GPU（cuda:0） 或你手动指定的 GPU。
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
.to(device)	# 更加通用
```

* 需要思考有哪些数据要放到 cuda 上

  * 模型的参数：模型的参数（如权重、偏置等）应该放在 GPU 上进行计算和更新。尤其在训练过程中，这些参数会经过反向传播并需要在 GPU 上更新。
    ```python
    model.to(device)  # 将模型移到 GPU 或 CPU，device 是 "cuda" 或 "cpu"
    ```

    

  * 训练数据：训练数据（例如**输入特征、标签**等）也需要放到 GPU 上，特别是当训练过程需要频繁地在 GPU 和 CPU 之间传输数据时，可能会成为性能瓶颈。**所有输入数据（如图片、文本数据）和对应的标签都应被放在 GPU 上**，以提高训练效率。

    ```python
    inputs = inputs.to(device)  # 使用 .to() 更通用
    labels = labels.to(device)  # 使用 .to() 更通用
    ```

    还有比如说与我目前方向相关的图数据：

    ```python
    g = g.int().to(device)
    ```

    

  * 损失函数中的相关数据：损失函数中的相关数据（例如，模型预测的输出和真实标签）也应放在 GPU 上进行计算。否则，如果损失函数中的数据仍然在 CPU 上，PyTorch 会自动将它们传输到 GPU，但这会导致性能损失。

  * 优化器的状态（通常由优化器自动管理）：优化器（如 `Adam`, `SGD`）本身的参数通常不会显式地放到 GPU 上，因为它会自动跟踪模型参数的梯度。然而，**如果你自己实现了优化器，或优化器的状态变量需要与模型参数一起计算，** 这些状态（例如动量等）也需要放到 GPU 上。例如，在使用 `torch.optim` 时，优化器会**自动处理 GPU 迁移**：
    ```python
    optimizer = torch.optim.Adam(model.parameters())  # 优化器会自动使用模型所在设备的参数
    ```

#### 交叉验证

* 框架如下

```python
for cross_id in range(args.cross_num):
    '''
    中间处理
    包括预处理、模型保存路径设置、其他提取数据、数据分割
    cuda 设置
    '''
   if cross_id == 0:
            print('---------Dataset Statistics---------')
            print('一些数据信息')
            print('-------------Pretraining------------') # (或者这里提示 training)
        
    print(f'cross: {cross_id}')
    print('------------')

   	print('Model Pretraining')
    '''
    其他处理
    '''
```

#### 早停机制（用类实现）

* 最基础的需要记录 7 项

  (1) early_stop (2) patience (3) counter (4) best_score (5) best_epoch (6) save_path (7) min_epoch

* 具体实现

```python
class EarlyStopping_simple:
    def __init__(self, patience=50, save_path=None, min_epoch=-1):
        self.patience = patience
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.best_epoch = None
        self.save_path = save_path
        self.min_epoch = min_epoch

    def step(self, acc, epoch, model):
        score = acc
        if epoch < self.min_epoch:
            return self.early_stop
        if self.best_score is None:
            self.best_score = score
            self.best_epoch = epoch
            self.save_checkpoint(model)
        elif score < self.best_score:
            self.counter += 1         
            if self.counter >= self.patience:
                self.early_stop = True
                print()
                print(f'EarlyStop at Epoch {epoch} with patience {self.patience}')
        else:
            self.best_score = score
            self.best_epoch = epoch
            self.save_checkpoint(model)
            self.counter = 0
        return self.early_stop

    def save_checkpoint(self, model):
        '''Saves model when validation loss decrease.'''
        torch.save(model.state_dict(), self.save_path)
```



#### 损失函数与模型之间的代码组织

我们可以先观察一下 `licap` 之间对损失函数以及模型之间的代码处理

```python
class Predicate_GAT(nn.Module):
    def __init__(self, args, g, in_dim, hidden_dim , out_dim, num_heads, rel_num, rel_dim, 
                 loss_function=None,
                 loss_1_fcn=None,
                 loss_2_fcn=None,
                 train_important_idx=None,
                 train_normal_idx=None,
                 imp_bin_idx2node_idx=None,
                 imp_node_idx2bin_idx=None,
                 imp_node_coeff=None):
        super(Predicate_GAT, self).__init__()
        self.layer1 = MultiHead_Predicate_GAT_Layer(g , in_dim, hidden_dim, rel_dim, num_heads)
        self.layer2 = MultiHead_Predicate_GAT_Layer(g, hidden_dim*num_heads, out_dim, rel_dim, 1)

        self.loss_fn = loss_function
        self.loss_1_fcn = loss_1_fcn
        self.loss_2_fcn = loss_2_fcn
        

        self.train_important_idx = train_important_idx
        self.train_normal_idx = train_normal_idx
        
        self.imp_bin_idx2node_idx = imp_bin_idx2node_idx
        self.imp_node_idx2bin_idx = imp_node_idx2bin_idx
        self.imp_node_coeff = imp_node_coeff

        self.loss_eta1 = args.loss_eta1
        self.loss_eta2 = args.loss_eta2

        # Relation Embedding
        self.rel_emb = nn.Embedding(rel_num, rel_dim) 


    def forward(self, node_feats, edge_types, idx=None):

        edge_feats = self.rel_emb(edge_types) # [num_edges, rel_dim]

        h = self.layer1(node_feats, edge_feats)
        h = F.elu(h)
        h = self.layer2(h, edge_feats)

        # caculate_loss            
        embed_all = h # [N_node, dim]
                     
        imp_bin_centroids, bin2centroids = return_centroids(embed_all, self.imp_bin_idx2node_idx, self.train_important_idx) # [bin_num, dim]
                
        imp_node_centroid = return_imp_node_centroid(self.imp_node_idx2bin_idx, bin2centroids, self.train_important_idx) # [imp_num, dim]    
        embed_normal = embed_all[self.train_normal_idx] ### mod sample by constant
                
        loss_1 = self.loss_eta1 * self.loss_1_fcn(embed_all[self.train_important_idx], embed_normal)

        loss_2 = self.loss_eta2 * self.loss_2_fcn(embed_all[self.train_important_idx], imp_bin_centroids, imp_node_centroid, self.imp_node_coeff)

        loss = loss_1 + loss_2

        return h, loss, loss_1, loss_2
```

我们可以一码多用

* `self.training`

> `self.training` 是 **PyTorch 模块（nn.Module）自带的布尔属性**，用于指示当前模型是否处于“训练模式（training mode）”。
>
> 它的值由以下两个方法控制：
>
> | 方法            | 作用                                        |
> | --------------- | ------------------------------------------- |
> | `model.train()` | 将模型设为训练模式（`self.training=True`）  |
> | `model.eval()`  | 将模型设为评估模式（`self.training=False`） |

我们可以在我们的**训练模型（`model`）**中**这样设置代码来更好地处理损失**

```python
class My_Model(nn.Module):
	'''
    处理的具体内容
    '''

    if self.training:
        '''
        ...
        '''
       return logits, loss
    else:
        return logits
```













对于比较复杂的损失，我们直接写一个类对其进行封装处理

这段代码将损失的计算直接搬到了模型的 `forward` 函数中，也就是说，模型每一次前向传播计算处理完数据之后，直接进行了损失计算，即我们在 `Predicate_GAT` 类中封装了损失计算逻辑，对于比较复杂的损失计算，这种设计时合理的。

同时我们需要在**定义模型实例时**传入计算损失函数**需要用到的辅助数据**如 `imp_bin_idx2node_idx` 等），这些是与任务特定信息相关的参数。将这些数据封装在模型的类中，是一种常见的做法，可以在整个训练过程中**保持一致性**。损失函数的计算依赖于其 `forward` ，而 `forward` 需要使用的数据则是在定义模型实例时**传入的辅助数据**



==事实上，我个人认为，将损失函数的计算写在外部是更好的选择==

> 将损失计算移到外部进行，是一种常见的做法，尤其适用于那些**损失函数较复杂**或者需要灵活调整的情况。它有助于代码的模块化、灵活性和复用性，并且使得模型的实现更加专注于核心任务，即图数据的处理和嵌入计算，放在外面可以减小这个类的实例的**调入调出的开销，提高内存的使用率**。我们可以根据任务需求选择是否采用这种结构化的方式。

即，我们可以直接在训练循环中，使用模型的输出（`embed_all`）来计算损失，如下所示

```python
# 假设已经实例化了模型 Predicate_GAT 和损失函数
model = Predicate_GAT(args, g, in_dim, hidden_dim, out_dim, num_heads, rel_num, rel_dim)

# 训练过程
for epoch in range(num_epochs):
    model.train()
    
    # 获取节点特征和边特征
    node_feats = ...
    edge_types = ...
    
    # 前向传播得到嵌入表示
    embed_all = model(node_feats, edge_types)
    
    # 损失计算
    imp_bin_centroids, bin2centroids = return_centroids(embed_all, imp_bin_idx2node_idx, train_important_idx)
    imp_node_centroid = return_imp_node_centroid(imp_node_idx2bin_idx, bin2centroids, train_important_idx)
    embed_normal = embed_all[train_normal_idx]
    
    loss_1 = loss_eta1 * loss_1_fcn(embed_all[train_important_idx], embed_normal)
    loss_2 = loss_eta2 * loss_2_fcn(embed_all[train_important_idx], imp_bin_centroids, imp_node_centroid, imp_node_coeff)
    
    loss = loss_1 + loss_2
    
    # 反向传播和优化
    loss.backward()
    optimizer.step()

```

#### 网络搭建

参考的代码是 `RGTN` 模块 

* 个人感觉，一般来讲，新框架的搭建一般要写三个类（1）最底层的就是一个卷积层（2）第二个类作用在第一个类的基础上，**一般用来控制层数或者是头数**（3）第三个类作用在第二个类的基础上，会添加一些其他的组件（比如说优化的部分，损失函数，协同注意力融合等模块）

  其他的情况比如第0层，就是写一个神经元类（在循环神经网络中常见）

* **第一层**： 一般在**卷积层部分**的初始化需要添加如下参数

  `in_dim`, `out_dim`，`num_heads`, `feat_drop`, `attn_drop`，`layer_norm`, `batch_norm`, `residual` , 以及其他额外的输入，比如 `rel_dim` （表示边嵌入）

  是否传入 `g` 视情况而定，我们可以在 `forward` 过程中传入 `g`

  因为这是最底层的层，所以一般不会包含隐藏层维度

* **第二层**：一般需要写入第一层中的所有参数包括

  `in_dim`, **`hidden_dim`**，**`heads`**, `feat_drop`, `attn_drop`，`layer_norm`, `batch_norm`, `residual`  等等

  其中这里 `heads` 应为一个列表，表示每一层启用的头的个数

  视情况而定是否传入 `g`， 以及还需要考虑**层的数量 `num_layers`** ，**设置隐藏层 `hidden_dim`**。

  **如果，最后的输出需要一些魔改操作的话，其实比较推荐在这一层==只处理隐藏层==，而不处理输出层，输出层可以考虑在第三层处理，很关键**

  若需要嵌入的话，还需要传入`rel_num` `rel_dim` 当然还有 **`rel_emb` ，或者自己创建（`rel_emb = None`）** 等等

  并组织各个层之间的维度对齐

* **第三层**：

  一般需要传入损失以及计算损失了（包括需要传入一些计算损失需要用到的**辅助数据与数据结构**），可学习的参数；各种 `attn_drop` 之类的配合 `args` 构造出来。
  
  训练所需要的索引 `idx` 与标签信息 `labels`

#### 如何在图上进行采样

见 Pytorch 笔记

### 经验与造轮子

#### 损失函数

* 最终得到的这个标量损失最后一步**一般是由一组向量推来**，**一般情况下我们使用 `.mean` 来得到损失而不是用 `.sum` 得到损失**（注意，我们一般情况下不对向量进行反向传播，即我们要门对其做 `.mean` 处理，要么对其做 `.sum` 处理）

  * 思考为什么

  > （1）保持梯度稳定性
  >
  > 如果使用 `.sum()`，那么损失的大小会随 batch size 增大而增大，导致梯度也变大。例如：
  >
  > ```python
  > import torch
  > 
  > x = torch.randn(10, requires_grad=True)  # 10个样本
  > loss = x**2  # 每个样本的损失
  > loss_sum = loss.sum()  # 直接求和
  > loss_mean = loss.mean()  # 计算均值
  > 
  > loss_sum.backward()  # 计算梯度
  > print(x.grad)  # 梯度较大
  > 
  > x.grad.zero_()  # 清空梯度
  > 
  > loss_mean.backward()  # 计算梯度
  > print(x.grad)  # 梯度较小，数值稳定
  > ```
  >
  > **现象：** `loss_sum` 的梯度比 `loss_mean` 大 **10 倍** （即 `batch_size` 倍），因为 `.sum()` 直接把所有样本的损失加起来，导致梯度变大。
  >
  > 如果 batch size 变化，梯度的大小也会变得不稳定，而 `.mean()` 可以保持梯度在一个稳定的范围内，使得学习率不需要调整。
  >
  > （2）与学习率无关
  >
  > 在梯度下降中，学习率 (`lr`) 决定了参数更新的步长。如果我们使用 `.sum()`，梯度的数值会随着 batch size 改变，导致学习率需要调整：
  >
  > - 用 `.sum()`，如果 batch size 变大，梯度变大，可能导致梯度爆炸，**需要手动缩小学习率**。
  > - 用 `.mean()`，梯度大小不变，学习率可以保持一致，不需要频繁调整。
  >
  > 因此，`.mean()` 使得**同样的学习率适用于不同的 batch size**，从而提高了模型的稳定性和可移植性。
  >
  > （3）使不同 batch 的损失具有可比性
  >
  > 假设我们有两个 batch，batch size 分别是 32 和 16，如果使用 `.sum()`，那么 batch1 的总损失比 batch2 的损失大了一倍，这不合理，因为两个 batch 的样本**平均损失是一样的**。但如果使用 `.mean()`，尽管两个 `batch` 的 `batch_size` 不一样，但是它们的梯度却没有与 `batch_size` 产生强线性关系，使得模型训练更稳定。
  
* 自己写了一个同构图上的多头谓词 `GAT` （更加并行）==**核心是理解注意力系数的更新操作（需要一点线代的洞察力！！）**==

```python
class GAT(nn.Module):
    def __init__(self, g, in_dim, out_dim, num_heads, rel_dim):
        super(GAT, self).__init__()
        self.g = g
        self.fc = nn.Linear(in_dim, num_heads * out_dim)
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.num_heads = num_heads

        self.attn_l = nn.Parameter(torch.empty(1, num_heads, out_dim))
        self.attn_mid = nn.Parameter(torch.empty(1, num_heads, rel_dim))
        self.attn_r = nn.Parameter(torch.empty(1, num_heads, out_dim))
        self.reset_parameters()

        
    def reset_parameters(self):
        gain = nn.init.calculate_gain('relu')
        nn.init.xavier_normal_(self.fc.weight, gain = gain)
        nn.init.xavier_normal_(self.attn_l, gain = gain)
        nn.init.xavier_normal_(self.attn_mid, gain = gain)
        nn.init.xavier_normal_(self.attn_r, gain = gain)

        
    def edge_attention(self, edges):
        return {'e': F.leaky_relu(edges.src['e_l'] + edges.edata['e_mid'] + edges.dst['e_r'])}  # (E, num_heads, 1)
    
    
    def message_func(self, edges):
        return {'e': edges.data['e'], 'z': edges.src['z']}

    
    def reduce_func(self, nodes):
        h = torch.sum(nodes.mailbox['e'] * nodes.mailbox['z'], dim = 1) # (N, num_heads, out_dim)
        return {'h': h}


    def forward(self, h, p):
        z = self.fc(h).view(-1, self.num_heads, self.out_dim)   # (N, num_heads, out_dim)
        p = p.unsqueeze(dim = 1).repeat(1, self.num_heads, 1)   # (E, num_heads, out_dim)
        e_l = (z * self.attn_l).sum(dim = -1, keepdim = True)  # (N, num_heads, 1)
        e_mid = (p * self.attn_mid).sum(dim = -1, keepdim = True)  # (E, num_heads, 1)
        e_r = (z * self.attn_r).sum(dim = -1, keepdim = True)  # (N, num_heads, 1)
        g.ndata.update({'e_l': e_l, 'e_r': e_r, 'z': z})
        g.edata.update({'e_mid': e_mid})
        g.apply_edges(self.edge_attention)

        e = g.edata['e']    # (E, num_heads, 1)
        g.edata['e'] = dgl.ops.edge_softmax(g, e)

        g.update_all(
            self.message_func,
            self.reduce_func
        )

        return g.ndata.pop('h') # (N, num_heads, out_dim)
    

class MultiHeadGAT(nn.Module):
    def __init__(self, g, in_dim, hidden_dim, out_dim, num_heads, rel_dim, rel_num, merge = 'cat'):
        super(MultiHeadGAT, self).__init__()
        self.layer1 = GAT(g, in_dim, hidden_dim, num_heads, rel_dim)
        self.layer2 = GAT(g, num_heads * hidden_dim, out_dim, 1, rel_dim)
        self.p_embed = nn.Embedding(rel_num, rel_dim)

    def forward(self, node_feats, edge_types):
        edge_feats = self.p_embed(edge_types)
        h = self.layer1(node_feats, edge_feats) # (N, num_heads, out_dim)
        h = h.view(-1, self.layer1.num_heads * self.layer1.out_dim)
        h = F.elu(h)
        h = self.layer2(h, edge_feats)  # (N, num_heads, out_dim) (N, 1, out_dim)
        h = torch.mean(h, dim = -1)
        return h
```



### 当前NIE方向的研究情况（重要）

最前沿的论文将本领域的方向瞄准到了**半监督学习** / **无监督学习**。（因为图标注是缺失的，之前的工作忽略了在实际中真实的节点重要性数据通常只是部分被标记这一事实）

这里的**无监督学习**是**对比学习**

总之，大部分之前的工作都是在想进办法从不同的角度比如局部与全局（**结构信息**）、异构图信息、外部输入信息（**文本信息**）来挖掘更多的隐藏信息（即通过各种信息增强手段来提升模型性能，但我认为都是换汤不换药，本质上没有什么突破性的创新工作），通过一些框架手段（比如注意力机制、transform、对比学习等）生成更高质量的嵌入向量，用这些质量很高、浓度很高的嵌入向量来估计节点的重要性。此外，也逐渐从关注节点的排名转移到节点重要性的具体值



而未来的研究重点则大多瞄向了时序与动态领域：就是未来打算用更先进的动态时间建模技术和更丰富的外部、多模态信息，来提升对“重要性值”这一指标的准确估计能力。



### 我的 idea 记录（重要）

部分已经迁移到 NIE 这个项目中了

想 idea 的时候突然领悟到了为什么 EASING 这篇工作的制造伪标签能够提高模型的泛化能力。

* 鉴于本人水平有限，因此先笼统地记录一下，觉得靠谱之后在进行详细地规划，然后开始做实验，当然得先跑 baseline

* 目前的大方向：蒸馏技术、无监督学习、半监督学习

* 有一个聚焦点就是无监督学习，由于 EASING 是第一篇提出的在图上做无监督学习的论文（2025年很新），那么我们是否可以把目标聚焦在伪标签的质量上，以此开辟其中一个创新点。

  仅针对 EASING 这篇论文的静态图领域，有如下创新点（GPT给出）：

  1. **引入不确定性建模**：目前，EASING框架在半监督学习中引入了不确定性正则化，通过估计节点的重要性和不确定性联合优化。这种方法是通过Distribution-based Joint Estimator (DJE)网络实现的，该网络使用编码-解码结构来共同估计节点的价值和不确定性  。如果能够进一步优化不确定性的建模方式，或者结合多种不确定性来源（如数据噪声、模型不确定性），可以提高估计精度，并可能成为创新点。
  2. **图神经网络的结合**：虽然EASING使用了深度神经网络架构来进行节点重要性估计，但结合更多图结构信息（如考虑边的加权、节点属性的多模态信息）来提升节点的重要性估计仍是一个潜在的研究方向。例如，可以探索不同类型的边对节点重要性估计的影响，或引入图中的局部与全局结构信息以改进模型的表现 。
  3. **数据增强与伪标签生成**：半监督学习中的伪标签生成是一个关键点，目前的工作通过蒙特卡罗Dropout方法生成伪标签，这为模型提供了丰富的无标签数据 。但可以进一步优化伪标签的质量，采用更加先进的生成策略，如基于对抗训练的方法来提高伪标签的准确性和稳定性，这也是一个潜在的创新点。
  4. **动态图模型**：当前EASING框架主要针对静态图，但动态图的研究尚未完全深入。通过探索动态图节点重要性估计，特别是在节点重要性随时间变化的情况下，可能带来新的研究成果。这种动态性的引入有可能使得模型更加灵活，并适应不同类型的图演变。
  5. **多任务学习**：节点重要性估计不仅仅是一个回归问题，还可以与其他图学习任务（如节点分类、图分类）结合，通过多任务学习来共享知识，从而进一步提升性能。这种跨任务的学习方式在静态图的节点重要性估计中仍然是一个值得探索的方向。

  综上，静态图上的改进可以从多个方面入手，特别是在不确定性建模、数据增强、动态图建模和多任务学习方面，这些方向都有较大的创新空间。

在对比学习的基础上，考虑将网络做深，从多个GNN模型中学习知识并通过，结合 cka 以及蒸馏的方法不断对上游目标进行矫正（这个太笼统了）。



我们考虑聚焦无监督学习，由于图天然适合做聚类。我有一个不成熟的想法就是，首先根据某一种策略对图进行“聚类”（节点类型？谓词类型？相似度），这样图就会变成一张张有代表性的子图，对这些子图使用 transform 等操作进行特征提取。而在每个聚类中大概率会有有标签的节点和未标记的节点，是不是能想一种做法加速训练并且能保证生成的伪标签的质量（但是同时要注意预防过拟合，毕竟加入伪标签的目的是为了提高泛化能力）。

还有没有其他创新点呢比如如何加入蒸馏技术等其他呢？伪标签的损失函数又该如何设计呢？



有一个改进建议说是：

- 聚焦一个核心问题（如“如何生成高质量的回归伪标签”），提出一个**理论保证**（类似EASING的Theorem 1）。
- 设计**全新的伪标签生成机制**（例如：基于最优传输的伪标签分配，或聚类与重要性值的联合优化）。**建议**：聚焦**动态聚类+伪标签质量优化**，提出一个**理论证明**或**全新损失函数**，并设计**可视化案例**（如展示聚类前后伪标签的分布变化）。







### 	LICAP

==在进行训练时，为了公平比较，**语义特征和结构特征被连接起来**（~~之前的实验并没有做到这一点，而是只只选取了语义特征或者结构特征~~）作为节点输入特征==

与以往知识图谱上的 NIE 方法不同，这项工作引入了现实世界中对重要节点（即具有高重要性分数的节点）偏好的潜在先验知识。**为了注入这种先验知识，提出了一种新颖的采样策略，结合对比学习，利用可用的节点重要性分数预训练节点嵌入**。还需注意的是，所提出的 LICAP 是一种**插件式方法**，可以集成到以前的 NIE 方法中，而不是一种新的特定 NIE 方法。

创新点：

1. 提升了 `embedding` 的质量

2. label 感知分组将连续分数划分成有序区间以**生成对比样本**；分箱机制，**顶层节点优先 分层采样机制**

   这么做的其中一个原因是，我们完全不需要在预训练阶段就估计节点重要性，这一任务将在下游实现；我们在预训练阶段的目的仅是为了得到更好的嵌入表

   这样一来，原本并非为回归问题设计的对比学习，现在可以采用对比样本对嵌入进行预训练。

3. 谓词 GNN
4. 通过联合最小化两个对比损失优化节点嵌入。



细节：

1. 顶层节点优先，分层采样机制

   top-bin 与 non-top-bin 根据 `important ratio`  $\gamma$ 划分，代码中是取 0.1

   ==理解一下 InfoNCE 损失函数==

2. 划分为第一级对比样本与第二级对比样本（分别对应 $L_1$ 和 $L_2$ 的 loss）

   在顶层区间中，将每个节点与顶层原型（即图 3 中的三角形）进行正对比。顶层原型是通过对所有顶层节点的嵌入进行元素级平均得到的。对于负对比，我们将从非顶层区间中随机采样的非顶层节点，作为每个顶层节点的负样本对。

   对于更细区间中的每个顶级节点（这里的更细区间是指将**顶层区间**划分为更细区间），其正对比样本被定义为该更细区间的原型（例如，图 4 中包含红色节点的更细区间的红色三角形），这同样是通过对该更细区间内节点的嵌入进行元素级平均得到的。至于负对比样本，它们分别也是其余更细区间的原型，我们设计了一种重新加权负采样机制，以保持这些更细区间之间的相对顺序。这种重新加权负采样机制基于这样一种直觉：来自距离更远区间的样本更不相似（或更不接近）。因此，我们引入一个接近系数 $\beta$ 来对负对比对进行重新加权，使得接近系数越大，相应的负样本对项在分母中的影响就越大。

   第一级对比样本和 $L_1$ 损失旨在更好地将顶层节点与非顶层节点区分开来，而第二级对比样本和 $L_2$ 损失则试图通过保持更细区间之间的相对顺序，来更好地区分顶层区间内的顶层节点。





疑惑点：

1. 这么做对比学习的目的是什么？

2. 这个接近系数 $\beta$ 到底有什么用？为什么要引入它，是用来区分什么的
   个人感觉是，正样本对都在同一层，所以正样本对之间是没有差异的，但是负样本对在不同层，要体现层与层之间的差异，用一个接近系数 $\beta$ 来衡量

3. 为什么要设计 $L_1$ 和 $L_2$ 损失，如果只是想找更优质的节点，直接降序排序得到不就行了吗？这么做的意义是什么？其更深层的原理和机制是什么。论文中提到要通过使用InfoNCE损失来结合对顶级节点偏好的先验知识来预训练节点嵌入，如何理解？我到现在还是无法理解这种损失到底是在做什么？？（还是得还之前 `deepwalk` 的账啊）

   突然之间秒懂，是要根据损失去调整嵌入特征 $\mathbf{h}_i$， 获得更优质的嵌入特征！比如获得的特征能够更好地区分 top-bin 中地节点和 non-top-bin 中的节点；同时也能更好地区分 top-bin 中其他不同层之间的节点，**通过对比学习和结合先验知识，生成更优质的节点嵌入，为后续的节点重要性估计任务提供更好的基础。**



#### 预备知识点

* 预训练范式

  * > 预训练范式（Pre-training Paradigm）是深度学习领域的一种模型训练方法，核心思想是通过**分阶段训练**来提升模型性能：
    > **先在大规模通用数据上进行无监督或自监督的预训练**，学习通用特征表示；**再在特定任务的小规模数据上进行微调**（Fine-tuning），适应下游任务。这一范式显著降低了数据标注成本，推动了自然语言处理（NLP）、计算机视觉（CV）等领域的突破。

* 对比学习，无监督学习包括对比式学习与生成式学习，**对比学习是无监督学习的一种**

  * > 在重要节点识别任务中，对比学习的主要思想是：
    >
    > 1. **构造正样本（Positive Sample）**：通常是**同一节点的不同视图**，或者**同类别的重要节点**。
    > 2. **构造负样本（Negative Sample）**：通常是**普通节点**，或者**不同类别的节点**。
    > 3. **优化目标**：让重要节点的表示尽可能靠近，而普通节点远离它们，以便更好地区分节点的重要性。
    >
    > 常见的方法包括：
    >
    > - **基于全局结构的对比**：让重要节点在全局网络中保持一致性。
    > - **基于局部子图的对比**：让重要节点的局部结构与其重要性保持一致。
    > - **基于动态变化的对比**：在动态图中，学习重要节点随时间变化的稳定性。
    
  * InfoNCE 将一个正样本与多个负样本进行区分，已成为更受欢迎的对比学习损失函数。该文章在节点重要性估计（NIE）问题中采用对比学习，通过使用 InfoNCE 损失函数，融入对重要节点（top nodes）偏好的先验知识，来预训练节点嵌入。

* 二项分布概率质量函数

* 相较于之前的相关工作，licap 这个工作使用了新的数据集 `GA16K` 和额外的回归度量作为基准

#### 理解数据

##### `fe15k_rel.pk`

* `fb15k_rel.pk`：这是一个知识图谱数据，表示**图谱的结构特征**，以字典的形式保存，涵盖了 `edges: tuple`， `edge_type: tensor`, `labels: tensor`, `feature: tensor`, `invalid_masks: tensor`

  具体的形式如下
  ```python
  {'edges': (tensor([ 345, 9796,  848,  ..., 5338, 4277, 1098]),
    tensor([10667,  1985,  6425,  ..., 12077, 11101, 13898])),
   'edge_types': tensor([  0,   1,   2,  ...,   9,  26, 166]),
   'labels': tensor([ 9504., 10199.,  9030.,  ..., 41222., 31642., 44935.]),
   'features': tensor([[-0.2106,  0.3095,  0.6127,  ..., -0.0039, -0.2529,  0.1002],
           [-0.2618,  0.6114, -0.2634,  ...,  0.3543, -0.0417, -0.0791],
           [ 0.1157,  0.0885, -0.1008,  ...,  0.1172,  0.3553, -0.1994],
           ...,
           [ 0.2731,  0.4277,  0.4038,  ...,  0.4685,  0.4484,  0.4826],
           [-0.2515, -0.2345,  0.9372,  ..., -0.1647,  0.3712, -0.0693],
           [ 0.2306, -0.1211, -0.1945,  ...,  0.5564,  0.0363, -0.1344]]),
   'invalid_masks': tensor([0, 0, 0,  ..., 0, 0, 0])}
  ```

  * 节点数量为 14,951，边的数量为 592,213，谓词种类为 1,345，有将近 14,105 (94.3%) 的节点是有节点特征的（64维嵌入）
  * `edges`: `tuple` ，表示源点与汇点的索引
  * `edge_types: tensor`，表示每条边的**谓词种类**
  * `labels: tensor`，表示节点重要性（node importance）的得分，通过从维基百科对收集到的真实世界重要性值（如FB15K的页面浏览量）进行对数转换来获得。（有时间去了解一下具体是怎么收集的）
  * `features：tensor  (num_nodes, 64)`，表示每个节点的词嵌入特征 ，通过 `node2vec` 算法得到节点特征
  * `invalid_masks`, 指示哪些**节点**或边需要被忽略或排除在计算之外。经过验证 `invalid_masks` 为 `1` 的节点其 `labels` 为 `0`, 我们不使用这些数据进行训练

##### `fb_lang.pk`

* `fb_lang.pk` ：这是一个仅关于节点的数据，表示**图谱节点的语义特征**，是一个二维 `np.array` 
  具体形式如下

  ```python
  array([[-0.07588089, -0.15141135, -0.13396032, ..., -0.08600746,
          -0.17194201,  0.53592861],
         [-0.02278661, -0.29997835, -0.0073817 , ...,  0.02436821,
          -0.02998137,  0.46098486],
         [-0.15221825, -0.06115236, -0.34801662, ..., -0.12346848,
          -0.14316572,  0.39701506],
         ...,
         [ 0.01512893,  0.186928  , -0.18825455, ..., -0.17741039,
          -0.02106529,  0.62954003],
         [-0.21668366, -0.01483662, -0.10437213, ...,  0.15704495,
          -0.13830011,  0.55147076],
         [-0.05817803,  0.12917031, -0.13514727, ..., -0.02458374,
          -0.02240661,  0.38673902]])
  ```

  论文中提到其通过 Transformer-XL 生成，维度为 **128**。但是实际数据上却是**768 维**？语义信息通常通过自然语言处理技术（如Transformer-XL）从节点的文本描述中提取，用于补充知识图谱的结构信息（如节点间的连接关系）。例如，在电影知识图谱（TMDB5K）中，语义信息可能包括电影的剧情简介、演员或导演的文本描述；在学术知识图谱（GA16K）中，可能是论文的标题或摘要。

  **语义信息和结构信息被作为两个独立的输入通道（例如在 RGTN 模型中），共同用于节点重要性估计任务。**



#### 理解预处训练过程

* 可能需要用到的函数

```python
np.round()
np.where()		# 注意返回的是一个 `tuple` 需要使用 [0] 进行索引
np.intersect1d(arr1, arr2, assume_unique = True)	# assume_unique = True 表示假设arr1和arr2都是唯一的，可以加速计算
np.random.choice(arr, size)

torch.sort()	# 两个返回值，分别是值和索引
```



* 我将学习到交叉验证、早停机制、划分正例样本与负例样本、分桶机制

* 设置参数与超参数，设置随机种子

* 设置各种保存路径，一般都会保存在 `checkpoints` 中

* 开始进入交叉验证大循环：
  * 进入 `load_data()` 函数开始装载与提取数据（涉及三种情况（1）只提取节点语义特征（2）提取两者特征并将它们拼接（3）提取两者特征但不将它们拼接）
    * 提取出对应的特征、掩码等数据
    * 处理节点的入度：对其进行 norm 处理（归一化因子），然后将归一化因子保存到**图的节点数据中**（`g.ndata['norm'] = norm`），并使用 `g.apply_edges()` 将每一个汇点的 `norm` 添加到对应的边上。
    * 标签的对数变换
    * 数据集划分（70% for train, 10% for val, 20% for test）
      * 五折交叉验证，==**这个操作手法需要学习一下（交叉验证）**==
    * 返回 `hg, edge_types, edge_norm, rel_num, node_feats, labels, train_idx, val_idx, test_idx`

  * 进入 `find_imp_idx()` 函数寻找重要节点（这是该论文 `LICAP` 的核心概念，用于指导**对比学习**的样本生成策略）。==**这里的操作手法需要学习一下（划分正负例样本）**==

    * 这里最后刻意将 `normal` 按照节点 50 % 采样。（从代码中看， normal 节点的数量大概是 important 节点数量的两倍）

  * 进入 `et_imp_bin_idx2node_idx()` 函数，根据节点标签的数值范围，将目标节点 `target_idx` 分桶，并记录哪些桶是有效的。其主要作用是**对重要节点进行分段索引**，可能用于后续的分析或采样。==**这里的操作手法需要学习一下（分桶操作）**==

  * 进入 `return_bin_idx2bin_coeff()` 函数**计算每个 bin（桶）的权重系数**，并存储在 `bin_coeff` 字典中。其核心逻辑是使用**二项分布概率质量函数（PMF，Probability Mass Function）**来计算不同 bin 之间的权重。

    * 理解其原理，理解 $k$ 和 $n$ 是如何选取的

    * 应用场景如下：
  
      **在重要节点识别中**，可能用于**根据 bin 的位置，为不同 bin 赋予不同的加权系数** 即衡量不同 bin 之间的**相对影响力**。
  
      **在对比学习或采样任务中**，可以作为权重分布，引导模型更关注某些 bin。
  
      通过利用二项分布的 **概率质量函数** 来衡量节点间（当然这里是 bin ）的相关性和影响力，尤其在一些 **图神经网络** 或 **基于距离的加权策略** 中得到广泛应用。
  
  * 进入 `return_imp_node_coeff()` 函数，**提取重要节点对应的系数**：根据 `imp_idx` 中的节点索引，找到每个节点对应的 bin 索引，进而提取每个节点所属 bin 的系数。**拼接系数**：将所有提取的系数拼接成一个大张量，并返回。
  
  * 处理自环问题并且更新 `edge_types` ，`rel_num` `n_edges`
  
  * 开始进行 模型 的预训练
  
    * 创建三个损失模块
  
    * 隐藏层维度为8，头为8，谓词嵌入的维度为10
  
    * 进入谓词嵌入 GAT 模型 `Predicate_GAT`（==**这个一定要掌握！！**==）
  
      * `in_dim = 64`, `hidden_dim = 8`, `out_dim = 64`, `rel_dim = 10`
  
    * 进入早停模块初始化
  
    * 进入 `return_centroids()` 函数: **计算一组节点嵌入（embeddings）的质心（centroid）**,之所以被称之为质心是因为它会分别计算每个 `bin` 中对应节点特征的均值，即为该 `bin` 的质心
  
      > **计算 bin 内所有节点的质心**（均值）。
      >
      > **存入 `bin2centroids`**，用于单独查询每个 bin 的质心。
      >
      > **拼接 `imp_bin_centroids`**，形成所有 bin 质心的矩阵。
      >
      > **跳过空 bin**，避免计算错误。
  



#### 理解 `downstream` 过程

* 代码中首先传入未处理过的数据（嵌入向量），即默认不使用经过 `pretrain` 的数据进行训练

* 接着传入经过预处理之后的嵌入向量。

  * 其中若针对 `rgtn` 进行下游任务的训练，则会使用结构和语义两种被预处理过的信息进行训练

  * 若针对其他模型进行下游任务的训练，那么代码是无法跑通的，因为它的 `features` 在使用之前并没有进行定义，疑似作者每轮都是手动去操控的（这个地方我们可以修改一下）

    添加这一行 `features = semantic_feat if args.pretrain_model == 'pregat_semantic' else struct_feat`

* 加载模型正常训练然后评估



#### 理解两个损失函数

* 自己尝试写一下，要很熟悉矩阵以及张量操作
* 太猛了，大概懂了，**先从损失函数入手**，在训练时处理损失函数需要的数据
* 思考一下 $\text{Loss}_2$ 中的系数设置从直觉上以及数学上设计的合理性
  * 数学上和哲学上都是合理的，首先 $\text{Loss} = -\log \frac{A}{A+B}$ 就是一个恒大于 0 的数，当 $A >> B$ 的时候，损失越接近 $0$ ，系数 $\beta_{m,n}$ 的出现使得物理上距离更远的两个 `bin` 在数值得出的 `B`相较于 `A` 会更小，符合损失函数所要传达的意思。

#### 理解 licap 的时间复杂度





#### 理解实验 base line 的选取设置以及具体的超参设置

有三种方法

* 无监督方法：核心是 **PageRank（PR）**和**个性化 PageRank（PPR）**算法，它们在不依赖训练标签的情况下评估节点重要性。
  * 使用 `NetworkX` 包
* 非 GNN 的监督方法：**线性回归（LR）**和**多层感知机（MLP）**是两种经典的机器学习模型。由于节点重要性估计实际上是一个回归问题，所以它们可被应用于该任务。
  * 使用 `scikit-learn` 包
* 基于图神经网络（GNN）的监督方法包含两个子集，这些方法能够同时利用图的拓扑结构和节点特征。
  - **第一类：通用 GNN 模型**：是经过修改以适用于节点重要性估计问题的通用 GNN 模型。其中，选择 GCN（图卷积网络）作为谱域 GNN 模型的代表，它通过对图的拉普拉斯矩阵进行谱分解来学习节点表示；GraphSAGE（图采样与聚合编码器）作为空域 GNN 模型的代表，它通过采样和聚合邻居节点特征来生成节点嵌入；RGCN（关系图卷积网络）作为处理关系图数据的 GNN 模型代表，专门用于处理具有多种关系类型的图数据，能够更好地捕捉关系信息。
    - 使用 `DGL` 包并设置一个 64 维的 隐藏层
  - **第二类：特定于 NIE 的 GNN 模型**：采用 GENI 和 RGTN 这两种在知识图谱节点重要性估计任务中达到当前最优性能的模型进行比较和基准测试。GENI 利用图注意力机制和邻居分数聚合来推断节点重要性；RGTN 则使用关系图变压器，在学习过程中融入节点语义信息（即节点的文本描述）来进行节点重要性估计 。
    - 使用这个[仓库](https://github.com/GRAPH-0/RGTN-NIE)中的代码实现

| 超参数                | 取值范围或具体值             | 备注                                                        |
| --------------------- | ---------------------------- | ----------------------------------------------------------- |
| 重要比率 $\gamma$     | [0.01, 0.05, 0.1, 0.2]       | 用于LICAP中对节点进行分层采样（important-ratio）            |
| 损失平衡比率 $\eta_2$ | [0.5, 1, 10, 50]             | 与 $\eta_1$（值为1）一起平衡两种对比损失（loss-eta2）       |
| InfoNCE温度参数 $T$   | 0.05                         | 用于计算对比损失                                            |
| PreGAT或GAT隐藏层维度 | 8                            | 设置模型隐藏层维度                                          |
| PreGAT或GAT头数       | 8                            | 采用多头注意力机制的头数                                    |
| PreGAT谓词维度        | 10                           | 设置谓词嵌入的维度                                          |
| 学习率                | [0.0005, 0.001, 0.005, 0.01] | 对LICAP增强的NIE方法和原始NIE方法均进行搜索（weight-decay） |



| 数据集处理及评估相关设置 | 详情                                                         |
| ------------------------ | ------------------------------------------------------------ |
| 结构特征提取方法         | 使用Node2Vec从输入图中提取每个节点的结构特征                 |
| 语义特征获取方式         | FB15K和TMDB5K语义特征从RGTN GitHub库克隆；GA16K语义特征通过运行Transformer-XL获取 |
| 预训练结构特征维度       | 64                                                           |
| 预训练语义特征维度       | 128（实际上代码中给出的是768，好奇怪）                       |
| 分组箱长度               | FB15K：1.0；TMDB5K：0.5；GA16K：1.0                          |
| 评估方式                 | 五折交叉验证，报告回归指标和排序指标                         |



#### 理解实验的评估指标

在节点重要性估计的评估中，需要同时考虑重要性得分预测和重要性得分排序。因此，我们同时使用回归指标和排序指标，其正式定义如下。

-  **回归指标**：由于节点重要性估计问题的真实标签是非负实数，因此使用回归指标进行评估是很自然的。我们使用两个常用的回归指标，即均方根误差（RMSE）和平均绝对误差（MedianAE），来量化预测的重要性得分与相应真实标签的接近程度。值越低表示性能越好。    
  - RMSE衡量预测得分与真实得分之间的平均距离。假设有$n$个样本，用$s^{*}$和$s$分别表示预测得分和实际得分，其正式公式为：$RMSE =\sqrt{\frac{\sum_{i = 1}^{n}(s_{i}^{*} - s_{i})^{2}}{n}}$   
  - MedianAE衡量预测得分与真实得分之间绝对差异的中位数。与RMSE相比，它对异常值更具鲁棒性，因为它关注的是中位数预测误差，而不是所有样本的总体误差。MedianAE的正式定义如下：$MedianAE = median(|s_{1}^{*} - s_{1}|, \cdots, |s_{n}^{*} - s_{n}|)$ 
-  **排序指标**：为了从另一个角度评估性能，我们遵循文献[4]，额外采用两个排序指标：归一化折损累计增益（NDCG）和斯皮尔曼等级相关系数（SPEARMAN）。值越高表示性能越好。    
  - NDCG衡量排序列表的质量，它是折损累计增益（DCG）的扩展。DCG同时考虑了项目的相关性及其在排序中的位置。在根据预测得分$s^{*}$对具有真实得分$s$的项目列表进行排序后，用$s_{r}$表示第$r$个项目的真实得分。位置$k$处的DCG（DCG@k）[4]可以定义为：$DCG @ k=\sum_{r = 1}^{k} \frac{s_{r}}{\log _{2}(r + 1)}$    
  -  NDCG通过将DCG除以理想DCG（IDCG）进一步进行归一化。位置$k$处的IDCG（IDCG@k）是前$k$个位置中可能的最大DCG。根据这些定义，位置$k$处的NDCG（NDCG@k）可以通过以下公式计算：$NDCG @ k=\frac{DCG @ k}{IDCG@ k}$   
  -  SPEARMAN是衡量预测得分$s^{*}$与真实得分$s$之间等级相关系数的指标。在将得分$s^{*}$和$s$分别转换为相应的等级$r^{*}$和$r$后，我们将$r^{*}$和$r$的平均值定义为$\bar{r}^{*}$和$\bar{r}$。SPEARMAN可以表示为：$SPEARMAN =\frac{\sum_{r}(r^{*}-\overline{r^{*}})(r-\overline{r})}{\sqrt{\sum_{r}(r^{*}-r^{*})^{2}} \sqrt{\sum_{r}(r-\overline{r})^{2}}}$    
  -  OVER是预测的重要节点与真实重要节点之间的重叠率。用$S_{top - k }^{*}$表示预测的前$k$个重要节点的集合，$S_{top - k}$表示真实的前$k$个重要节点的集合。$|·|$表示集合的基数。OVER@k的计算公式为：$OVER @ k=\frac{|S_{top - k}^{*} \cap S_{top - k}|}{k}$ 





#### 理解实验的具体内容

**研究问题设定**  
提出7个研究问题，涵盖LICAP对提升最先进NIE方法性能的作用、关键组件的有效性、预训练不同特征的效果、超参数影响、对高重要性节点的感知能力以及对其他NIE方法性能的提升效果等方面。这些问题为后续实验和分析提供了明确方向。

**知识图谱上的节点重要性估计**  
对比LICAP与多种基线方法的性能。结果显示，LICAP与RGTN结合在所有指标上均优于基线方法。  

- 无监督方法（如PR和PPR）由于无法利用标签进行监督，性能较差；  
- GNN-基于方法能够同时利用节点特征和图结构，表现更优。  
在基线方法中，RGTN表现突出，但LICAP能显著提升RGTN在回归指标上的性能，充分展现了LICAP的优势。

**消融研究：LICAP对比损失的影响**  
通过构建基于RGTN的LICAP变体进行对比实验，验证了两个对比损失的有效性。  
实验结果表明，同时包含 $L_1$ 和 $L_2$ 损失的LICAP - $L_1 + L_2$ 表现最佳。  

- 进一步分析发现，$L_1$ 单独作用时效果通常优于 $L_2$，这是因为 $L_2$ 单独使用时过于关注细节，使得学习过程困难。  
- 此外，随机采样的LICAP - r.d.方法效果较差，这证明了顶部节点优先采样策略的有效性，突出了利用先验知识对提升NIE方法性能的重要性。

**消融研究：谓词感知GAT的影响**  
比较LICAP - PreGAT、LICAP - GAT和原始RGTN的性能。  
研究发现LICAP - PreGAT性能最优，尤其在具有更多谓词的FB15K数据集上优势更为明显。这表明谓词感知机制能够有效区分不同的谓词，捕捉其中有意义的信息，从而提升模型性能。如果在谓词数量较少的知识图上，则 PreGAT 将近退化为 GAT，效果可能并不好（**但事实上，我发现即便在谓词数量更多的 fb15k 数据集上，PreGAT的提升也并不明显...**）

**预训练不同输入通道**  
探究LICAP对不同输入通道（结构特征、语义特征、两者结合）的预训练效果。  

RGTN明确地将**结构特征**和**语义特征**视为两个单独的通道。

研究结果显示，单独预训练结构或语义特征通常比同时预训练两者效果好。这可能是因为RGTN的两个输入通道需要一定的差异性，以更好地利用多源特征。  

这表明按照相同的 LICAP 架构同时预训练结构和语义嵌入，可能会损害模型的学习能力。原因可能在于，RGTN 的两个输入通道需要在一定程度上具有差异性，**这样才有利于模型充分利用多源特征**。而使用相同的 LICAP 架构对两者进行预训练，**可能导致两个通道的嵌入特征过于相似，无法有效发挥多源特征的优势**，进而影响模型学习效果。

尽管如此，与原始方法相比，三种变体都能提升性能，说明LICAP在不同输入通道设置下均能发挥积极作用。

**超参数分析**  
分析损失平衡比率 $\eta_{2}/\eta_{1}$ 和 重要比率 $\gamma$ 对模型性能的影响。  
研究发现，排序指标 SPEARMAN 比回归指标 RMSE 对超参数更鲁棒。  

- **排序对预测异常值相对不敏感**，而RMSE作为回归指标受异常值影响较大。  
- 此外，不同数据集的最佳 $\gamma$ 值不同，**这是由于各数据集在图结构和知识图谱主题等方面存在差异。**

**可视化LICAP预训练嵌入**  
通过可视化LICAP预训练前后的节点嵌入，**直观地发现预训练后高重要性节点在空间中更聚集。这一现象表明LICAP能更好地感知高重要性节点，实现了研究的预期目标，进一步证明了LICAP的有效性。**

**LICAP应用于多种方法**  
将LICAP与更多NIE方法结合进行实验。结果显示，**LICAP能提升MLP的性能，但对LR的效果不稳定**，可能是因为LR的线性假设与知识图谱上的NIE问题兼容性不佳，而MLP的非线性激活函数能更好地与LICAP协作。  
对于GNN-基于的方法（如GCN、RGCN、GraphSAGE和GENI），LICAP也有不同程度的性能提升。  （==个人感觉这里说得太牵强了，实验效果其实并没有那么好==）

- 其中，RGCN和GENI与LICAP结合后在不同数据集上的表现相对更优，**这是因为LICAP考虑了关系信息，与同样关注关系的RGCN和GENI更适配。**  
- 此外，LICAP对非GNN方法的性能提升幅度相对更大，但结合LICAP的GNN方法凭借GNN骨干网络在图数据处理上的优势，最终仍取得更好的结果。



#### 作者对未来工作的展望

对于未来的工作

* 将 LICAP 扩展到动态图上的 NIE 问题是一个有趣的研究方向。
* 此外，研究标签分布如何影响 LICAP 和 NIE 方法的性能也很有价值。
* 另一个有前景的方向是将 LICAP 的思想迁移到其他与图相关的回归或排名问题中。



#### 实验的复现

* 感觉是数据造假（你妈的论文中的文字说明的超参数和github中给的脚本命令设置的超参数都不对应我日你的！）

* 代码中的 `args.num-out-heads` 怎么感觉一点用都没有啊？最终的输出 logits 不是通过 RGTN 输出的，而是对 RGTN 隐藏层的最后一层输出拿来进行交叉注意力处理得到的输出 logits，所以很明显，这个 `args.num-out-heads = 1` 其实是没用的，代码中其他地方也没看见这个的用法。

* 难以置信，怎么跑出来的效果这么差！！！

* 针对 FB15K，我们这样进行超参数设置 $\gamma = 0.1$， $\eta_2 / \eta_1=2(\eta_1=1, \eta_2 =2)$

* 发现应该是调参的问题，调参的效果还是很显著的

* 最终最终，研究了一下 `RGTN` 中的参数设置，打算按照这个再进行一次训练。可以与 `RGTN` 的论文进行对比，并看看 `RGTN + LICAP` 是否能被改进。（反正之前默认的参数都是没有一点吊效果的，很恼火很郁闷），如果这次还是看不到任何提升，那么我有理由怀疑 `LICAP` 这篇论文的数据有点水分！而且比较奇怪的一点是，论文中给的超参数设置和项目中训练脚本给的超参数数据对不上！以下是 `RGTN` 这篇文章中附录中给出的超参数情况

  > 在 LICAP 中针对 RGTN 的参数设置
  >
  > `self.lambda_ = 0.7 self.alpha = 0.5`   代码中将两者搞反了!
  >
  > `self.num_hidden = 64`
  >
  > 
  >
  > 注意：这里的 `self.num_layers` 是隐藏层的个数（**事实上，表示的就是堆叠了几层的 RGTN**），默认设置为 3，隐藏层每一层的 `self.num_heads` 头默认设置为4, 输出层 `self.num_out_heeads `的头默认设置为1 
  >
  > 那么 `heads = ([self.num_head] * self.num_layers) + [self.num_out_heads] = [4, 4, 4, 1]` 当然这是默认设置。
  >
  > `self.num_heads = 8`
  >
  > `self.num_layers = 2`

##### FB15K

* $\gamma =0.1, \eta_2 / \eta_1 =1$

| Methods    | RMSE ↓               | MedianAE ↓           | NDCG@100 ↑           | SPEARMAN ↑           | OVER@100 ↑           |
| ---------- | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |
| PR         |                      |                      |                      |                      |                      |
| PPR        |                      |                      |                      |                      |                      |
| LR         |                      |                      |                      |                      |                      |
| MLP        |                      |                      |                      |                      |                      |
| GCN        | 1.2111±0.0287        | 0.7070±0.0137        | 0.9350±0.0108        | 0.6321±0.0283        | 0.3700±0.0544        |
| RGCN       | 2.0204±1.1747        | 0.6622±0.0171        | 0.9055±0.0113        | 0.6889±0.0200        | 0.3120±0.0354        |
| GraphSAGE  | 1.0828±0.0194        | 0.6462±0.0124        | 0.9049±0.0084        | 0.6832±0.0095        | 0.2700±0.0210        |
| GENI       | 0.9829±0.0206        | <u>0.5778±0.0145</u> | 0.9079±0.0078        | 0.7396±0.0101        | 0.3240±0.0356        |
| RGTN       | **0.8979±0.0305**    | **0.5282±0.0206**    | <u>0.9420±0.0123</u> | **0.7879±0.0141**    | <u>0.4060±0.0771</u> |
| RGTN+LICAP | <u>0.9646±0.0463</u> | 0.5973±0.0459        | **0.9421±0.0077**    | <u>0.7832±0.0120</u> | **0.4100±0.0510**    |



* 这张表格对 GENI 与 RGTN + LICAP 进行了调参，但是 $\eta_2$ 仍旧为 1

* 发现不对劲了，因为貌似参数没有保持一致（我们现在考虑测试 RGTN 与 RGTN + LICAP，超参数使用 RGTN 的那篇论文进行实现，这样的话， **pretrain的超参数也要对应着改动**）

  * ```shell
    # rgtn 论文中的 rgtn 模型参数
    python two_branch/two_branch_train.py --dataset FB15k_rel_two --data_path datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 \
    --save-path gtran-list-3-100_checkpoint.pt --gpu 0
    
    ```

  * ```shell
    # pretrain 中对应的修改参数
    # pretrain_pregat_struct_FB15k.sh
    
    # 训练结构信息
    python pretrain/pregat_pretrain_struct.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --num-hidden 8 --num-heads 8
    
    # 训练语义信息
    python pretrain/pregat_pretrain_struct.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --num-hidden 8 --num-heads 8
    ```
    
  * ```shell
    # down_stream 中的 shell 文件
    # downstream_struct_FB15k.sh
    
    # 仅 rgtn
    python downstream/rgtn_downstream.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 --pretrain-model 'null'
    
    # rgtn + licap
    python downstream/rgtn_downstream.py --dataset FB15k_rel_two --data_path ./datasets/fb15k_rel.pk --loss-lambda 0.8 \
    --num-hidden 8 --num-heads 8 --spm --residual --norm --loss-alpha 0.3 --list-num 100 --pretrain-model 'pregat_struct'
    ```
  
    

| Methods    | RMSE ↓               | MedianAE ↓            | NDCG@100 ↑           | SPEARMAN ↑           | OVER@100 ↑           |
| ---------- | -------------------- | --------------------- | -------------------- | -------------------- | -------------------- |
| PR         |                      |                       |                      |                      |                      |
| PPR        |                      |                       |                      |                      |                      |
| LR         |                      |                       |                      |                      |                      |
| MLP        |                      |                       |                      |                      |                      |
| GCN        | 1.2111±0.0287        | 0.7070±0.0137         | 0.9350±0.0108        | 0.6321±0.0283        | 0.3700±0.0544        |
| RGCN       | 2.0204±1.1747        | 0.6622±0.0171         | 0.9055±0.0113        | 0.6889±0.0200        | 0.3120±0.0354        |
| GraphSAGE  | 1.0828±0.0194        | 0.6462±0.0124         | 0.9049±0.0084        | 0.6832±0.0095        | 0.2700±0.0210        |
| GENI       | 1.2506±0.4130        | 0.7107±0.2596（异常） | 0.9110±0.0261        | 0.7167±0.0752        | 0.3340±0.0855        |
| RGTN       | **0.8565±0.0176**    | **0.4896±0.0120**     | **0.9506±0.0102**    | **0.8115±0.0058**    | **0.4440±0.0634**    |
| RGTN+LICAP | <u>0.8967±0.0427</u> | <u>0.5264±0.0391</u>  | <u>0.9429±0.0092</u> | <u>0.7915±0.0255</u> | <u>0.3920±0.0435</u> |

* 这组数据主要是针对 RGTN 与 RGTN + LICAP 这一模型。超参数选取的是让 RGTN 效果最好的那一组（参考的是 RGTN 的代码）。结果发现和 RGTN 那篇代码相比，NDCG@100 与 NDCG@100 这两项指标差了1个百分点左右，而 OVER@100 则差了4个百分点。

  但是在此基础上，添加了 LICAP 模块。有几点让我比较郁闷

  （1）发现每项指标都被秒杀了

  （2）论文中给的数据是 添加了 RGTN 的效果更好，但是它们并没有用到 RGTN 那篇论文的 SOTA。这是为什么？是因为如果使用 SOTA 的配置反而跑的不好？于是用了一些能降低 RGTN 性能的超参数训练一个比较差的 RGTN ，然后让 LICAP 发挥作用？

  （3）有点烦躁了



$\eta_2 = 2.0$

| RGTN+LICAP | 0.9053±0.0193 | 0.5323±0.0194 | 0.9397±0.0047 | 0.7907±0.0151 | 0.3900±0.0395 |
| ---------- | ------------- | ------------- | ------------- | ------------- | ------------- |





##### **TMDB5K**

| Methods    | RMSE ↓        | MedianAE ↓    | NDCG@100 ↑    | SPEARMAN ↑    | OVER@100 ↑    |
| ---------- | ------------- | ------------- | ------------- | ------------- | ------------- |
| PR         |               |               |               |               |               |
| PPR        |               |               |               |               |               |
| LR         |               |               |               |               |               |
| MLP        |               |               |               |               |               |
| GCN        | 0.7946±0.0316 | 0.5370±0.0136 | 0.8765±0.0175 | 0.7677±0.0139 | 0.4820±0.0248 |
| RGCN       | 1.1699±0.7719 | 0.7592±0.4501 | 0.8487±0.0582 | 0.6648±0.1562 | 0.4280±0.0964 |
| GraphSAGE  | 0.7399±0.0147 | 0.4815±0.0198 | 0.9003±0.0017 | 0.7587±0.0197 | 0.5320±0.0407 |
| GENI       | 0.7194±0.0137 | 0.4809±0.0431 | 0.9130±0.0117 | 0.7860±0.0157 | 0.5880±0.0240 |
| RGTN       | 0.7593±0.0486 | 0.4917±0.0154 | 0.9058±0.0089 | 0.7968±0.0058 | 0.5440±0.0196 |
| RGTN+LICAP | 0.7478±0.0512 | 0.4917±0.0390 | 0.9088±0.0145 | 0.7953±0.0110 | 0.5820±0.0500 |





| Methods    | RMSE ↓               | MedianAE ↓           | NDCG@100 ↑           | SPEARMAN ↑           | OVER@100 ↑           |
| ---------- | -------------------- | -------------------- | -------------------- | -------------------- | -------------------- |
| PR         |                      |                      |                      |                      |                      |
| PPR        |                      |                      |                      |                      |                      |
| LR         |                      |                      |                      |                      |                      |
| MLP        |                      |                      |                      |                      |                      |
| GCN        | 0.7946±0.0316        | 0.5370±0.0136        | 0.8765±0.0175        | 0.7677±0.0139        | 0.4820±0.0248        |
| RGCN       | 1.1699±0.7719        | 0.7592±0.4501        | 0.8487±0.0582        | 0.6648±0.1562        | 0.4280±0.0964        |
| GraphSAGE  | 0.7399±0.0147        | 0.4815±0.0198        | 0.9003±0.0017        | 0.7587±0.0197        | 0.5320±0.0407        |
| GENI       | **0.7194±0.0137**    | <u>0.4809±0.0431</u> | **0.9130±0.0117**    | <u>0.7860±0.0157</u> | **0.5880±0.0240**    |
| RGTN       | <u>0.7289±0.0664</u> | 0.4892±0.0738        | <u>0.9056±0.0074</u> | **0.7902±0.0115**    | <u>0.5460±0.0427</u> |
| RGTN+LICAP | 0.7329±0.0135        | **0.4697±0.0215**    | 0.8996±0.0130        | 0.7850±0.0160        | 0.5420±0.0475        |



#### **一些工具或者技巧**

* **针对真实世界KG的标签（如FB15K的页面浏览量和GA16K的引用计数），作者对其进行了对数转换（猜测是数据太大了，后面的损失函数与生成嵌入要直接用到它，不能使用过大的数据？？）==这个要深刻理解==**

* **在计算 $L_1$ 损失的时候，代码中将 `embed_important` 与 `embed_normal`  （分别对应了论文中公式（1）的 $h_i$ 与 $h_j$）进行了归一化操作，即** 

  ```python
  embed_important = F.normalize(embed_important)
  embed_normal = F.normalize(embed_normal)
  ```

  **这是为了防止后续在进行 `torch.exp()`  操作的同时指数爆炸，经过实验直接变成 `nan` 了（这是因为分母或分子为 `inf` 导致结果为 `nan`）**


* **设置随机种子**

* **简单早停模块**

* **梯度裁剪**

  * **防止梯度爆炸（在反向传播时使用！！），用于提高训练稳定性，常用于深度网**

    * **需要在 `loss.backward()` 之后、`optimizer.step()` 之前执行，而不是在 `forward` 里执行。**

  * **`torch.nn.utils.clip_grad_norm_(parameters = model.parameters(), max_norm = 10, norm_type = 2)`**

    > **梯度裁剪的缩放公式如下：**
    >
    > **$g_i = g_i \times \frac{\text{max\_norm}}{\|\mathbf{g}\|_2}$**
    >
    > **其中：**
    >
    > * **$g_i$ 是梯度的某个分量。**
    >   
    > * **$\|\mathbf{g}\|_2$ 是所有梯度的 L2 范数（即欧几里得范数）：**
    >   
    >   **$\|\mathbf{g}\|_2 = \sqrt{\sum_i g_i^2}$**
    >
    > * **如果 $\|\mathbf{g}\|_2 \leq \text{max\_norm}$，则不进行缩放。**
    >
    > * **如果 $\|\mathbf{g}\|_2 > \text{max\_norm}$，则所有梯度按照这个比例缩放，使得梯度范数不会超过 `max_norm`。**



### **RGTN**

* **==这个图的 `transform` 也只是利用了局部的信息，并没有像 `LLM` 那样利用全局的信息，针对这一点感觉可以进行创新做一下实验？==**

  * **破案了，是我学识浅薄了，之前讨论的是自注意力，所以只需要关注自己就行了。交叉注意力部分才是关注~~全局信息~~（==还是自己的信息，只不过是自己的结构和语义信息！！！==）**

* **我是不是应该使用网格搜索来找到最佳模型？**

* **表征学习**

  **其实就是学习低维的、嵌入的向量**

* **究竟什么是节点重要性？一言以蔽之**

  **==节点重要性估计（NIE）是一项根据图的结构和属性信息推断图中节点重要性或受欢迎程度的任务。==**

* **度中心性、介数中心性与PageRank（通过计算与节点相连的边的数量和质量来大致估计节点的重要性。）然而，这些方法不能直接用于评估复杂知识图谱中节点的重要性，因为它们只考虑了图的拓扑结构，而忽略了繁杂的节点和边中所包含的丰富结构和语义信息。**

* **GENI  和 MULTIIMPORT。GENI 将通过 node2vec [9] 获得的节点特征映射为重要性值，并以图注意力网络的方式自适应地聚合来自不同边类型的这些值。得益于监督学习框架和图注意力机制，GENI 比手工设计的方法表现更优。在 GENI 的基础上，MULTIIMPORT 进一步探索如何利用外部输入的重要性信号来学习潜在的节点重要性。尽管它们在准确估计节点重要性方面取得了成功，但它们忽略了可能与节点重要性相关的节点描述。**

#### **预备知识点**

* **FFN：** 

  **FFN（Feed Forward Network），即前馈神经网络，是一种由全连接层（Dense Layer）和非线性激活函数组成的简单神经网络模块。它在Transformer架构（如论文中的RGTN）中扮演重要角色，通常用于对注意力机制输出的特征进行进一步变换和增强。**

  * **一般需要满足以下几个条件**
    * **扩展维度，非线性激活函数，恢复维度，正则化（可选），添加残差连接（可选），当然后面还能失活 `Dropout`**

  * **$\text{FFN}(x) = W_2 \cdot \text{ReLU}(W_1 \cdot x + b_1) + b_2$**

  * **在论文中 FFN 的输入是经过注意力聚合以及残差相加处理之后的数据**

  * **其作用是：**
    1. **特征增强：对注意力层输出的节点特征进行非线性变换，捕捉更复杂的模式（之前的操作并没有进行非线性变换）。**
    
    2. **维度恢复：虽然中间层会扩展维度，但最终输出维度与输入一致，确保后续层的兼容性。**
    
       **（1）先扩展维度，在高维空间中进行非线性变换，让模型学习更丰富的特征表示。（类似“放大镜”，先放大细节再聚焦关键信息）**
    
       **（2）再压缩回原维度：避免维度膨胀导致计算量过大，同时保留最重要的特征。**
    
       **（3）深化局部特征（单个词的语义表示），即它在处理的时候是单独处理每个词的嵌入特征，下面是与自注意力阶段的对比，自注意力阶段更关注全局关系，FFN 特征更关注局部特征**
    
       > 1. **自注意力阶段：**
       >    - **决定哪些词需要重点关注（例如“苹果”与“吃”的关系更强）。**
       >    - **输出：一组经过全局调制的特征向量（每个词包含上下文信息）。**
       > 2. **FFN 阶段：**
       >    - **对每个词向量单独处理，深化其语义表示。**
       >    - **例如：将“苹果”从“一种水果”进一步细化为“可食用的甜味水果”。**
    
    3. **与残差连接配合：FFN的输出会与输入相加（公式6），缓解深层网络的梯度消失问题。**

* **残差连接**

* **层归一化与批归一化**

  **和我想得一样，看笔记**

* **协同注意力模块**

* **Learning-to-Rank（LTR）损失：核心思想是：不仅要预测准确的节点重要性值，还要确保节点之间的相对排序关系与真实情况一致。**

#### **本文贡献**

- **本文提出了一种基于表示学习的节点重要性估计框架，该框架能够全面利用各类节点和关系中蕴含的丰富结构和语义信息。**
- **设计了一种关系图变换器，利用可学习的谓词表示来传播节点嵌入，从而区分谓词语义对节点重要性传播的影响。**
- **引入学习排序损失来指导表示学习过程，以获得具有相对位置感知的节点表示，进而提高节点重要性估计的整体质量。**

#### **这项工作的应用前景**

**节点重要性估计有许多潜在的应用。以电影知识图谱为例，我们可以预测新添加的电影实体的重要性，以帮助优化资源分配。我们还可以改变一部电影与不同演员之间的联系，获取各种重要性值，为电影选角提供参考。**

**ps：以前都没有想到过有这些应用场景**

#### **理解文中的公式**

**公式（1）究竟是标量还是向量！！！**

* **理论上应该是标量，但是实际上根据作者给的公式明显就是一个向量。破案了就是标量，边的每个头的特征维度为1** 

**公式（3）**

* **其中的 $W^l_o$ 是什么意思**

  > **在论文的公式（3）中，$W^l_o$ 是第 $l$ 层 Relational Graph Transformer 中的一个可学习的线性变换矩阵，其作用是对多头注意力（Multi-Head Attention）输出的拼接结果进行降维和整合。以下是详细解析：**
  >
  > **公式（3）的上下文**
  > $$
  > M_v^l = W_o^l \Bigg\|_{k=1}^H \left( \sum_{u \in \mathcal{N}_v} a_{(u,v)}^{k,l} \cdot W_V^{k,l} h_u \right)
  > $$
  >
  > **其中：**
  >
  > - **$M_v^l$ 是节点 $v$ 在第 $l$ 层聚合后的消息。**
  > - **$\|$ 表示向量拼接（concatenation）。**
  > - **$H$ 是注意力头的数量。**
  > - **$a_{(u,v)}^{k,l}$ 是第 $k$ 个注意力头计算的权重（由公式1-2得到）。**
  > - **$W_V^{k,l}$ 是第 $k$ 个头对应的值（Value）变换矩阵。**
  > - **$h_u$ 是邻居节点 $u$ 的表示。**
  >
  > **$W^l_o$ 的具体作用**
  >
  > 1. **多头注意力的输出整合：**
  >    - **每个注意力头会生成一个维度为 $d$ 的向量（$d$ 是隐层维度），拼接后得到 $H \times d$ 维的向量。**
  >    - ~~**$W_o^l \in \mathbb{R}^{d \times (H \cdot d)}$ 将拼接后的高维向量投影回 $d$ 维，保持各层维度一致。**~~ （是重新映射到 `out` 维度） 
  >
  > 2. **可学习的参数：**
  >    - **它是与层数相关的矩阵（上标 $l$ 表示第 $l$ 层），允许不同层学习不同的整合模式。**
  >    - **类似于标准Transformer中的 $W_O$ 矩阵（见原始Transformer论文[1]），但这里适配了图结构的多关系特性。**
  >
  > 3. **与经典GNN的对比：**
  >    - **在GAT中，多头注意力的输出直接拼接或平均，而本文通过 $W_o^l$ 显式学习整合方式，增强了表达能力。**
  >
  > **设计动机**
  >
  > - **降维需求：避免多头注意力拼接后维度膨胀（$H \cdot d$），维持模型效率。**
  > - **关系感知：在知识图谱中，不同层的节点表示可能需要不同的信息聚合策略，$W_o^l$ 通过层特异性参数实现这一点。**
  >
  > **与其他公式的关联**
  >
  > - **后续处理：公式（4）-（6）中，$M_v^l$ 会经过残差连接、FFN和归一化，生成下一层的节点表示 $h_v^{l+1}$。**
  > - **与RGCN/GAT的区别：RGCN为不同关系类型设计独立矩阵，而本文的 $W_o^l$ 统一处理所有关系，但通过注意力权重 $a_{(u,v)}^{k,l}$ 隐含关系差异。**
  >
  > **总结**
  >
  > **$W_o^l$ 是关系图Transformer的核心组件之一，负责将多头注意力的异构信息压缩为统一的节点表示，同时保留语义和结构特征。其设计体现了对知识图谱中复杂关系的建模能力，也是模型性能优越的关键之一。**

**公式（7）~公式（10）**

**见下文的 理解协同注意力模块（即 cross attention）**



**公式（11）~公式（13）**

**此部分是论文中提出的重要性预测模块（Importance Prediction Module）的核心部分，用于将节点的结构和语义表示融合并映射为最终的重要性值。以下是对这些公式的详细说明及补充细节：**

> **以下是经过完整LaTeX公式渲染后的内容：**
>
> ---
>
> **公式（11）~（13）是论文中提出的重要性预测模块（Importance Prediction Module）的核心部分，用于将节点的结构和语义表示融合并映射为最终的重要性值。以下是对这些公式的详细说明及补充细节：**
>
> **公式（11）：注意力权重计算**
> $$
> \gamma^{(s)} = \frac{\exp(h_v^{(s)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}, \quad \gamma^{(c)} = \frac{\exp(h_v^{(c)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}
> $$
>
> **说明：**
> 1. **输入：**
>    - **$h_v^{(s)}$：节点 $v$ 的结构表示（来自结构编码器）。**
>    - **$h_v^{(c)}$：节点 $v$ 的语义表示（来自语义编码器）。**
>    - **$\lambda$：可训练的注意力向量，用于将节点表示映射为标量值。**
>
> 2. **操作：**
>    - **通过点积 $h_v^{(s)} \lambda^T$ 和 $h_v^{(c)} \lambda^T$，将结构和语义表示分别映射为标量。**
>    - **使用 softmax 函数计算两者的注意力权重 $\gamma^{(s)}$ 和 $\gamma^{(c)}$，确保权重之和为 1。**
>
> **补充细节：**
> - **注意力机制的作用：动态调整结构和语义信息对最终重要性预测的贡献。例如，在电影知识图谱中，某些节点（如知名导演）的结构关系可能更重要，而其他节点（如剧情新颖的电影）的语义描述可能更关键。**
> - **可训练参数：$\lambda$ 是模型通过反向传播学习的参数，其维度与节点表示维度一致（如 64 维）。**
>
> **公式（12）：重要性值投影**
> $$
> s_v^{(s)} = W_s^1 h_v^{(s)}, \quad s_v^{(c)} = W_s^2 h_v^{(c)}
> $$
>
> **说明：**
> 1. **输入：**
>    - **$h_v^{(s)}$ 和 $h_v^{(c)}$ 同上。**
>    - **$W_s^1$ 和 $W_s^2$：可训练的投影矩阵，将节点表示映射为 1 维重要性值。**
>
> 2. **操作：**
>    - **分别将结构和语义表示通过线性变换（矩阵乘法）映射为标量重要性值 $s_v^{(s)}$ 和 $s_v^{(c)}$。**
>
> **补充细节：**
> - **投影矩阵的维度：假设 $h_v^{(s)}$ 和 $h_v^{(c)}$ 的维度为 $d$，则 $W_s^1$ 和 $W_s^2$ 的维度为 $1 \times d$。**
> - **分离投影的目的：允许结构和语义信息独立地贡献重要性值，避免两者在融合前相互干扰。**
>
> **公式（13）：重要性值融合**
> $$
> s_v^* = \text{LeakyReLU}(\gamma^{(s)} s_v^{(s)} + \gamma^{(c)} s_v^{(c)})
> $$
>
> **说明：**
> 1. **输入：**
>    - **$\gamma^{(s)}$ 和 $\gamma^{(c)}$：来自公式（11）的注意力权重。**
>    - **$s_v^{(s)}$ 和 $s_v^{(c)}$：来自公式（12）的投影重要性值。**
>
> 2. **操作：**
>    - **使用注意力权重对 $s_v^{(s)}$ 和 $s_v^{(c)}$ 进行加权求和。**
>    - **通过 LeakyReLU 激活函数引入非线性，确保输出为非负值（重要性值通常为非负）。**
>
> **补充细节：**
> - **LeakyReLU 的作用：避免梯度消失问题，同时允许小幅度的负值输入（虽然重要性值通常为正，但激活函数的设计可能为模型提供额外的灵活性）。**
> - **加权求和的意义：动态结合结构和语义信息。例如，若 $\gamma^{(s)}$ 接近 1，则结构信息主导重要性预测；反之则语义信息主导。**
>
> **整体流程总结**
>
> 1. **表示分离：通过结构和语义编码器分别生成节点表示 $h_v^{(s)}$ 和 $h_v^{(c)}$。**
> 2. **注意力权重计算：动态学习两种表示的贡献比例（公式 11）。**
> 3. **重要性值投影：将两种表示独立映射为重要性值（公式 12）。**
> 4. **融合与激活：加权融合并应用非线性激活，输出最终重要性值 $s_v^*$（公式 13）。**
>
> **补充重要细节**
>
> 1. **损失函数的配合：**
>    - **公式（13）的输出 $s_v^*$ 会与真实重要性值 $s_v$ 通过 RMSE 损失（公式 16）和 LTR 损失（公式 15）联合优化，确保预测值既准确又保持正确的排名关系。**
>    
> 2. **模块设计的动机：**
>    - **知识图谱中节点的重要性可能依赖于多种因素（如链接数量、文本描述质量等），因此需要灵活融合多源信息。**
>    - **分离结构和语义编码器避免了特征混淆，而注意力机制提供了自适应的融合能力。**
>
> 3. **实际应用示例：**
>    - **在电影知识图谱中，若某电影的导演很知名（结构信息重要），则 $\gamma^{(s)}$ 可能较高；若剧情描述独特（语义信息重要），则 $\gamma^{(c)}$ 可能较高。**
>
> **通过这一模块，RGTN 能够充分利用知识图谱的多模态信息，实现更精准的节点重要性估计。**



#### **理解协同注意力模块（即 cross attention）**

**==我们发现，代码中的结构信息对其中一个点也只是关注了图中的很局部的信息（邻居节点）==**

**节点结构信息和语义信息对最终节点重要性的贡献在不同的场景中可能不同。例如，在电影知识图中，如果情节设计流行，即使主要创作者不那么出名，一些电影也可能会流行起来。相反的情况是，有几个大师参与，即使情节看起来不受欢迎，一些电影也可能会受到关注。因此，自适应地融合结构和语义信息中的节点表示将有利于节点重要性估计的性能。**

**即这一部分应该是要思考利用这两个特征达到 $1 + 1 > 2$ 的效果而非 $1 + 1 < 2$**

* **文章使用相互交流来增强它们**

* **公式（7）为什么又要用 $W_F$ 进行依次线性变换？明明结构表示 $h^{(s)}_v$ 和语义表示 $h^{(c)}_v$ 已经维度一致，为什么还要乘一个线性变换矩阵 $W_F$？不能直接拿来做 co-attention 吗？**

  * 1. **表示空间对齐**

       **虽然 $h^{(s)}_v$ 和 $h^{(c)}_v$ 维度一致，比如都是 64 维，但：**

       - **它们来自不同的 encoder（结构 & 语义）；**
       - **所在的语义空间分布差异很大。**
       - **它们不在同一个空间，就是不可比的**
    
       **📌 举个比喻：同样是 64 维，但一个是图结构抽象出来的向量，一个是 Transformer-XL 编出来的语言语义特征，这两个向量的“含义”完全不同，就像“画风不同”的两组图片。**
    
       **🔧 所以需要一个统一的投影（$W_F$），将它们映射到一个“对齐后”的共同空间，这样 attention 才有“可比性”。即将不同来源的信息映射到同一个表示空间，以便它们可以在该空间中相互比较和交互，若不加以处理那么即使它们的维度相同（例如都是 64 维），它们表达的“内容”在数学空间中是完全不同的，因此不能直接进行比较或交互。**
    
       **比如，在多模态领域中，将不同模态的向量（如 ResNet 图像特征和 BERT 文本特征）投影到同一空间；通常 ==共享映射矩阵== 是一种防止过拟合且强制对齐的手段。$W_F$ 的共享意味着它会学到一种“折中”的映射方式，让来自结构与语义的表示在同一空间中“尽可能协调”；从训练角度来看，损失函数会驱动模型去调节 $W_F$，使得结构和语义的融合表示对下游任务（如节点重要性估计）是有效的。**
    
       
    
       **很多网络都有这样的操作：==先各自提取，再统一映射对齐再交互。==**
    
       | **角度**     | **回答**                                                     |
       | ------------ | ------------------------------------------------------------ |
       | **理论支撑** | **间接有：来自多模态对齐与注意力机制的一致性设计思路，但不是定理级别** |
       | **实验支撑** | **有：共享 $W_F$ 在众多模型中效果好；消融通常性能下降**      |
       | **概念本质** | **不是“强制相同语义”，而是“训练中逼近协同语义空间”**         |
    
    2. **为注意力机制提供 Query / Key 表达能力**
    
       **可以把这个 $W_F$ 理解为 embedding standardizer**
    
       * **把来自结构/语义两个来源的表示统一后，再送去做 $Q/K$；**
    
       * **如果不做这个步骤，可能造成注意力值失真，训练不稳定。**
    
    3. **提供更多参数容量（更强的表达能力）**
    
       **哪怕两个向量维度一样，如果直接拿来算注意力，其实是把整个学习过程限制住了（即 attention 只能依据原始向量之间的点积来衡量关系）。**
    
       **引入这些线性变换之后，相当于告诉模型：**
    
       > **“你不仅可以考虑原始的结构和语义特征，还能自由组合它们的不同维度，以学习到最合适的注意力打分方式。**



#### **理解 LTR（Learning-To-Rank） 排名损失与损失函数**

**如何跳出节点嵌入的局部性？这个是怎么理解的？**

> ### **Learning-to-Rank Loss（学习排序损失）**
>
> #### **核心思想**
> **传统的回归损失（如RMSE）仅关注节点重要性值的绝对误差，而忽略了节点间的相对排名关系。因此，作者引入列表式学习排序损失（Listwise LTR Loss），直接优化节点的重要性排名。**
>
> #### **公式解析**
> 1. **标准化重要性值：**
>    $$
>    s_v' = \frac{\exp(s_v)}{\sum_{j \in \mathcal{N}_v^{(r)}} \exp(s_j)}, \quad s_v^{*'} = \frac{\exp(s_v^*)}{\sum_{j \in \mathcal{N}_v^{(r)}} \exp(s_j^*)}
>    $$
>    - **对真实重要性值 $s_v$ 和预测值 $s_v^*$ 进行softmax归一化。**
>
> 2. **交叉熵损失：**
>    $$
>    \mathcal{L}_v^{(r)} = -\sum_{i \in \mathcal{N}_v^{(r)}} s_i' \log(s_i^{*'})
>    $$
>
> #### **设计动机**
> 1. **全局排名感知：通过比较节点间的相对重要性，从全局视角优化模型。**
> 2. **竞争机制：softmax函数引入节点间的竞争，区分重要与非重要节点。**
>
> ---
>
> ###  **Training Process（训练过程）**
>
> #### **损失函数组成**
> **总损失函数：**
> $$
> \mathcal{L} = a\mathcal{L}_0 + b\frac{\mathcal{L}_1 + \mathcal{L}_2}{2} + c \left( \frac{1}{|\mathcal{V}_s|} \sum_{j \in \mathcal{V}_s} \mathcal{L}_j^{(r)} \right)
> $$
>
> 1. **主回归损失：**
>    $$
>    \mathcal{L}_0 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^* - s_i)^2
>    $$
>
> 2. **辅助回归损失：**
>    $$
>    \mathcal{L}_1 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^{(s)} - s_i)^2, \quad \mathcal{L}_2 = \frac{1}{|\mathcal{V}_s|} \sum_{i \in \mathcal{V}_s} (s_i^{(c)} - s_i)^2
>    $$
>
> #### **超参数设计**
> - **权重设置为 $a=0.3$, $b=0.7$, $c=0.5$，平衡多任务学习。**
>
> #### **训练策略**
> 1. **分阶段训练：先预训练单模态编码器，再联合优化。**
> 2. **动态采样：计算LTR损失时随机采样参考节点（20~200个）。**
> 3. **早停机制：监控验证集NDCG指标。**
>
> ---
>
> ### **关键创新点**
> 1. **多任务学习框架联合优化RMSE和LTR损失**
> 2. **通过辅助损失约束单模态预测**
> 3. **结合GNN的局部消息传递与LTR的全局排名优化**
>
> ---
>
> ### **完整内容补充**
>
> #### **公式（11）~（13）：重要性预测模块**
> 1. **注意力权重计算：**
>    $$
>    \gamma^{(s)} = \frac{\exp(h_v^{(s)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}, \quad \gamma^{(c)} = \frac{\exp(h_v^{(c)} \lambda^T)}{\exp(h_v^{(s)} \lambda^T) + \exp(h_v^{(c)} \lambda^T)}
>    $$
>
> 2. **重要性值投影：**
>    $$
>    s_v^{(s)} = W_s^1 h_v^{(s)}, \quad s_v^{(c)} = W_s^2 h_v^{(c)}
>    $$
>
> 3. **重要性值融合：**
>    $$
>    s_v^* = \text{LeakyReLU}(\gamma^{(s)} s_v^{(s)} + \gamma^{(c)} s_v^{(c)})
>    $$
>
> 



#### **理解实验**

* **文中在 `transfrom` 这个架构中，针对谓词边与起点与汇点之间的注意力，选取了几种结合的模式，包括 `mul` `dot` `add` ，代码中默认使用 `mul`** 





#### **疑问点**

##### **为什么公式（2）针对的是对汇点的入边进行归一化而不是源点的出边**

* **因为最后的语义特征要归到节点上，而汇点接收信息，将语义特征归到汇点上而非源点上更加符合直观感觉**

* > **1. 公式（2）的数学形式**
  >
  > **公式（2）的归一化是针对目标节点（汇点）的所有入边进行的：**
  >$$
  > a_{(u,v)}^{k,l} = \sum_{m} \frac{\exp(w_{(u,v),m}^{k,l})}{\sum_{u' \in \mathcal{N}_v} \sum_{m'} \exp(w_{(u',v),m'}^{k,l})}
  > $$
  > - **分子：计算源节点 $u$ 通过边 $m$ 对目标节点 $v$ 的注意力权重 $w_{(u,v),m}^{k,l}$（由公式1计算）。**
  > - **分母：对目标节点 $v$ 的所有入边邻居 $u' \in \mathcal{N}_v$ 和所有可能的边类型 $m'$ 进行归一化。**
  > 
  > **2. 为什么归一化针对汇点（而非源点）？**
  >
  > **（1）任务需求：节点重要性估计**
  >
  > - **目标：预测目标节点 $v$ 的重要性，而非评估邻居节点 $u$ 的重要性。**
  >- **信息聚合方向：需要将邻居节点 $u$ 的信息（结构和语义）汇聚到目标节点 $v$ 上，因此归一化需保证所有入边对 $v$ 的贡献总和合理（例如加权和为1）。**
  > 
  > **（2）数学合理性**
  >
  > - **概率解释：注意力权重 $a_{(u,v)}^{k,l}$ 可视为“邻居 $u$ 对目标 $v$ 的重要性概率”，需满足 $\sum_{u} a_{(u,v)}^{k,l} = 1$。**
  >- **梯度稳定性：归一化针对汇点能避免不同目标节点 $v$ 的注意力权重尺度差异，使训练更稳定。**
  > 
  > **（3）与经典模型的对比**
  >
  > - **GAT/GCN：归一化也是针对目标节点的邻居（即汇点的入边），但本文进一步扩展到了多关系边（通过 $m$ 区分边类型）。**
  >- **PageRank：类似地，PageRank的权重归一化也是针对“被链接的网页”（汇点），而非“链接出去的网页”。**
  > 
  > **3. 你的解释的修正**
  >
  > **你的直观理解（“语义特征归到汇点”）是正确的，但需要补充：**
  >- **更深层原因：这是由节点重要性估计的任务目标决定的。模型需要学习“哪些邻居对目标节点更重要”，而非“目标节点对邻居的影响”。**
  > - **边方向的物理意义：在知识图谱中，边通常表示“源节点对目标节点的某种关系”（如“导演-电影”），重要性应从邻居（导演）传递到目标（电影）。**
  > 
  > **4. 反例思考**
  >
  > **如果归一化针对源点（即 $\sum_{v} a_{(u,v)}^{k,l} = 1$）：**
  >- **问题1：一个邻居节点 $u$ 的重要性会被均摊到所有连接的 $v$ 上，无法区分它对不同目标节点的贡献差异。**
  > - **问题2：与任务目标脱节，因为我们需要的是“目标节点的重要性”，而非“邻居的重要性分布”。**
  > 
  > **总结**
  >
  > **你的直觉是对的，但更本质的原因是：**
  >1. **任务驱动：节点重要性估计需要聚合邻居信息到目标节点。**
  > 2. **数学约束：归一化针对汇点符合概率建模和梯度优化的需求。**
  > 3. **知识图谱特性：多关系边的语义需要通过目标节点中心的注意力机制捕获。**
  > 
  > **这种设计与GAT、Transformer等模型一致，但通过显式建模关系类型（谓词）进一步增强了表达能力。**



##### **Q1：为什么交叉注意力机制要设置 `temp` 温度，而自注意力机制则没有 Q2：为什么交叉注意力机制的 `FFN` 和自注意力机制的 `FFN` 不一样，前者先降维后升维，后者反之。这是为什么？**

* **因为交叉部分相当于是多模态情况，两个领域的特征不一样，需要温度来进行平滑**

* **就是一个更加关注泛化能力一个更加关注表达能力**

  > **总的来说，这两种设计反映了处理数据时不同的 FFN 设计策略，分别侧重于模型的泛化能力和复杂关系的学习。`CrossAttention` 设计侧重于通过先降维后升维来减少复杂度，强调泛化能力；而 `GTLayer` 的设计则通过先增大维度再缩小维度，提供了更多的表达能力和灵活性。每种设计都有其优势和权衡，影响模型的计算成本、容量以及学习到的表示。**



##### **在计算LTR时，为什么要对节点进行采样，而不是直接运用所有节点进行计算**

> **在计算Learning-to-Rank (LTR)损失时对节点进行采样（而不是使用全部节点）主要基于以下几个关键原因：**
>
> 1. **计算效率的考量**
>    - **知识图谱通常包含大量节点（如IMDB数据集有超百万节点）**
>    - **计算所有节点对的softmax归一化：**
>    $$
>    s_v' = \frac{\exp(s_v)}{\sum_{j \in \mathcal{V}} \exp(s_j)}
>    $$
>    **时间复杂度为O(|V|^2)，在大规模图上不可行**
>
> 2. **训练稳定性的需要**
>    - **全量计算会导致：**
>      - **梯度被大量不重要节点稀释（因为分母变大了，会被其他炮灰给稀释。采样节点的话没准信号强度能提升十几倍几十倍，这种情况可能也会导致梯度消失）**
>      - **容易陷入局部最优（主要优化头部重要节点）**
>    - **采样可控制对比强度：**
>    
>    $$
>    \mathcal{N}_v^{(r)} = \text{Sample}(V, n) \quad (n \ll |V|)
>    $$
>    
> 3. **课程学习(Curriculum Learning)效应**
>    - **动态采样模拟了"由易到难"的学习过程：**
>      - **初期：更多随机采样探索全局结构**
>      - **后期：侧重难例采样（如重要性相近的节点对）**
>
> 4. **负采样策略的延伸**
>    - **类比知识图谱嵌入中的负采样：**
>      - **真实场景中不重要节点远多于重要节点**
>      - **采样相当于自动进行难负例挖掘**
>
> 5. **防止过平滑(Over-smoothing)**
>    - **在GNN中，全量计算会使所有节点重要性得分趋同**
>    - **采样保持了一定的区分度，如对电影节点：**
>    
>    $$
>    \mathcal{N}_v^{(r)} \subset \{\text{同类型电影}\} \cup \{\text{关联导演作品}\}
>    $$
>    
> 6. **实际效果验证**
>    - **论文实验显示：**
>      - **采样n=100时效果最佳**
>      - **全量计算反而使NDCG@100下降约2-3%**
>      - **训练时间可缩短5-10倍**
>
> **技术实现上，作者采用了动态分批次采样策略：**
> ```python
> def sample_nodes(batch_nodes, full_graph, n_samples=100):
>     # 混合采样：当前batch节点 + 随机节点 + 难例节点
>     return torch.cat([
>         batch_nodes,
>         random.sample(full_graph.nodes, n_samples//2),
>         find_hard_negatives(batch_nodes)
>     ])
> ```
>
> **这种设计在保持排序质量的同时，显著提升了大规模知识图谱上的训练效率。**



##### 如何==深度理解论文中的损失设置==

主要是理解，使用 `softmax` 计算排名损失的意义以及理解这么操作为什么会有用。

* 损失由以下三部分组成

  1. 最终预测重要性值（融合了结构与语义信息）与真实值的 RMSE（主损失）

  2. 结构分支预测与真实值的 RMSE（辅助损失）
  3. 语义分支预测与真实值的 RMSE（辅助损失）
  4. 基于 **Learning-to-Rank (LTR)** 的排序损失，强调**节点重要性的相对顺序**

* 这样设计的意义

  * 引入多路 `RMSE` 是为了训练的稳定性（这是从数值的绝对视角来看）
    * 分别对结构分支和语义分支引入 RMSE（$L_1,L_2$），有助于各自学习与目标值的拟合，而不仅仅依赖最终融合结果。
  * 引入排序损失是为了全局排名感知（这是从数值的相对视角来看）
    * 排序损失 $L^{(r)}$ 采用 Listwise LTR 方式，它不是简单对预测值拟合，而是鼓励模型学习节点之间的**排名差异**。==事实上，针对节点重要性这个问题，相对排名更加重要==
    * Softmax 排名使模型跳出局部最小值，提高重要性表示的区分度，增强对高低重要性节点的辨识力。（==重点理解为什么能使模型跳出局部最小值==）

* 一个例子说明引入LTR的意义

  > ### 🌰 假设场景：我们要预测三个节点的重要性
  >
  > | 节点 | 真实重要性（打分） | 模型预测值（$Case A$） | 模型预测值（$Case B$） |
  > | ---- | ------------------ | ---------------------- | ---------------------- |
  > | $A$  | $10$               | $8$                    | $3$                    |
  > | $B$  | $5$                | $6$                    | $6$                    |
  > | $C$  | $1$                | $4$                    | $9$                    |
  >
  > ------
  >
  > ### ✅ 一、只用 $RMSE$ 来看两个 $case$ 的好坏：
  >
  > 我们分别计算预测值和真实值的 $RMSE$：
  >
  > #### **$Case A$**：
  >
  > $$
  > RMSE = \sqrt{\frac{(8 - 10)^2 + (6 - 5)^2 + (4 - 1)^2}{3}} = \sqrt{\frac{4 + 1 + 9}{3}} = \sqrt{4.67} \approx 2.16
  > $$
  >
  > #### **$Case B$**：
  >
  > $$
  > RMSE = \sqrt{\frac{(3 - 10)^2 + (6 - 5)^2 + (9 - 1)^2}{3}} = \sqrt{\frac{49 + 1 + 64}{3}} = \sqrt{38} \approx 6.16
  > $$
  >
  > 👉 **结论：$Case A$ 的 $RMSE$ 更小，看起来更好。**
  >
  > ------
  >
  > ### ❗但我们再看一下预测的**排序情况**：
  >
  > - **真实排名（从大到小）**：$A > B > C$
  > - **$Case A$ 的预测排名**：$B > A > C$（错误）
  > - **$Case B$ 的预测排名**：$C > B > A$（完全错误）
  >
  > 你可能觉得“$RMSE$ 小就够了”，但在“节点重要性估计”任务中，我们真正关心的是：**谁更重要**，也就是排序对不对！
  >
  > ------
  >
  > ### ✅ 二、引入 $softmax$ 排名损失之后：
  >
  > 我们把预测值做 $softmax$，比较概率分布对不对。
  >
  > #### $Case A$：
  >
  > 预测值为 $[8, 6, 4]$，$softmax$ 后是：
  >
  > $$
  > [0.87, 0.12, 0.01] \quad \text{（$A$最大）}
  > $$
  >
  > → 排名大致对了，但 $B$ 比 $A$ 高，所以有**一定损失**。
  >
  > #### $Case B$：
  >
  > 预测值为 $[3, 6, 9]$，$softmax$ 后是：
  >
  > $$
  > [0.01, 0.09, 0.90] \quad \text{（$C$最大）}
  > $$
  >
  > → 排名完全错了，$softmax$ 会给出很大的损失惩罚！
  >
  > ------
  >
  > ### 🧠 总结理解：
  >
  > - **$RMSE$ 只看值的差异**，不关心排序错没错。
  > - **$softmax$ 排名损失惩罚排序错误的情况**，让模型更注重“谁比谁重要”。
  > - 所以，它更适合像节点重要性这种“排序本质”的任务。



#### **自己瞎想的创新点**

* **从 `figure-4` 得到的启发，**

  - **Structure/Semantic：仅优化单一特征分支的 RMSE 和 LTR 损失。**
  - **Concatenation：直接优化拼接后的特征，缺乏对结构和语义信息的差异化处理。**
  - **RGTN：通过协同注意力动态融合两种特征，并利用多任务损失（RMSE + LTR）联合优化。**

  **这种设计验证了 RGTN 的优越性：简单拼接无法充分利用异构特征，而 RGTN 的融合机制能更灵活地平衡结构和语义信息。**

  **那么我们能否根据谓词的种类（用聚类的方法得到语义相近的谓词种类），分别设置损失函数，根据图的拓扑结构（比方说强连通分量为一组。。）分别设置损失函数？**

##### **`deepseek` 的回答**

> **你的想法非常有创新性，并且符合知识图谱（KG）中异构特征和复杂关系的处理需求。通过基于谓词语义的聚类或基于图拓扑的分组来设计差异化的损失函数，确实可以进一步提升模型对异构信息的利用能力。以下是对这一思路的详细分析和可行性探讨：**
>
> ---
>
> ### **1. 基于谓词语义的差异化损失函数**
> #### **方法**
> - **谓词聚类：  
>   使用聚类算法（如层次聚类、GMM、或基于KG嵌入的聚类）将语义相似的谓词分组（例如，"directed_by" 和 "written_by" 可能属于“创作关系”簇）。**
> - **分组损失函数：  
>   为每个谓词簇设计独立的损失函数（如不同权重的 RMSE 或 LTR 损失），以反映不同关系类型对节点重要性传播的差异。**
>
> #### **优势**
> - **语义感知：  
>   相似谓词（如“导演”和“编剧”）对节点重要性的影响可能类似，分组损失可以强化这种共性。**
> - **缓解稀疏性：  
>   低频谓词可通过聚类共享同一组损失参数，避免过拟合。**
>
> #### **挑战**
> - **聚类质量依赖：  
>   需要高质量的谓词嵌入（如通过TransE、CompGCN等生成）或领域知识指导聚类。**
> - **动态调整：  
>   某些谓词可能在不同上下文中作用不同（如“合作”关系在科学合作网络 vs. 电影网络中的重要性不同），静态分组可能不够灵活。**
>
> #### **改进方向**
> - **自适应聚类：  
>   在训练过程中动态调整谓词分组（如通过在线聚类或注意力机制）。**
> - **混合损失：  
>   保留全局损失的同时，为特定簇添加正则化项（例如，对“关键关系”簇加大 LTR 损失权重）。**
>
> ---
>
> ### **2. 基于图拓扑结构的差异化损失函数**
> #### **方法**
> - **强连通分量（SCC）分组：  
>   将节点按 SCC 划分（例如，一个紧密合作的科学家群体 vs. 孤立的节点），为不同 SCC 设计损失函数。**
> - **中心性分组：  
>   根据节点中心性（如度、Betweenness）分组，对核心节点和边缘节点采用不同的损失权重。**
>
> #### **优势**
> - **结构感知：  
>   强连通区域内的节点重要性可能高度相关，分组损失可以捕捉这种局部一致性。**
> - **处理长尾分布：  
>   对稀疏子图（如孤节点）采用更宽松的损失，避免模型过度拟合密集子图。**
>
> #### **挑战**
> - **计算复杂度：  
>   实时计算 SCC 或中心性会增加训练开销（尤其是动态图）。**
> - **边界模糊性：  
>   节点可能属于多个重叠社区（如演员同时参与多个电影系列），硬分组可能不合理。**
>
> #### **改进方向**
> - **层次化损失：  
>   全局损失 + 局部损失（如为每个 SCC 添加辅助 RMSE 损失）。**
> - **图划分技巧：  
>   使用 Louvain 等社区发现算法替代 SCC，更灵活地捕捉模块化结构。**
>
> ---
>
> ### **3. 结合异构特征的通用框架建议**
> **若要系统化实现上述思路，可以扩展 RGTN 的架构如下：**  
> 1. **谓词聚类分支：**  
>    - **在关系图变换层（Equation 1）中，为每个谓词簇分配独立的注意力头。**  
>    - **每个簇的损失函数加权聚合（如关键簇权重更高）。**  
> 2. **拓扑感知分支：**  
>    - **通过预处理（如 SCC 检测）或在线聚类（如 GNN 生成的节点嵌入）动态分组。**  
>    - **在损失函数中为不同组添加正则化项（例如，强连通区域内的节点排名需更严格）。**  
> 3. **动态融合模块：**  
>    - **使用元学习（如 HyperNetwork）或门控机制，根据当前输入调整不同分组的损失权重。**
>
> ---
>
> ### **可行性结论**
> **你的想法完全可行，且已有部分研究支持类似方向（如关系聚类在 KG 嵌入中的应用、图结构感知的损失设计）。但需注意：**  
> - **平衡复杂度与收益：附加的聚类和分组可能增加计算成本，需通过实验验证提升效果。**  
> - **避免过工程化：优先验证简单分组（如基于谓词频次的粗聚类）的效果，再逐步细化。**  
>
> **如果实现得当，这种异构感知的损失设计有望进一步提升节点重要性估计的精度，尤其是在复杂知识图谱（如多领域、动态演化）的场景中。**



##### **`gpt` 的回答**

> **你的这个想法其实很有潜力，尤其是和 RGTN 这样的结构结合起来，可以更进一步发挥异构图中“谓词多样性”和“图结构信息”的优势。我们来详细分析一下你的两个核心想法的可行性：**
>
> ------
>
> ### **想法一：根据谓词种类进行聚类，并分组设置损失函数**
>
> **核心动机： RGTN中已经考虑了不同谓词（predicate）在重要性传递中有不同的作用，它们用独立的可学习表示（predicate embedding）参与注意力权重计算。**
>
> **你扩展的思路： 聚类这些谓词的embedding（或语义）得到语义相近的谓词类簇，对不同类簇引入不同的损失函数或加权机制，体现出不同类型关系对节点重要性的不同影响力。**
>
> **可行性分析：**
>
> - **✅ 优点：**
>   - **利用谓词间语义相似性增强建模的语义感知能力；**
>   - **可适配“强主导关系”和“辅助关系”之间的作用差异；**
>   - **聚类结果可以辅助调节学习过程中的损失重点（类似Focal Loss思想）。**
> - **⚠️ 挑战：**
>   - **谓词聚类后的类簇数量和划分质量会影响最终效果，可能需要先训练出较稳定的谓词embedding；**
>   - **设计 group-wise loss 时要考虑不同组之间的“协同性”，避免模型对某组过拟合。**
>
> **初步实现路径建议：**
>
> 1. **使用 K-Means 或 Spectral Clustering 对谓词embedding（训练中或预训练）进行聚类；**
> 2. **每一组谓词对应一套 attention 或 loss scaling 参数（例如加权RMSE/LTR loss）；**
> 3. **实验验证每一类关系对最终预测的重要程度，调节其 loss 权重。**
>
> ------
>
> ### **想法二：根据图的拓扑结构进行分组，例如以强连通分量为单位**
>
> **核心动机： 图中某些子结构，如强连通分量（SCC）或社区结构，可能内部节点影响力具有高度耦合性，从局部结构角度设置损失可能更合理。**
>
> **你扩展的思路： 将图划分为若干结构区域（如SCC、K-core、社区等），为每个结构区域单独设置损失函数或训练策略，例如分区域做局部排序或加权学习。**
>
> **可行性分析：**
>
> - **✅ 优点：**
>   - **对重要性排序更具局部结构敏感性；**
>   - **能在训练时控制不同结构子图的梯度贡献，有利于模型泛化；**
>   - **对于低连接度区域（long-tail）可提高关注度。**
> - **⚠️ 挑战：**
>   - **某些图划分方式（如SCC）在异构图中未必直接适用，可能要结合关系类型；**
>   - **在 mini-batch 训练下，如何划分结构并动态保持子图信息是技术难点。**
>
> **实现路径建议：**
>
> 1. **对原图进行结构划分（比如 Louvain 算法做社区发现，或计算 K-core/SCC）；**
> 2. **在训练中，采用结构区域内的 局部对比损失（local LTR），或者为不同区域设置 loss 权重；**
> 3. **可考虑引入“结构感知注意力”机制，让模型学习到“哪些区域更重要”。**
>
> ------
>
> ### **最终评估：想法是否靠谱？**
>
> **我觉得：非常靠谱。**
>
> **这两个方向实际上是对现有模型的精细化建模思路的强化，能更好地挖掘：**
>
> - **谓词之间的语义层次结构；**
> - **图拓扑下的信息耦合关系。**
>
> **如果你能设计出合理的结构（尤其是分组策略与损失协同机制），这个方向是非常有创新性和发表潜力的。RGTN 本身已经为这个任务打下了良好基础，你的扩展可以看作是更进一步的“语义/结构引导的目标分组学习”。**









### SKES

* 感觉现在的目标就是**如何获取更多的信息**，模型变得越来越复杂，各种缝合什么注意力 transform 都用上了，目的就是为了获得更加多元更加丰富的信息。然后再包装一下，当然听得确实是有道理的，如果有代码且代码效果如实验一样那么可以认可，可惜除了RGTN那篇其余的都没有（要么没代码，有代码的跑不到论文中的效果）

#### 前言

==值得注意的是，网络**异质性**会导致节点重要性解释中的语义和数值差异，这使得在 HINs 上研究该问题比在同构网络中更具挑战性。==

尽管存在网络连接，**相邻节点对目标节点重要性值的影响可能不同** —— 例如，作者和主题对论文重要性值的贡献维度不同。此外，学者的 h 指数通常在 [0,350] 范围内，而论文的最高被引次数可能超过 30 万次，这表明重要性值的异质性本质上受**语义异质性影响**。

相关工作一览：

GENI（Park 等人，2019）应用图神经网络和注意力机制来聚合结构信息以进行节点重要性估计。MULTIIMPORT（Park 等人，2020）通过使用多种外部输入信号改进了 GENI。RGTN（Huang 等人，2021）同时**利用网络结构信息和节点属性**来估计节点的重要性。然而，所有这些工作都**侧重于解决基于重要性的排序问题，而没有推断具体的==重要性值==**。最近的工作 HIVEN（Huang 等人，2022）通过学习节点的局部和全局信息来考虑异质信息网络中节点重要性的值异质性。然而，主要问题在于 HIVEN **纯粹依赖图神经网络进行自动信息聚合，却忽略了异质信息网络中显式的结构知识挖掘**，导致模型在重要性计算中表现不佳且**可解释性**较低。

SKES的三个递进模块：

（1）**结构先验知识挖掘模块**专注于从给定的异质信息网络（HIN）中挖掘节点的内在信息（即节点自身的中心性和节点间的相似性），提供覆盖多样性和异质性的结构知识。（2）**特征分布协同表示模块**通过自适应的异质知识协同，以经验方式学习表示节点独特、复杂的高维特征分布。（3）我们手动创建一个随机特征分布作为参考，其在嵌入空间中充当 “坐标原点”。由于随机性，该参考的信息量极少。随后，**节点重要性值估计模块**通过测量输入节点与参考在潜在空间中的距离来量化其信息性，并将该距离转换为节点重要性估计值。



#### 预备知识

* 元路径诱导子图

  * 可以看下这个[视频](https://www.bilibili.com/video/BV1Li4y1C7WM/?spm_id_from=333.337.search-card.all.click&vd_source=56ba8a8ec52809c81ce429c827dc30ab)

  * 第一篇异构图神经网络的论文为 `HAN` 写于2019年，同样可以看这个[视频](https://www.bilibili.com/video/BV12a411b7BC?spm_id_from=333.788.videopod.sections&vd_source=56ba8a8ec52809c81ce429c827dc30ab) 入门，重点把握以下：
    * n 阶邻居（经过元路径生成的诱导子图中，每个节点的邻居还包括自己 Meta-path based Neighbors）
    
    * 节点级别的注意力
    
      * 这里在使用softmax之前使用 sigmoid 将分数压在了 0~1 之间，对分数进一步进行压缩与平滑。经过实验验证发现确实是这样
    
      * 花了大量的时间稍微理解了下 `tanh` 与 `sigmoid`的处理，在 HAN 这篇论文中
    
        > **tanh + Softmax 的组合**比 **sigmoid + Softmax** 更能：
        >
        > 1. **通过负值彻底抑制无关元路径**（权重接近 0）；
        > 2. **增强重要路径的权重集中度**（避免噪声干扰）。
        >
        > 这正是 HAN 选择 tanh 的核心原因——它让语义注意力机制更具判别力！
    
    * 元路径级别（语义级别）的注意力


  获取信息丰富的结构知识对于估计节点重要性至关重要。为了在HIN中实现这一点，我们采用基于元路径的方法（Sun等人，2011）**首先获得底层子网络**，如下所示。

  * 元路径诱导子图：$G^k_j=由第 k 条 \text{metapath} 构造出的、只包含第 j 类节点的子图$.

  * **在构造 metapath-induced 子图时，通常会**
     **将原图中的有向边视为无向边**，
     **只要存在符合类型序列的路径即可，无需方向严格匹配。**

  * 其实就是异构图中寻找谓词类型，得到一个导出子图。这一导出子图看成一个图的局部

* 1-Wasserstein距离

  > ### **具体例子：用数字理解 1-Wasserstein 距离**  
  >
  > 假设我们有两个**离散的一维概率分布** $P$ 和 $Q$，用它们的概率质量函数（PMF）表示：  
  >
  > - **分布 $P$**（原始分布）：  
  >   $$
  >   P = \begin{cases}
  >   1 \text{（概率 } 0.4\text{）}, \\
  >   2 \text{（概率 } 0.3\text{）}, \\
  >   3 \text{（概率 } 0.3\text{）}.
  >   \end{cases}
  >   $$
  >   
  > - **分布 $Q$**（目标分布）：  
  >   $$
  >   Q = \begin{cases}
  >   2 \text{（概率 } 0.5\text{）}, \\
  >   3 \text{（概率 } 0.5\text{）}.
  >   \end{cases}
  >   $$
  >
  > #### **步骤 1：计算累积分布函数（CDF）**
  > - **$P$ 的 CDF**（$F_P$）：  
  >   $$
  >   F_P(x) = \begin{cases}
  >   0 & \text{if } x < 1, \\
  >   0.4 & \text{if } 1 \leq x < 2, \\
  >   0.7 & \text{if } 2 \leq x < 3, \\
  >   1.0 & \text{if } x \geq 3.
  >   \end{cases}
  >   $$
  >   
  > - **$Q$ 的 CDF**（$F_Q$）：  
  >   $$
  >   F_Q(x) = \begin{cases}
  >   0 & \text{if } x < 2, \\
  >   0.5 & \text{if } 2 \leq x < 3, \\
  >   1.0 & \text{if } x \geq 3.
  >   \end{cases}
  >   $$
  >   
  > - **$Q$ 的逆 CDF**（$F_Q^{-1}$）：  
  >   $$
  >   F_Q^{-1}(p) = \begin{cases}
  >   2 & \text{if } 0 < p \leq 0.5, \\
  >   3 & \text{if } 0.5 < p \leq 1.0.
  >   \end{cases}
  >   $$
  >
  > #### **步骤 2：计算最优传输映射 $f^*$**
  > 根据 **$f^*(x) = F_Q^{-1}(F_P(x))$**，我们计算每个 $x$ 的映射：
  > - $x = 1$:  
  >   $F_P(1) = 0.4$,  
  >   $F_Q^{-1}(0.4) = 2$（因为 $0 < 0.4 \leq 0.5$）。  
  >   → $f^*(1) = 2$.  
  >
  > - $x = 2$:  
  >   $F_P(2) = 0.7$,  
  >   $F_Q^{-1}(0.7) = 3$（因为 $0.5 < 0.7 \leq 1.0$）。  
  >   → $f^*(2) = 3$.  
  >
  > - $x = 3$:  
  >   $F_P(3) = 1.0$,  
  >   $F_Q^{-1}(1.0) = 3$.  
  >   → $f^*(3) = 3$.  
  >
  > 所以，**最优传输映射 $f^*$** 为：
  > $$
  > f^*(x) = \begin{cases}
  > 2 & \text{if } x = 1, \\
  > 3 & \text{if } x = 2 \text{ or } 3.
  > \end{cases}
  > $$
  >
  > #### **步骤 3：计算 1-Wasserstein 距离**
  > 根据公式：
  > $$
  > W(P, Q) = \int \|x - f^*(x)\|_1 \, dP(x),
  > $$
  > 我们计算每个 $x$ 的贡献：
  > - $x = 1$:  
  >   $\|1 - 2\|_1 = 1$, 概率 $P(x=1) = 0.4$.  
  >   → 贡献：$1 \times 0.4 = 0.4$.  
  >
  > - $x = 2$:  
  >   $\|2 - 3\|_1 = 1$, 概率 $P(x=2) = 0.3$.  
  >   → 贡献：$1 \times 0.3 = 0.3$.  
  >
  > - $x = 3$:  
  >   $\|3 - 3\|_1 = 0$, 概率 $P(x=3) = 0.3$.  
  >   → 贡献：$0 \times 0.3 = 0$.  
  >
  > **总 Wasserstein 距离**：
  > $$
  > W(P, Q) = 0.4 + 0.3 + 0 = 0.7.
  > $$
  >
  > #### **直观解释**
  > - **$P$ 的 "1" 需要移动到 "2"**（成本 $1 \times 0.4 = 0.4$）。  
  > - **$P$ 的 "2" 需要移动到 "3"**（成本 $1 \times 0.3 = 0.3$）。  
  > - **$P$ 的 "3" 不需要移动**（成本 $0$）。  
  > - **总成本 = 0.7**，即 $W(P, Q) = 0.7$。
  >
  > ---
  >
  > ### **在 SKES 中的应用**
  > 在论文中，SKES 使用 **1-Wasserstein 距离** 来：
  > 1. **定义一个随机参考分布 $P_0$**（如均匀分布）。  
  > 2. **计算每个节点的特征分布 $P_i$ 与 $P_0$ 的距离 $W(P_0, P_i)$**。  
  > 3. **用 $W(P_0, P_i)$ 衡量节点的重要性**（距离越大，节点越重要）。
  >
  > 这样，**1-Wasserstein 距离** 提供了一种可解释的数学框架，用于量化节点特征的"信息量"差异。

* pathsim

  * PathSim 度量的是两个节点是否在图中**扮演了类似的结构角色**。

    它特别适合用于**异构图**，我们可以根据不同的元路径选择不同的相似度视角。

    和 node2vec 这种局部游走方法相比，PathSim 更“全局”和“语义明确”。

* 协同表示学习



#### 文章贡献：



#### 理解结构化先验知识开发

##### 元路径诱导的子网建设。

##### 先验中心性和相似性嵌入（提出了这些是节点内与节点间的先验知识）

* 在上一步导出的子图执行
* 提出了节点逐点中心性和逐对相似性
  * 揭示节点内和节点间的先验知识。
* 节点中心性
  * 对这些流行的中心性度量进行预处理，以提高知识覆盖率。详细配方见附录。然后通过两层感知器将**每个中心值**（中心值可以从度中心性、pagerank中等选取）矢量化为128维。
  * 论文中的 $L$ 是选取的度中心性的指标数
* 节点间的相似性
  * 以边作为切入，边上两点作为计算对象
  * **属性相似性**：基于节点属性（如文本描述）的**余弦相似度**，构建**边权重矩阵**（即余弦相似度作为边权），通过 node2vec 生成嵌入 $f_{i,k}^{\text{att}}$。
  * **拓扑相似性**：基于 **PathSim** 计算节点对在元路径下的结构相似性，通过 node2vec 生成嵌入 $f_{i,k}^{\text{top}}$。
  * **融合**：将属性和拓扑相似性嵌入相加，得到**相似性知识嵌入** $c_{i,k}^{(L+1)} = f_{i,k}^{\text{att}} + f_{i,k}^{\text{top}}$。
  * 总结：中心性和相似性知识为底层网络提供了**连贯和互补**的视图，因为这些度量中的每一个通常都代表了结构信息的特定视角。

#### 理解特征分布的协同表示

##### 异构知识聚合

反复通过注意力机制然后进行加权求和，做了两层（一层针对参数 $l$ ，一层针对参数 $k$），对这个节点的异构知识嵌入向量做了非常高浓度的==**聚合**==与==**压缩**==

> **通过两层嵌套注意力机制（分别对结构知识维度和 metapath 维度），SKES 实现了对异构结构先验知识的深度聚合，形成表达节点复杂语义的高质量嵌入，为后续通过 optimal transport 测量节点的重要性提供了理论保障与信息基础。**

因为先验中心性和相似性知识代表了节点重要性的不同维度，因此作者建议将它们协同融合，以便后续表示未知的高维特征分布

* 这里其实就是**在异构图上计算注意力**的过程
* “$\alpha_{i,k}^{(l)}$ 表示在第 $k$ 条 metapath（关系路径）下，结构知识类型为 $l$（比如某种 centrality 或 similarity），对节点 $v_i$ 的结构特征的注意力权重，该值是在所有与节点 $v_i$ 同类型、且出现在该 metapath 所诱导的子图中的节点上求平均得到的。”但需要注意，紧接着马上就要对每一层进行 softmax。
  把眼光放远一点，这是在做**对每一层做注意力机制**，只是说因为异构图的特殊性，对它们的处理更加细化了，**先考虑元路径，再考虑节点类型，将结构更加细分了**
* 既然我们先考虑元路径，再考虑节点类型，那么我们自然还要“回”上去，即考虑所有节点类型为 $i$ （这里不考虑具体节点），源路径为 $k$ 的情况下所作出的==**嵌入贡献**==（取平均）得到 $\tau_{i,k}$ ，做法是同样是使用前馈神经网络映射成一个 scalar。**当然紧接着就是要进行 softmax 处理（维度为 k）**
* 最终的$\mathbf{x}_i$ 是通过最终的 $\mathbf{e}_i$ 与初始属性拼接而成，$\mathbf{e}_i$ 则是 $\mathbf{e}_{i,k}$ 的加权和。就是说，最终的节点嵌入，（1）综合了我们构造的一些结构信息（centrality 或 similarity），使用了注意力进行了**加权处理**（2）利用了知识图本身的结构信息，从元路径的角度进行了注意力与**加权处理**（3）节点属性可能包含一些文本与语义信息。

##### 特征分布的经验表示

这部分介绍了每个节点如何构建**经验特征**，此处的任务是从上面得到的特征中学习一个**高维、可用于衡量信息量的表征向量，即所谓的经验==分布==**（好好理解一下什么是特征分布，为什么要这么做？）

作者的这一套利用节点特征嵌入构造特征分布是一种经验流，没有经过严格的数学证明，但是在实验上证明了它是有效的。

> Wasserstein 距离确实可以度量分布；
>
> 但 attention 得到的 $h_i^R$ 是不是一个好代理？取决于建模质量，没有理论保证；
>
> 这是一种启发式（heuristic design），实践上有效，**理论上没有严格闭环证明**。

> 作者认为，节点的重要性源于其在**异构图中融合的多源知识**，而这种融合**不能简单用一个嵌入向量来表达**。他引入“节点特征分布”的概念，并设计了一套流程（注意力层 + 分布采样 + Optimal Transport），通过经验分布近似来量化每个节点与无信息参考点的距离。这种构造在理论上由1-Wasserstein距离支撑，能够保证几何可解释性，并提供一种新的 importance learning 视角。

在公式（7）中，那个和 $\mu$ 有关的就看成对应的边类型的强度，是一个scalar。然后针对前面的矩阵乘法，我们可以这样理解，因为是在图上！所**以直接将源点、边、汇点做矩阵乘法看成一个整体是一件非常自然的事情！**（提一嘴：这个操作在考研线代中是很常见的）

公式（9）就是常见的**多头注意力聚合与残差连接**

从偏数学和感性理解的视角自己脑洞了一下 $\mathbf{q}^{\top} W k$ 的可解释性，有时间补充一下。

这里的分布可以这样理解，主要是公式（10）

> 论文不是保留不同来源的单独表达；
>
> 是用一整套 transform（自注意力融合 + 特征抽取），生成一个**最终向量**；
>
> 然后，把这个向量的**每一维特征视为分布上的一个离散点**，形成**经验分布**。
>
> ==这种操作虽然会损失一些信息粒度，但是便于比较==

##### 节点重要性值估算

该部分的核心是：**将经验特征分布转换为节点重要性值（importance value）**。

读完一整遍之后才理解，事实上在公式 (10) 之前，虽然作者**嘴上说着**“为特征分布建模”，但实际上就是在做**高质量节点嵌入学习（representation learning）**。

> 在前面的部分中，我们已经完成了：
>
> - 利用注意力机制学习到每个节点的高维表征向量 hiRh^R_ihiR
> - 将其视为“经验分布”的样本（即：一个高维向量 → 一组样本点）
>
> 接下来，我们要用一个 **统一的、信息稀疏的参考分布 P0P_0P0** 来度量各节点的信息丰富程度（即其 importance）：
>
> > “一个节点的重要性 = 它的分布 PiP_iPi 与无信息参考分布 P0P_0P0 的差异程度”。
>
> 这个差异度是通过 **1-Wasserstein 距离** 来衡量的。

在理解公式时，要注意理解这个概念：**经验==累计==分布函数（Empirical CDF）**

> 你可以认为 $h_i^R$ 是：
>
> $h_i^R = [0.2, 0.5, 0.1, 0.9]$
>
> 把它当作一个"离散样本"，就可以构建经验分布：有 25% 的概率落在每一个点上。
>
> $F_{P_i}(x)$ 就是：
>
> $x<0.1$：返回 0
>
> $0.1 \leq x<0.2$：返回 0.25
>
> $0.2 \leq x<0.5$：返回 0.5
>
> ...
>
> $x \geq 0.9$：返回 1
>
> 它是个分段函数，==**描述这个节点的"语义信息分布"。**==
>
> ### 关键点说明
> 1. **离散样本**：每个值（0.1, 0.2, 0.5, 0.9）被赋予相同的概率权重（25%）。
> 2. **经验 CDF**：  
>    - 在 $x$ 越过每个数据点时，函数值增加 $\frac{1}{n}$（这里 $n=4$），形成阶梯状结构。  
>    - 例如，$F_{P_i}(0.3) = 0.5$，因为有两个样本点（0.1, 0.2）满足 $\leq 0.3$。  
>
> 3. **语义信息分布**：  
>    - **该 CDF 反映了节点特征的统计特性（如数值的集中程度或分散性）**，可用于后续分析（如分布匹配或假设检验）。  
>
> 如果需要进一步应用（如计算分位数或生成新样本），可直接基于此分段函数操作。

把握核心：根据**累积**概率分布反向求对应的**离散值**

* 公式（11）和公式（12）是对 $f^{*}(x \mid \mathbf{h}_i^R)$ 的两种定义，第一种更接近本质，第二种是经过处理之后更加直观的表示：

  公式（12）的意思是，在基准 $\mathbf{h}_0$ 中选择一个元素，得到其在 $\mathbf{h}_0$ 中所有元素按照升序排序的排名，根据这个排名在 $\mathbf{h}_i$ 中找对应的离散值元素

  其中 $\pi(\cdot)$ 表示排序后的元素排名。

  以下是例子：

  > ### **实例数值模拟**
  > 假设：
  > - $\mathbf{h}_0 = [0.1, 0.3, 0.5]$（参考分布），  
  > - $\mathbf{h}_i^R = [1.2, 0.8, 1.5]$（作者表征）。  
  >
  > 1. **排序对齐**：  
  >    - $\mathbf{h}_0$ 排序后排名：$\pi(0.1)=1$, $\pi(0.3)=2$, $\pi(0.5)=3$。  
  >    - $\mathbf{h}_i^R$ 排序后排名：$\pi(0.8)=1$, $\pi(1.2)=2$, $\pi(1.5)=3$。  
  >
  > 2. **分位数匹配**：  
  >    - $f^*(0.1) = 0.8$, $f^*(0.3) = 1.2$, $f^*(0.5) = 1.5$。  
  >
  > 3. **计算 $\mathbf{h}_i^*$**：  
  >    $$
  >    \mathbf{h}_i^*=[0.8−0.1,1.2−0.3,1.5−0.5]=[0.7,0.9,1.0].
  >    $$
  >    
  >
  >    - $\| \mathbf{h}_i^* \|_1 = 2.6 \propto W(P_0, P_i)$。  
  >
  > 4. **重要性值**：  
  >    若学得 $\boldsymbol{\lambda} = [0.4, 0.3, 0.2]$，则：  
  >    $$
  >    g(v_i) = 0.4 \times 0.7 + 0.3 \times 0.9 + 0.2 \times 1.0 = 0.75.
  >    $$
  >
  >    该值反映作者相对于随机基准的重要性。
  >
  > ---
  >
  > ### **实际意义**
  > - **对比其他作者**：若另一作者 $v_j$ 的 $g(v_j) = 0.5$，可推断“Yankai Chen”更重要。  
  > - **跨类型比较**：用相同方法估计论文节点（基于引用分布），与作者重要性在统一尺度下对比。  
  >
  > 通过这一流程，SKES将复杂的异构网络信息转化为可量化的分布距离，实现了可解释的重要性估计。

  最终的 $1$ 范数是对其 $W$ 距离的近似

* 为什么用**Wasserstein距离**

  * **跨分布可比性**：直接比较异构节点（如作者和论文）的原始特征无意义，但转化为与同一参考 $P_0$ 的距离后，所有节点重要性处于**统一量纲**。

  * **几何保持性**：满足三角不等式，确保节点间重要性关系可推理（如 $v_i$ 比 $v_j$ 重要 → $W(P_0,P_i) > W(P_0,P_j)$）。

  * **鲁棒性**：对嵌入的小扰动不敏感（**优于直接回归原始值**）。

    * 传统回归模型（如MLP）可能对每个维度的微小变化都敏感，尤其是存在非线性激活函数时。而使用W距离，最终计算的结果可能会产生偏移，但不会因为某个点的突变而**震荡**

      > **非线性函数本身对输入扰动敏感**
      >
      > 以 ReLU / Sigmoid / Tanh 为例：
      >
      > * **ReLU**：输入从 $−0.0001$ 变到 $+0.0001$，激活值从 0 跳到 0.0001，导致后续梯度从 0 **突然变为正**。
      >
      > - **Sigmoid / Tanh**：在**中间区域梯度很大**，一点点输入扰动就会导致输出值显著变化。
      >
      > 这种非线性的“弯折”特性，意味着输入维度上的微小扰动，在模型内部可能被“**放大**”。
      >
      > 
      >
      > **多层叠加放大扰动**
      >
      > 若某一输入向量发生了变化，那么可能
      >
      > - **通过每一层的权重矩阵**放大（矩阵乘法中的线性组合）
      > - **通过激活函数的曲率**非线性变化
      > - **叠加多层后**，最终造成 **预测值的较大波动
      >
      > 这就是为什么 MLP 的每一维输入都会“带来一条路径”，而这条路径会贯穿整个网络，形成潜在的扰动传播通道。

* 在SKES中本质是**将节点重要性转化为分布搬运成本**，其计算过程通过排序对齐实现高效优化，兼具理论严谨性和计算可行性。



#### 未来工作

作者指出，现有方法主要依赖图神经网络（GNN）和注意力机制进行特征学习，但异构信息网络（HIN）中存在丰富的结构和语义信息，可能需要更先进的学习范式来挖掘。未来计划研究以下方向：对比学习（Contrastive Learning）：通过对比不同节点或子图的特征分布，增强模型对节点差异的捕捉能力，例如借鉴COSTA、Spectral Feature Augmentation等图对比学习方法。主动学习（Active Learning）：结合预期模型变化最大化（Expected Model Change Maximization）等技术，动态选择高价值节点进行标注，提升模型在少样本场景下的性能。生成式模型（Generative Models）：探索如何利用生成式方法（如变分自编码器VAE）建模HIN的复杂分布，生成更具代表性的节点嵌入。

现有HIN通常包含文本、图像、视频等多模态数据（如电影海报、学术论文文本），但SKES目前仅利用了结构和文本特征。未来将重点研究：跨模态特征融合：引入语言模型（如BERT）或视觉模型（如CLIP）处理非结构化数据，例如将电影的视觉海报特征与导演的文本简介结合，提升节点重要性估计的准确性。统一多模态框架：设计能够同时处理异构结构和多模态内容的模型，例如结合图文联合嵌入（Image-Text Embedding）和图神经网络，构建更全面的节点表示。实际应用场景拓展：在电商、社交网络等多模态丰富的领域验证模型，例如融合用户评论（文本）、商品图片（视觉）和交易记录（结构），估计用户或商品的重要性。

动态HIN处理：现有模型假设网络结构静态，但现实中HIN（如社交网络）具有动态演化特性。未来计划引入时序建模（如Temporal GNN）捕捉节点重要性的动态变化。模型效率提升：针对大规模HIN（如DBLP级别的数据），优化模型的计算复杂度，例如通过层次化聚合（Hierarchical Aggregation）或子图采样（Subgraph Sampling）降低计算成本。可解释性增强：虽然SKES通过参考分布和Wasserstein距离提供了一定的可解释性，但未来可进一步引入注意力可视化、特征归因分析（Feature Attribution）等技术，明确结构知识对重要性估计的具体贡献。

作者的未来工作围绕“异构信息深度挖掘”和“多模态融合”展开，旨在解决现有模型在复杂场景下的局限性，推动节点重要性估计技术在实际应用中的落地。这些方向不仅扩展了SKES的适用范围，也为异构网络研究提供了新的思路。



### EASING

* 消融实验中证明了：==引入半监督学习策略，有效提升了模型在标注不足情形下的泛化能力。==

* 最值得被解决的问题是，之前有类似的论文也是用结构信息和语义信息配合 transform 。但不同的是，它是将输出看成高质量的节点嵌入或者节点重要性值，而这篇直接将 transform 的输出认为（表示）成节点分布。凭什么作者想怎么定义就怎么定义？？**我完全摸不着头脑，无法理解。**
  * ==**节点嵌入可以人为定义吗？**具体又该怎么做？怎么设计呢？==

* 个人感觉它这篇论文的做法还是比较偏直觉向的，偏经验向的。而且手段都是一些很常见的东西，比如 transform
  
* 感觉重点还是搞了个**不确定性**来提高创新性，像之前的SKES就搞出了个分布搬运成本
* 均值：度量重要性；方差：度量不确定程度
* 学习并熟练掌握异构图的 transform范式
* 学习并掌握一下半监督学习范式
* **公式（4）与公式（11）给我一种从未知中学习未知的感觉，总之就是很迷...**
* 编码器利用丰富的异构图信息表示节点分布，**解码器利用分布均值和协方差推导目标重要性值和不确定性**（这里面的过程感觉就比较玄学）

#### **摘要**

节点重要性估计是网络分析中的一个经典问题，它是各种网络应用的基础。以往的方法要么利用内在的拓扑特征（如图中心性），要么借助额外信息（如数据**异质性**）来增强节点特征。然而，这些方法都遵循监督学习的设定，忽略了在实际中真实的节点重要性数据通常只是部分被标记这一事实。在这项工作中，我们提出了==**首个半监督节点重要性估计框架 EASING**，以**提高异构图中未标记数据的学习质量**==。与以往方法不同，EASING **明确捕捉不确定性**，以**反映模型预测的置信度**。为了**联合估计重要性值和不确定性**，EASING 采用了 **DJE**，这是一种深度编码器 - 解码器神经架构。DJE 为图节点引入**分布建模**，其中分布表示可导出重要性和不确定性估计。此外，DJE 有助于为未标记数据生成有效的**伪标签**，丰富训练样本。基于标记数据和伪标记数据，EASING **通过不同节点不确定性正则化**，开发了有效的半监督异方差学习方法。在三个真实世界数据集上进行的大量实验突出了 EASING 相较于竞争方法的优越性能。

==初看疑问：1. 半监督学习框架具体是长什么样的；2. 什么是分布建模；3. 如何对未标记数据生成有效的伪标签；4. DJE；5. 公式（4）中的方差 $\sigma^2$ 究竟是怎么得到的==

#### 关键词

节点重要性估计、半监督学习、异构图、网络分析、不确定性正则化

#### 面临的挑战

第一，与真实的节点重要性标签相比，从未标记图节点中学习可能不可避免地引入噪声，使模型优化产生偏差。第二，所研究的问题本质上是回归问题，这意味着预期的伪标签是连续的数值，而不是半监督学习分类问题中可通过阈值函数轻松获得的二元（1/0）标签 [38, 44]。

第一种挑战：**伪标签不准**，本质上是**标签带噪声**问题。

第二种挑战：**任务结构复杂**，本质上是**难以拟合精细标签**的问题。

#### 预备知识点

* 伪标记的不确定性与伪标记重要性值

  * **伪标记不确定性**衡量的是模型对某个未标注样本预测标签的信心程度。简单来说，它描述了模型在给定某个样本时，预测结果的“模糊”程度。一般与**熵**相关。

    **低不确定性：** 当模型预测结果的熵较低时，表明该样本的伪标签可能是可靠的，可以作为训练数据加入；**高不确定性：** 当模型预测结果的熵较高时，表示该样本的伪标签不可靠，应该避免将其用于训练。

  * **伪标记重要性值**衡量的是伪标签样本对模型训练的影响和贡献，通常考虑的是**样本的“信息量”**和该样本在训练中的“重要程度”。

    **高重要性：** 伪标签样本的重要性较高时，模型会更重视这些样本的学习；**低重要性：** 伪标签样本的重要性较低时，模型对这些样本的关注度可以相对减少，避免其对训练造成负面影响。

* 异方差损失项

在传统的线性回归模型中，通常假设误差项的方差是恒定的（即同方差性，homoscedasticity）。然而，在很多实际应用中，误差的方差往往随着预测值或输入特征的变化而变化，表现为不同的输入对应不同的误差波动范围，这就是**异方差性**。

举个例子，假设你在做房价预测，房价在不同区域的波动性可能不同。某些高端区域的房价波动很小，而某些低端区域的房价波动较大。在这种情况下，模型的误差项可能表现出异方差性。

* 半监督学习的通用框架

在**半监督学习（Semi-Supervised Learning）**中，我们通常会为**有标签数据（labeled data）**和**无标签数据（unlabeled data）**分别设计目标函数（objectives），然后把它们结合起来，共同训练模型。

- **有标签数据的目标（labelled objective）**：通常是监督学习中常见的损失函数，如交叉熵损失（Cross-Entropy Loss）、均方差误差，用于指导模型正确分类已有标签的数据。
- **无标签数据的目标（unlabelled objective）**：尽管这些数据没有标签，我们依然可以通过其他方式（如伪标签、自监督任务、平滑性约束等）设计损失函数来利用它们的信息。

最终训练时的总损失函数一般是这两部分的加权和，例如：

$\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{supervised}} + \lambda \cdot \mathcal{L}_{\text{unsupervised}}$



* MC Dropout

可以去了解一下其缩放补偿机制

**Dropout** 是一种防止神经网络过拟合的技术，训练时以一定概率随机“丢弃”神经元（即设置为0）。通常，测试时会关闭 Dropout，使用全连接的网络。

**Monte Carlo** 是一种统计方法，通常指**“通过多次随机采样来估计某个量”**。

将两者结合：**MC Dropout = 在测试时也启用 Dropout + 多次前向传播取平均**

> 在训练时，Dropout 是为了正则化，防止过拟合；而在测试时保留 Dropout，是为了引入不确定性，从多个子网络采样，近似贝叶斯推断。



> ### 🧠 MC Dropout 的核心思想
>
> 1. 在训练时，使用常规的 Dropout。
> 2. 在测试时，**保留 Dropout**（通常是关闭的）。
> 3. 对同一输入数据，进行 **多次前向传播**（比如 50 次），因为 Dropout 是随机的，每次会“看见”不同的网络子结构。
> 4. 将这些预测结果：
>    - **取平均**，作为最终预测值。
>    - **计算方差**，作为预测的“不确定性”。



> ### 📚 展开解释：
>
> #### ✅ **训练时 Dropout 的作用：**
>
> - **目的**：防止网络对训练数据过拟合。
> - **方式**：每个 batch 随机丢弃部分神经元，让模型学会在“信息不完整”的情况下也能做出预测。
> - **测试时**：我们一般**关闭 Dropout**，用全连接网络预测，得到最强的模型输出。
>
> #### 🧠 **测试时保留 Dropout 的作用（MC Dropout）：**
>
> - **目的**：模拟从多个模型中采样，从而估计模型预测的“不确定性”。
> - **方式**：
>   - 保留 Dropout，使每次前向传播都**使用不同**的“子模型”。
>   - 多次前向传播，得到一组预测结果。
>   - 取平均值作为最终预测，取方差表示预测的不确定性。
> - **这是在做贝叶斯推断的一种近似**，称为：**Bayesian approximation via Dropout**（Yarin Gal, NeurIPS 2016）。
>
> ------
>
> ### 🧪 为什么**不是在训练时做 MC Dropout**？
>
> - 训练阶段你只有一次前向传播，并不能通过多次采样获得一个“预测分布”。
> - 训练阶段的 Dropout 是用来“扰动模型”，而不是采样。
> - 不确定性估计是**对测试结果的评估**，必须在**测试阶段进行多次采样**，才有意义。



#### 工作概览

（1）EASING 明确考虑了 “**不确定性**” 这一概念，以此表明对模型预测的置信度。在这项工作中，不确定性**仅由图节点信息决定**，不考虑外部因素。然后，我们利用估计出的不确定性对自监督学习过程进行**正则化**。与传统的同方差设定（每个数据样本对损失累积的贡献相同）不同，我们的半监督异方差学习范式根据节点样本的不确定性为其分配不同的权重。（2）为了联合估计**重要性值**及其**相关的不确定性**，我们提出了一种有效的深度神经网络，即**基于分布的联合估计器**（DJE）。DJE **基于每个图节点都遵循随机分布这一假设**，这一假设在自然融入不确定性的同时，为聚合图信息提供了灵活性。==DJE 采用编码器 - 解码器结构，其中编码器捕捉丰富的异构图信息以表示节点分布，而解码器则利用分布均值和协方差来推导目标重要性值和不确定性。==（3）鉴于我们问题中的标签是数值格式，我们为未标记数据生成节点重要性和不确定性的伪标签对。这是通过**变分推理**直接整合 DJE 的预测来实现的。我们还进一步分析了生成的伪标签的质量。如图 1 所示，通过同时利用真实的标记数据和构建的伪标记数据，EASING 有助于更有效地进行模型训练。

工作的贡献：

- 我们提出了带不确定性正则化的 EASING 框架。据我们所知，这是**首个**针对**异构图**中**节点重要性**估计的**半监督**学习研究。
- 我们提出了 DJE，这是一种**编码器 - 解码器**神经架构。其一，它能进行有信息的分布建模，以联合估计重要性值和不确定性；其二，它有助于有效地生成伪标签。
- 在三个被广泛研究的真实世界数据集上进行的大量实验，证明了我们的 EASING 框架及其组成模块的有效性。



#### 对模型/公式的理解

##### 公式（4）/不确定性正则化数据学习（repeat）

> 公式（4）是论文中提出的**不确定性正则化的半监督损失函数**，用于处理未标记数据（unlabeled data）的优化问题。其具体形式如下：
>
> $$
> \mathcal{L}^{unlb} = \frac{1}{|\mathcal{D}'|} \sum_{x' \in \mathcal{D}'} \left( \frac{(s_{x'}^+ - \widehat{s}_{x'})^2}{2\sigma_{x'}^2} + \frac{\ln \sigma_{x'}^2}{2} \right)
> $$
>
> **公式组成解析**
>
> 1. **第一项：加权平方误差**
>    - $(s_{x'}^+ - \widehat{s}_{x'})^2$：这是伪标签$s_{x'}^+$（通过模型生成的未标记数据的预测值）与模型当前预测值$\widehat{s}_{x'}$之间的平方误差。
>    - $\sigma_{x'}^2$：表示节点$x'$的**不确定性**（方差），用于衡量模型对该节点预测的置信度。不确定性越高，$\sigma_{x'}^2$越大。
>    - **作用**：通过$\sigma_{x'}^2$对误差项进行加权。不确定性高的节点（$\sigma_{x'}^2$大）对损失的贡献较小，反之则贡献较大。这种设计使得模型**更关注高置信度的预测**。
>
> 2. **第二项：不确定性正则化**
>    - $\ln \sigma_{x'}^2$：对不确定性取对数，防止$\sigma_{x'}^2$无限增大或减小。
>    - **作用**：平衡第一项的加权效果。若仅最小化第一项，模型可能倾向于将$\sigma_{x'}^2$设为无穷大以**规避误差惩罚**；而第二项通过$\ln \sigma_{x'}^2$约束$\sigma_{x'}^2$的取值，**确保不确定性保持合理范围**。（~~**事实上，这里取对数我感觉是扩大了方差的效果，即放大了不确定性的效果**~~）
>
> **设计动机**
>
> 1. **异方差性（Heteroscedasticity）**  
>    传统均方误差（MSE）假设所有样本的噪声相同（同方差），但实际中不同节点的预测难度不同。公式（4）通过$\sigma_{x'}^2$显式建模异方差性，动态调整样本权重。
>
> 2. **伪标签的噪声处理**  
>    未标记数据的伪标签$s_{x'}^+$可能包含噪声。通过不确定性$\sigma_{x'}^2$，模型能自适应降低噪声标签的权重，减少其对训练的负面影响。
>
> 3. **与监督学习的区别**  
>    对比公式（2）的MSE损失，公式（4）引入了不确定性，形成**不确定性感知的回归目标**，更适用于半监督场景。
>
> **实际意义**
>
> - **高不确定性节点**：$\sigma_{x'}^2$较大，$\frac{1}{\sigma_{x'}^2}$较小，损失函数中误差项的权重降低，模型对其关注减少。
> - **低不确定性节点**：$\sigma_{x'}^2$较小，误差项权重增大，模型**更**专注于优化这些高置信度预测。
>
> **示例**
>
> 假设两个未标记节点：
> 1. 节点A：$\widehat{s}_A=3.0$, $s_A^+=3.2$, $\sigma_A^2=0.1$  
>    损失项：$\frac{(0.2)^2}{2 \times 0.1} + \frac{\ln 0.1}{2} = 0.2 - 1.15 = -0.95$（注意：实际优化中会避免负值，此处仅为示意）
> 2. 节点B：$\widehat{s}_B=5.0$, $s_B^+=5.5$, $\sigma_B^2=1.0$  
>    损失项：$\frac{(0.5)^2}{2 \times 1.0} + \frac{\ln 1.0}{2} = 0.125 + 0 = 0.125$
>
> 虽然节点B的绝对误差更大，但由于其不确定性高，最终对总损失的贡献反而小于节点A。（即B由于不确定性高，模型对B的关注会更少）
>
> **总结**
>
> 公式（4）通过**不确定性加权**和**正则化项**，实现了：
> 1. 对未标记数据的自适应学习，抑制低质量伪标签的影响。
> 2. 与DJE模型结合（公式17输出的$\widehat{z}_x$即$\sigma_{x'}^2$），形成端到端的半监督回归框架。

##### 基于分布的联合估计器

我们的目标是给定一个异构图，我们的目标是**通过分布建模联合估计节点重要性值及其相关的任意不确定性**。

为什么公式（11）可以学习到均值与协方差？？太玄幻。



##### 如何理解公式（11）

这里的计算很迷啊。。。

$S_x$ 和 $U_x$ 分别表示均值分别和协方差表示，我们需要通过它们来分别估计节点的重要性与不确定性。

主要还是理解它们的shape？只看公式貌似可以感觉 $S_x$ 和 $U_x$ 是一个向量 $(1, 2d)$ 但是看后面的解码器部分又发现肯定不是向量？？？？？我只能将 $\alpha^{\top}_s$ 理解成一个 $1 \times 2d$ 的向量，但是不是做矩阵乘法操作，而是做逐元素相乘，这样得到的还是一个 $N \times 2d$ 的张量。从代码的实现来看，我的推测是正确的，代码中实际保留了 `token` 粒度的输出。



公式（13）是很经典的操作，层归一化配合残差连接，中间使用一个网络（前馈神经网络或者DSA），这些网络我们可以根据需求与目标自定义，但是这个框架是很经典的。对于其的思考已经记录在论文与技术哲思中。



* 理解并且感受下 DL 中的编码与解码操作

  虽然 decoder 不是“还原”，但它确实是在基于编码结果生成**另一种形式的输出**，这种模式被借鉴到各种任务中。

  > ### 2. **在 EASING 中的用法：**
  >
  > - Encoder 负责**提取复杂信息**（结构 + 文本），生成富表达的节点表示（distribution embedding）
  > - Decoder 则利用这些表示，**进一步构造输出目标**（importance + uncertainty）

  * 与 transform 有关的这些编码解码的框架都非常的典



##### 如何理解公式（18）

我想表达的意思是为什么要使用两个 DJE （DJE1 与 DJE2） 而不是一个或者多个。（其实跟我的猜想差不多...）

> 如果只使用一个 DJE（即只用一组权重 + dropout mask）：
>
> - MC Dropout 只能靠 **mask 多样性** 来提供采样；
> - 多样性会较低，估计的伪标签方差不稳定；
> - 不容易模拟贝叶斯后验分布。
>
> 而使用两个独立 DJE：
>
> - 从结构和参数初始上就强制了模型之间的“采样多样性”；
> - 提高了集成伪标签的泛化性和鲁棒性。
>
> **为什么不是三个或更多 DJE？**
>
> 可以，但：
>
> - 成本上不划算（内存 + forward 时间成倍增长）；
> - 两个 + 多次 forward（T 次）已经可以拟合高质量的分布；
> - 论文设计在效率和性能之间做了合理折中。
>
>  **总结一句话：**
>
> > 论文中公式（18）中的 DJE1 和 DJE2 是为了 **实现变分推理（variational inference）中的模型不确定性估计**。它们作为独立的 dropout 模型，用于多次 forward 集成伪标签，是 **贝叶斯深度学习（MC Dropout）在图回归任务中的经典做法**，从而提升伪标签质量与泛化能力。

* 自监督异方差回归
  * 未标记节点的 ground truth 是未知的，这使得预测具有挑战性。因此，我们要想办法获得伪标签：比如说：节点重要性值与不确定性



##### 自监督异方差回归

> ### 📌 背景
>
> 对于未标注节点 x′∈D′x' \in D'x′∈D′，没有真实的节点重要性值（importance score），所以需要先“猜测”一个伪标签 —— 即预测值和其不确定性。
>
> ### 📌 方法
>
> 他们使用了 **变分推断（Variational Inference） + 模型集成（Ensemble）** 的思想：
>
> 1. 利用两个结构相同但独立初始化的 DJE 模型（即 DJE1 和 DJE2）；
> 2. 在它们都采用 **Monte Carlo Dropout**（MC Dropout）机制的前提下，对每个未标注节点执行 TTT 次前向预测；
> 3. 每个模型会输出预测值 s^x′,i<t>\hat{s}^{<t>}_{x',i}s^x′,i<t> 和不确定性 z^x′,i<t>\hat{z}^{<t>}_{x',i}z^x′,i<t>；
> 4. 最后对所有预测取平均得到：
>    - **伪重要性标签** sx′+s^+_{x'}sx′+：两个模型的 TTT 次预测均值；
>    - **伪不确定性标签** zx′+z^+_{x'}zx′+：两个模型输出的不确定性均值。
>
> ### ✅ 优点
>
> - 利用 dropout 采样避免单一预测的偏差；
> - **模型集成增强伪标签鲁棒性；**
> - 附带一个 **定理证明**（Theorem 1）：集成后的伪标签相比单个模型具有更低的期望误差。（公式 （20））



公式（18）：都采用**Monte Carlo Dropout**（MC Dropout）机制的前提下，对每个未标注节点执行 $T$ 次前向预测（需要注意的是，在训练时，前向传播一般都只有一次）；



> 🔹4.3.2 Self-supervised Heteroscedastic Learning Objective（异方差自监督目标）  
> 在获得伪标签后，接下来就是设计一个自监督回归损失函数，该损失函数要能同时处理：  
>
> - 多个预测值（来自不同模型或不同 dropout 样本）；  
> - 每个预测的不确定性；  
>
> 📌 **异方差回归损失函数定义**：  
> 对于每个伪标记节点 $x'$，其损失为：  
>
> $$
> L_{\text{unlabeled}}^{\text{reg}} = \frac{1}{|D'|} \sum_{x' \in D'} \sum_{i=1}^{2} \left( \frac{(s_{x'}^+ - \hat{s}_{x',i})^2}{2 \exp(\hat{z}_{x',i})} + \frac{\hat{z}_{x',i}}{2} \right)
> $$
>
> **解释如下**：  
> - $s_{x'}^+$：伪重要性值（构造的**伪标签**）；  
> - $\hat{s}_{x',i}$：模型 $i$ 的预测值；  
> - $\hat{z}_{x',i}$：模型 $i$ 的预测不确定性；  
> - 使用 $\exp(\hat{z})$ 保证方差始终为正。  
> - 这里体现了异方差的建模
> - 注意：这里的伪重要性值以及模型的预测值、不确定性分别是通过公式（19）与（18）得到的。后者是经过平均得到的伪标签，前者则是通过编码、解码器得到的输出。
>
> 📌 **不确定性稳定损失（Regularization）**  
> 他们还引入了一个辅助目标：  
>
> $$
> L_{\text{unlabeled}}^{\text{stab}} = \frac{1}{|D'|} \sum_{x' \in D'} \sum_{i=1}^{2} (z_{x'}^+ - \hat{z}_{x',i})^2
> $$
>
> 目的是鼓励模型预测的 **不确定性估计** 尽量靠近伪不确定性标签，从而稳定学习过程。  
>
> 🔸**最终的自监督目标函数**  
> 结合两个部分的损失：  
>
> $$
> L_{\text{unlabeled}} = L_{\text{unlabeled}}^{\text{reg}} + L_{\text{unlabeled}}^{\text{stab}}
> $$
>
> 此外，对于有标签的数据，他们也用异方差回归损失（第 4.3 最后）：  
>
> $$
> L_{\text{labeled}}^{\text{reg}} = \frac{(s_x - \hat{s}_x)^2}{2 \exp(\hat{z}_x)} + \frac{\hat{z}_x}{2}
> $$
>
> 再加上不确定性一致性损失：  
>
> $$
> L_{\text{labeled}}^{\text{stab}} = (\hat{z}_{x,1} - \hat{z}_{x,2})^2
> $$
>
> 最终整个训练目标为：  
>
> $$
> L = L_{\text{labeled}}^{\text{reg}} + L_{\text{labeled}}^{\text{stab}} + \lambda (L_{\text{unlabeled}}^{\text{reg}} + L_{\text{unlabeled}}^{\text{stab}})
> $$
>
> 🧠 **总结亮点**  
> | 项目             | 描述                                              |
> | ---------------- | ------------------------------------------------- |
> | **伪标签**       | 利用 MC dropout + 模型集成来提高标签可信度        |
> | **不确定性建模** | 显式预测并用 log-variance 表达 aleatoric 不确定性 |
> | **异方差回归**   | 不确定性越高，损失越小，从而降低噪声伪标签影响    |
> | **自监督机制**   | 用预测值自身作为监督信号，不依赖额外标签          |
> | **正则项**       | 限制模型预测的方差不要漂移太远，增加稳定性        |



##### 如何理解公式（22）

自己的想法：我先看这个公式，显然它在让 $\hat{z}_{x',i}$ 更加靠近它们的标签（文中是使用平均值表示的），所以从宏观上看，这个公式是让每个节点的不确定性值更快地到达其在该模型多集成下输出的平均值，所以这个公式的目的其实是在让模型更加加速收敛？

> 公式（22）**不是直接为了“加速收敛”**，而是为了：
>
> **减少不同模型之间的不确定性估计偏差，提高伪标签的稳定性和鲁棒性，从而在训练中更快找到稳定的“uncertainty anchor”**。
>
> 它本质上是一种 **模型一致性正则（model consistency regularization）**，间接帮助训练更稳定和高效。



为什么说不确定性的预测是很脆弱的？

> 🎯 你的质问是：  
> 凭什么说“不确定性的预测是很脆弱的”？有没有理论依据或经验支撑？  
>
> ---
>
> ### ✅ 1. 定义先行：什么是不确定性预测？  
> 在机器学习中，**不确定性（uncertainty）预测**通常分为两类：  
> - **Aleatoric uncertainty**：数据本身存在噪声（不可避免，比如图像模糊、label 不准确）；  
> - **Epistemic uncertainty**：模型知识不足产生的不确定性（例如样本在训练分布之外，模型不确定该怎么判）。  
>
> EASING 中建模的是 **Aleatoric uncertainty**，即通过输出一个 $\hat{z}_x$ 表示每个样本预测的“可靠程度”。  
>
> ---
>
> ### ✅ 2. 为什么不确定性预测容易不稳定？  
> 这是有**理论依据 + 实证支持**的，我们逐条解释：  
>
> #### 📌 原因 1：不确定性没有 ground-truth 指导，学习目标“间接”  
> - 你知道 $y$ 是什么（监督目标），但你不知道“这个预测应该有多不确定”；  
> - 模型只能通过间接信号（如残差、dropout variance）去学；  
> - 所以训练更依赖于损失函数设计和伪标签质量。  
>
> #### 📌 原因 2：不确定性是函数输出的“高阶函数”  
> 在回归中，我们通常用如下 loss 来预测均值和不确定性（如下是异方差回归 loss）：  
> $$
> L = \frac{1}{2\hat{z}_x^2}(y - \hat{s}_x)^2 + \log \hat{z}_x
> $$
> 这里 $\hat{z}_x$ 是乘在 loss 分母上的！  
> - 一旦估计偏了，就会造成 loss 被极大放大或缩小；  
> - 所以对训练过程极其敏感，常出现“震荡”“爆炸”“不收敛”现象。  
>
> **可参考文献**：  
> - Kendall & Gal, *What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?*, NeurIPS 2017  
> - Ilg et al., *Uncertainty Estimates for Optical Flow with CNNs*, CVPR 2018  
>
> #### 📌 原因 3：MC Dropout 本身就带来方差  
> 在论文中：  
> - DJE 使用 dropout 来做 epistemic 采样；  
> - 但 dropout 是随机的 → 多次 forward 会带来输出波动；  
> - 所以对不确定性输出 $\hat{z}$ 的估计带有“结构波动”，需要正则化一致性来稳定。  
>
> #### 📌 原因 4：小样本下，方差估计天然不稳定  
> - 不确定性估计本质上是“对方差的建模”；  
> - 但方差需要多个样本才能准确估计；  
> - 如果样本太少（尤其在图中每个节点邻居有限），就容易估计不准；  
> - 此时加一个正则项约束模型收敛方向是一种有效补救手段。  
>
> ---
>
> ### ✅ 3. 实际经验支持（来自多个任务）  
> 不确定性预测广泛用于以下任务中，而**稳定性约束几乎都是标配**：  
> - 半监督学习（FixMatch, Mean Teacher）  
> - 贝叶斯回归（MC Dropout）  
> - 医学图像预测（病变分类时估计置信度）  
> - 交通预测（输出不确定性来衡量风险）  
>
> 在这些任务中，不加一致性损失或温度平滑，都会导致不确定性预测震荡大、精度下降。  
>
> ---
>
> ### ✅ 结论总结：  
> 不确定性的预测被认为是“脆弱的”，不是拍脑袋说的，而是：  
> 1. 缺乏直接监督信号；  
> 2. 对训练动态高度敏感；  
> 3. 数学结构决定其易震荡（尤其乘在 loss 分母上）；  
> 4. 实践中反复验证需要额外一致性正则化来稳定训练过程。  
>
> 所以，EASING 采用公式（22）去拉近不同 forward 下的不确定性输出，是一个合理且常见的手段。



#### 实验部分

==文章指出：对于所有竞争模型，我们要么直接遵循其官方参数设置，要么在设置不可用时应用网格搜索。（换句话说，如果能找到模型的官方设置，直接用；否则直接网格搜索）==

Wilcoxon符号秩检验

##### 消融实验（RQ3）

==重点是第三部分：引入半监督学习策略，有效提升了模型在标注不足情形下的泛化能力。==

> ## ✅ 两种训练方式的对比实验：
>
> ### ① **有监督实验（w/o SSIL）**
>
> - **训练数据**：仅使用**有标签的节点（labeled data）**进行训练；
> - **目标**：最小化有标签节点的重要性值预测误差（如 MSE + 不确定性正则）；
> - **不使用**伪标签、不使用无标签数据；
> - 就是一个标准的 supervised learning。
>
> ------
>
> ### ② **半监督实验（完整的 EASING）**
>
> - **训练数据**：
>   - 使用**有标签的数据**；
>   - 额外加入大量**无标签的数据**；
> - **做法**：
>   - 使用模型（DJE）对无标签节点生成**伪标签（重要性值 + 不确定性）**；
>   - 利用伪标签作为弱监督信号，引入这些无标签节点参与训练；
>   - 同时优化有标签数据损失 + 无标签数据损失；
> - 是典型的 semi-supervised learning。
>
> ------
>
> ### 🧪 **评估方式：统一在同一个有标签测试集上测试**
>
> - 无论是哪个训练策略，最后都用同一个 **有标签的测试集** 来评估性能；
> - 比较模型在真实 ground-truth 标签上的表现（如 MAE、NRMSE、Spearman等）；
> - 看看 **是否使用 unlabeled data** 能带来更好的泛化能力。





> 论文的 **第 5.4 节（Ablation Study，消融实验）** 主要围绕研究问题 **RQ3** 展开：
>
> > **各模块组件在 EASING 中的作用有多大？**
>
>  **5.4 Ablation Study（消融实验）**
>
> 该部分通过逐一移除 EASING 模型中的关键组件，构建四个变体，对模型在 FB15K 数据集上的表现进行了评估。表 5 汇报了各变体的性能（包括 MAE、RMSE、NRMSE、SPEARMAN、Precision 和 NDCG），并与完整模型对比，得出以下分析结论：
>
> ------
>
> #### **(1) w/o DJE-Encoder**
>
> - **去掉 DJE 编码器**，即不使用其结构建模 distribution 表征，仅用初始特征直接建模。
> - **性能大幅下降**：如 RMSE 增加约 90.53%，SPEARMAN 降低 31.53%。
> - 🔍 **说明：DJE-Encoder 是核心组件，它对拓扑与文本特征进行编码，对于有效建模分布（进而估计重要性与不确定性）至关重要。**
>
> ------
>
> #### **(2) w/o DJE-Decoder**
>
> - **将 DJE 解码器替换为简单的线性层**输出重要性值和不确定性。
> - 性能有所下降，表现为 RMSE 提升约 2%，SPEARMAN 下降约 2.38%。
> - 🔍 **说明：DJE-Decoder 的结构更适合捕捉复杂的分布表征，进而提高估计质量。**
>
> ------
>
> #### **(3) w/o SSIL（Semi-Supervised Importance Learning）**
>
> - **去掉伪标签生成与无标签数据的学习部分**，仅基于有标签样本进行训练。
> - 性能下降较明显：RMSE 增加约 4.29%，SPEARMAN 下降 3.26%。
> - 🔍 **说明：引入半监督学习策略，有效提升了模型在标注不足情形下的泛化能力。**
>
> ------
>
> #### **(4) w/o AST（Auxiliary Scaling Trick）**
>
> - **移除辅助缩放策略（AST）**，该策略用于调节预测重要性的数值范围。
> - 性能略有下降，影响相对较小。
> - 🔍 **说明：AST 有一定辅助作用，尤其在提升最终预测表现方面；但其可选性较强，影响主要体现在效果边界优化上。**
>
> ✅ **总结**
>
> 5.4节通过消融实验明确展示了：
>
> - **DJE-Encoder 是最关键的模块**，其删除将导致性能崩塌；
> - DJE-Decoder 和 SSIL 模块对性能提升也非常重要；
> - AST 作为可选模块，提升效果虽小但稳健。
>
> 这些结果共同验证了 **EASING 的设计合理性与模块协同效应**。



##### EASING的实证分析（RQ4）从可扩展性、模型兼容性和超参数敏感性等角度，EASING 的表现如何？

**目的**：考察 EASING 在不同标签数量下的鲁棒性和可扩展性。

**针对5.5.1，可以这样理解：一般来讲，标签越多越好。但是随着标签数据的减少，SKES可利用的资源相对变少，性能下降。而EASING可利用的资源不变（没有标签的数据可以生成伪标签），虽然性能也在下降，但是下降缓慢，且显存占用较稳定。所以SKES的优势更大**

> 论文的 **第 5.5 节（Empirical Analyses of EASING）** 主要围绕研究问题 **RQ4** 展开：
>
> > **RQ4：从可扩展性、模型兼容性和超参数敏感性等角度，EASING 的表现如何？**
>
> 该部分从三个维度进行分析：**可扩展性（scalability）、兼容性（compatibility）、超参数敏感性（hyper-parameter sensitivity）**，如下所述：
>
> ------
>
> ## 🧩 5.5.1 Scalability with Varying Labeled Data Ratio
>
> 🔍 **目的**：考察 EASING 在不同标签数量下的鲁棒性和可扩展性。
>
> ### 实验设置：
>
> - 控制变量：逐步减少训练集中的标签比例（从 100% 降到 10%）。
> - 对比模型：
>   - **EASING**（半监督）
>   - **SKES**（监督学习，当前最先进的 baseline）
>
> ### 实验结果（见图 4(a)、(b)）：
>
> - **EASING 的性能下降更缓慢**，在标签变少的情况下依然保持较高准确性；
> - 对比 SKES，EASING 更鲁棒，验证了其半监督学习机制在标签不足时的优势。
>
> ### 训练资源消耗（图 4(c)）：
>
> - **训练时间**随着标签减少而减少；
> - **显存占用较稳定**，说明 EASING 的空间复杂度与样本数无强相关。
>
> ✅ **结论**：
>
> > EASING 对标签缺失有较强容错能力，同时资源开销可控，具有较好的可扩展性。
>
> ------
>
> ## 🧩 5.5.2 Compatibility to Other Models
>
> 🔍 **目的**：验证 EASING 的半监督框架是否能增强其他已有模型的性能。
>
> ### 实验设置：
>
> - 在现有模型（如 **RGTN** 和 **SKES**）中加入 EASING 的伪标签生成 + 不确定性回归机制。
> - 即保留原始模型的嵌入部分，**替换掉输出头（regression head）为 EASING 结构**。
>
> ### 实验结果（见表 6）：
>
> - RGTN + EASING 提升 RMSE 从 1.0586 → 1.0227（↑3.51%）
> - SKES + EASING 提升 RMSE 从 1.0248 → 1.0103（↑1.41%）
>
> ✅ **结论**：
>
> > EASING 框架具有很强的==**可移植性和通用性**==，能有效增强其他 GNN 模型。
>
> ------
>
> ## 🧩 5.5.3 Hyper-parameter Sensitivity
>
> 🔍 **目的**：研究模型对超参数变化的敏感程度。
>
> - 本节简要提及该实验，详细内容放在了**附录 C.4**；
> - 主要评估了超参数（如学习率、dropout、伪标签数量等）对模型性能的影响；
> - EASING 在大多数参数区间内表现稳定，无明显震荡。
>
> ✅ **结论**：
>
> > EASING ==对超参数不敏感，训练过程稳定，易于部署和调参。==
>
> ------
>
> ## ✅ 总结：5.5节讲了什么？
>
> > 该节系统分析了 EASING 的**实用性**和**可落地性**，表明它不仅在性能上领先，还具备：
>
> - **强适应性**（对标签数量、模型结构、参数配置都不敏感）；
> - **良好扩展性**（数据少也能训、计算资源友好）；
> - **兼容性强**（可与其他图模型融合使用）。
>
> 如果你对其中某一子实验（如如何把 EASING 嵌入 SKES 中）感兴趣，我可以帮你详细拆解实现方式。





#### 实验复现

##### 实验数据

就是 `LICAP` 的实验数据

探究代码可以得到，代码以及论文所描述的其实不是处理真正的异构图！**不是直接处理 DGL 的“异构图”（`dgl.heterograph`）**，但它可以处理**有边类型（edge types）或边特征（edge_feat）的同构图**。例如：

```python
# 所有节点类型一样，但边有不同关系（用 edge_feat 表示）
g = dgl.graph(...)
edge_feat = relation_embedding[edge_types]  # 每条边有一个关系向量
```

若要真正处理 DGL 的 **异构图结构（多个节点/边类型）**，则需使用 `dgl.nn.HeteroGraphConv` 等组件。而这段代码**假设图已经是统一结构，只是每条边有关系嵌入**，因此**属于“伪异构”处理或“同构图 + 多关系”处理**。

| 项目                           | 内容                                                       |
| ------------------------------ | ---------------------------------------------------------- |
| **是否处理异构图？**           | ✅ 是的，数据本质上是异构图，含不同类型节点和边             |
| **是否进行严格的异构图建模？** | ❌ 否，未使用专门的异构图网络（如 R-GCN、HAN、MAGNN）       |
| **采用的方式**                 | ✅ 使用边类型嵌入参与注意力计算，对异构性建模做了“轻量”处理 |
| **是否可归类为“异构图方法”？** | ✅ 可以，但是“简化建模”的方式，未追求高度结构性异构建模     |

==**论文《EASING》只建模了“边的异构性”，但没有显式利用“节点的异构性”**。==从所给的数据也可以看出，这里的图对节点的类型是统一看待的，但是边具有不同的类型。



##### BUG

* 在阅读代码的过程中发现了一点问题，论文中的公式（6）采用的是 `LN` 但是给出的代码使用的却是 `BN`

* ~~在代码中的 `model.py` 文件中第138行开始的 `forward()` 模块中，计算 `s` 和 `u` 的代码应该是错了（不健壮），推荐~~（代码没有问题，我的了我二逼了）

* 感觉这个工作的 `shape` 是不是不太合理：在 `model.py` 中 `DJE_layer` 中的 `forward` 模块中。**直接 `reshape` 会把原本处于同一 `N` 维度上的数据变成处于不同 `N` 维度上的数据**，**这会破坏 `token` 间结构的独立性**

  ```python
  qs = self.w_qs(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim)
  ```

  感觉应该是

  ```python
  qs = self.w_qs(s).view(s.shape[0], s.shape[1], self.heads_num, self.heads_dim)	# (B, N, H, D')
  qs = qs.permute(0, 2, 1, 3)		# (B, H, N, D')
  ```

  经过与 AI 对话，这里的做法确实是不太严谨。

  如果是这样的话，那么感觉最后 `reshape` 回去的操作也不合理

  ```python
  ua_s_attn = torch.matmul(qs / self.sqrt_d, ks.transpose(-2,-1)) # [B, heads_num, N, N]
  ua_s_attn = F.softmax(ua_s_attn,dim=-1) # [B, heads_num, N, N]
  ua_s = torch.matmul(ua_s_attn, vs).view(s.shape[0],s.shape[1],s.shape[2]) # [B, N, 2d]
  ```

  应该是这样：

  ```python
  # 计算多头注意力
  ua_s = torch.matmul(ua_s_attn, vs)  # [B, heads_num, N, heads_dim]
  
  # 先 transpose 回 [B, N, heads_num, heads_dim]，再合并
  ua_s = ua_s.transpose(1, 2).contiguous()  # [B, N, heads_num, heads_dim]
  ua_s = ua_s.view(B, N, -1)  # [B, N, heads_num * heads_dim] = [B, N, in_dim]
  ```

  

* 感觉在 `main_easing.py` 这个文件中的

  ```python
  loss_cmb_cps_0 = 0.5 * (torch.mul(torch.exp(-avg_var01), loss_mse_cps_0) + avg_var01 )
  loss_cmb_cps_1 = 0.5 * (torch.mul(torch.exp(-avg_var01), loss_mse_cps_1) + avg_var01 )
  ```

  这部分代码貌似错了，根据公式21，应该是

  ```python
  loss_cmb_cps_0 = 0.5 * (torch.mul(torch.exp(-var1s_0_), loss_mse_cps_0) + var1s_0_ )
  loss_cmb_cps_1 = 0.5 * (torch.mul(torch.exp(-var1s_1_), loss_mse_cps_1) + var1s_1_ )
  ```

  

##### 注意点与一些疑问

* `nn.Dropout` 是逐元素操作，与数据的维度没有什么关系

* `nn.BatchNorm1d`：是 PyTorch 中用于 **一维特征的批归一化（Batch Normalization）** 的模块，主要用于处理形状类似于 `[batch_size, num_features]` 或 `[batch_size, num_channels, length]` 的数据。**形状保持不变**。

* 对比比较 `BatchNorm1d` 与 `LayerNorm`，尤其是要理解归一化的维度

  | 比较点                    | **BatchNorm**（`BatchNorm1d`）                    | **LayerNorm**                                 |
  | ------------------------- | ------------------------------------------------- | --------------------------------------------- |
  | **归一化维度**            | **跨样本（batch）维度**，对每个 **特征维** 归一化 | **跨特征维**，对每个 **样本/节点** 独立归一化 |
  | **举例**（输入 `[B, D]`） | 对每一列特征 `D` 做标准化（跨 batch 维）          | 对每一行样本做标准化（跨 D）                  |
  | **是否依赖 batch size**   | ✅ 是（小 batch 可能不稳定）                       | ❌ 否（和 batch size 无关）                    |
  | **统计方式**              | `mean/std` 是 **在 batch 中统计**的               | `mean/std` 是 **在样本内部**统计              |

* 会使用 `dgl` 库的常用操作
  * `graph.dstdata.update({})` 与 `graph.srcdata.update({})`
  * `graph.apply_edges()`
  * `fn.u_dot_v()`
  
* 为什么 `DJE` 解码的中间处理过程要进行分头操作呢？直接计算不好吗？我做了一下实验。

  1. 第一组，就是论文中写得代码，个人感觉没有正确的 `reshape`
  2. 第二组，应该是最标准的写法，正确 `reshape`之后 + 多头处理
  3. 第三组，正确 `reshape` 但是并没有多头处理

  附上验证时的珍贵代码

  ```python
  import torch
  import torch.nn as nn
  import torch.nn.functional as F
  
  class DJE_layer(nn.Module):
      def __init__(self,
                  in_dim,
                  heads_num
                  ):
          super(DJE_layer, self).__init__()
          self.in_dim = in_dim
          self.sqrt_d = in_dim ** 0.5
  
          self.heads_num=heads_num
          self.heads_dim= int(self.in_dim / self.heads_num)
  
          # self.sqrt_head_d = self.heads_dim ** 0.5
  
          
          self.w_qs = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          self.w_ks = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          self.w_vs = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          
          self.w_qu = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          self.w_ku = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          self.w_vu = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim, bias=False),
              nn.ELU(inplace=True)
              )
          
          
          
          self.FFN_s = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim*2),
              nn.ELU(inplace=True),
              nn.Linear(self.in_dim*2, self.in_dim),
              nn.ELU(inplace=True)
          )
          
          self.FFN_u = nn.Sequential(
              nn.Linear(self.in_dim, self.in_dim*2),
              nn.ELU(inplace=True),
              nn.Linear(self.in_dim*2, self.in_dim),
              nn.ELU(inplace=True)
          )
          
          self.layer_norm_s_1 = nn.LayerNorm(self.in_dim, eps=1e-6)
          self.layer_norm_s_2 = nn.LayerNorm(self.in_dim, eps=1e-6)
          
          self.layer_norm_u_1 = nn.LayerNorm(self.in_dim, eps=1e-6)
          self.layer_norm_u_2 = nn.LayerNorm(self.in_dim, eps=1e-6)
          
      def forward(self, s, u):
          qs = self.w_qs(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          ks = self.w_ks(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          vs = self.w_vs(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          
          qu = self.w_qu(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          ku = self.w_ku(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          vu = self.w_vu(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
          
          ua_s_attn = torch.matmul(qs / self.sqrt_d, ks.transpose(-2,-1)) # [B, heads_num, N, N]
          ua_s_attn = F.softmax(ua_s_attn,dim=-1) # [B, heads_num, N, N]
          ua_s = torch.matmul(ua_s_attn, vs).view(s.shape[0],s.shape[1],s.shape[2]) # [B, N, 2d]
          
          ua_u_attn = torch.matmul(qu / self.sqrt_d, ku.transpose(-2,-1))
          ua_u_attn = F.softmax(ua_u_attn,dim=-1) # [B, heads_num, N, N]
          ua_u = torch.matmul(ua_u_attn, vu).view(u.shape[0],u.shape[1],u.shape[2]) # [B, N, 2d]
          
          s_hat = self.layer_norm_s_1(s + ua_s) # [B, N, 2d]
          s_output = self.layer_norm_s_2(s_hat + self.FFN_s(s_hat)) # [B, N, 2d]
          
          u_hat = self.layer_norm_u_1(u + ua_u) # [B, N, 2d]
          u_output = self.layer_norm_u_2(u_hat + self.FFN_u(u_hat)) # [B, N, 2d]
  
          #------------------------------------------------------------------------------------------#
          qs1 = self.w_qs(s).reshape(s.shape[0], s.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          qs1 = qs1.permute(0, 2, 1, 3)     # (B, H, N, D)
          ks1 = self.w_ks(s).reshape(s.shape[0], s.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          ks1 = ks1.permute(0, 2, 1, 3)     # (B, H, N, D)
          vs1 = self.w_vs(s).reshape(s.shape[0], s.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          vs1 = vs1.permute(0, 2, 1, 3)     # (B, H, N, D)
  
          qu1 = self.w_qu(u).reshape(u.shape[0], u.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          qu1 = qu1.permute(0, 2, 1, 3)     # (B, H, N, D)
          ku1 = self.w_ku(u).reshape(u.shape[0], u.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          ku1 = ku1.permute(0, 2, 1, 3)     # (B, H, N, D)
          vu1 = self.w_vu(u).reshape(u.shape[0], u.shape[1], self.heads_num, self.heads_dim)   # (B, N, H, D')
          vu1 = vu1.permute(0, 2, 1, 3)     # (B, H, N, D)
  
  
          ua_s_attn1 = torch.matmul(qs1 / self.sqrt_d, ks1.transpose(-2,-1)) # [B, H, N, N]
          ua_s_attn1 = F.softmax(ua_s_attn1, dim=-1) # [B, H, N, N]
          ua_s1 = torch.matmul(ua_s_attn1, vs1).permute(0, 2, 1, 3)   # (B, N, H, D') = (B, N, H, D')
          ua_s1 = ua_s1.reshape(s.shape[0], s.shape[1], s.shape[2])   # (B, N, D) = (B, N, 2d)
          
          ua_u_attn1 = torch.matmul(qu1 / self.sqrt_d, ku1.transpose(-2,-1)) # [B, H, N, N]
          ua_u_attn1 = F.softmax(ua_u_attn1, dim=-1) # [B, H, N, N]
          ua_u1 = torch.matmul(ua_u_attn1, vu1).permute(0, 2, 1, 3)   # (B, N, H, D') = (B, N, H, D')
          ua_u1 = ua_u1.reshape(u.shape[0], u.shape[1], u.shape[2])   # (B, N, D) = (B, N, 2d)
          
          s_hat1 = self.layer_norm_s_1(s + ua_s1) # [B, N, 2d]
          s_output1 = self.layer_norm_s_2(s_hat1 + self.FFN_s(s_hat1)) # [B, N, 2d]
          
          u_hat1 = self.layer_norm_u_1(u + ua_u1) # [B, N, 2d]
          u_output1 = self.layer_norm_u_2(u_hat1 + self.FFN_u(u_hat1)) # [B, N, 2d]
  
  
  
          #------------------------------------------------------------------------------------------#
          # 感觉不需要分头，我来测试一下
          qs2 = self.w_qs(s)      # (B, N, 2d)
          ks2 = self.w_ks(s)      # (B, N, 2d)
          vs2 = self.w_vs(s)      # (B, N, 2d)
  
          qu2 = self.w_qu(u)      # (B, N, 2d)
          ku2 = self.w_ku(u)      # (B, N, 2d)
          vu2 = self.w_vu(u)      # (B, N, 2d)
  
          ua_s_attn2 = torch.matmul(qs2 / self.sqrt_d, ks2.transpose(-2, -1))     # (B, N, N)
          ua_s_attn2 = F.softmax(ua_s_attn2, dim = -1)    # (B, N, N)
          ua_s2 = torch.matmul(ua_s_attn2, vs2)           # (B, N, 2d)
  
          ua_u_attn2 = torch.matmul(qu2 / self.sqrt_d, ku2.transpose(-2, -1))     # (B, N, N)
          ua_u_attn2 = F.softmax(ua_u_attn2, dim = -1)    # (B, N, N)
          ua_u2 = torch.matmul(ua_u_attn2, vu2)           # (B, N, 2d)
  
          s_hat2 = self.layer_norm_s_1(s + ua_s2) # [B, N, 2d]
          s_output2 = self.layer_norm_s_2(s_hat2 + self.FFN_s(s_hat2)) # [B, N, 2d]
          
          u_hat2 = self.layer_norm_u_1(u + ua_u2) # [B, N, 2d]
          u_output2 = self.layer_norm_u_2(u_hat2 + self.FFN_u(u_hat2)) # [B, N, 2d]
  
          return s_output, u_output, s_output1, u_output1, s_output2, u_output2
      
      
  B, N, D = 4, 16, 64
  s = torch.randn(B, N, D)
  u = torch.randn(B, N, D)
  
  model = DJE_layer(in_dim=D, heads_num=4)
  out = model(s, u)
  
  # 假设 out 是 model(s, u) 的输出，共 6 个 tensor：s0, u0, s1, u1, s2, u2
  names = ["s0", "u0", "s1", "u1", "s2", "u2"]
  
  # 输出每个 tensor 的基础信息
  for i, name in enumerate(names):
      print(f"{name}: shape = {out[i].shape}, contains NaN: {torch.isnan(out[i]).any().item()}")
  
  print("\n【比较 s0, s1, s2 之间的差异】")
  for i in range(0, 3):
      for j in range(i+1, 3):
          si, sj = out[i*2], out[j*2]
          max_diff = (si - sj).abs().max().item()
          mean_diff = (si - sj).abs().mean().item()
          equal = torch.allclose(si, sj, atol=1e-6)
          print(f"{names[i*2]} vs {names[j*2]} | max diff: {max_diff:.4e}, mean diff: {mean_diff:.4e}, allclose: {equal}")
  
  print("\n【比较 u0, u1, u2 之间的差异】")
  for i in range(0, 3):
      for j in range(i+1, 3):
          ui, uj = out[i*2+1], out[j*2+1]
          max_diff = (ui - uj).abs().max().item()
          mean_diff = (ui - uj).abs().mean().item()
          equal = torch.allclose(ui, uj, atol=1e-6)
          print(f"{names[i*2+1]} vs {names[j*2+1]} | max diff: {max_diff:.4e}, mean diff: {mean_diff:.4e}, allclose: {equal}")
  ```

  

  最后测试结果如下：

  ```bash
  s0: shape = torch.Size([4, 16, 64]), contains NaN: False
  u0: shape = torch.Size([4, 16, 64]), contains NaN: False
  s1: shape = torch.Size([4, 16, 64]), contains NaN: False
  u1: shape = torch.Size([4, 16, 64]), contains NaN: False
  s2: shape = torch.Size([4, 16, 64]), contains NaN: False
  u2: shape = torch.Size([4, 16, 64]), contains NaN: False
  
  【比较 s0, s1, s2 之间的差异】
  s0 vs s1 | max diff: 6.1583e-01, mean diff: 1.2151e-01, allclose: False
  s0 vs s2 | max diff: 6.0822e-01, mean diff: 1.2453e-01, allclose: False
  s1 vs s2 | max diff: 1.2839e-01, mean diff: 2.1172e-02, allclose: False
  
  【比较 u0, u1, u2 之间的差异】
  u0 vs u1 | max diff: 5.7573e-01, mean diff: 1.2056e-01, allclose: False
  u0 vs u2 | max diff: 5.8795e-01, mean diff: 1.2242e-01, allclose: False
  u1 vs u2 | max diff: 1.1532e-01, mean diff: 1.9952e-02, allclose: False
  ```

  可以发现

  > | 比较         | 说明                                                         |
  > | ------------ | ------------------------------------------------------------ |
  > | `s0` vs `s1` | 你的**第一种写法**（直接 reshape 到 `[B, H, N, D]`）跟第二种（permute）结果**不一致**。 |
  > | `s1` vs `s2` | **第二种写法**（permute）和**第三种（不分头）**结果比较接近。说明可能这两种比较“合理”。 |
  > | `s0` 与其他  | 明显偏差，意味着第一种写法的行为与其它两种都不同，**可能有问题或语义不一致。** |

  所以我们的怀疑可能是对的，论文中的代码应该是错了。因为我们的写法3是论文公式中最直接的逻辑，写法2进行了分头，写法1（原写法）应该是语义没有对齐。

  实际上，默认况下，使用多头的写法除以的因子应该为 `heads_dim` ，而不使用多头写法除以的因子应该为 `in_dim`。但是论文中一律用 $d$ ，不管是解码过程还是编码过程，所以这里我们不用去管。

  但是为什么写法2和写法3会不对呢？照理说应该是没问题的呀

* 从数学的角度证明写法2和写法3不等价

  事实上，即便忽略缩放因子与非线性函数 `softmax` 的影响，写法2和写法3的结果也不会相同。

  ```python
  # Q, K, V ∈ (B, N, d=4)
  # heads_num = 2, heads_dim = 2
  H = 2
  d_h = 2
  d = 4
  qs = torch.randn(B, H, N, d_h)
  ks = torch.randn(B, H, N, d_h)
  vs = torch.randn(B, H, N, d_h)
  
  # 写法2
  attn_head = torch.matmul(qs, ks.transpose(-2, -1))  # (B, H, N, N)
  ua_head = torch.matmul(attn_head, vs)               # (B, H, N, d_h)
  ua_cat = ua_head.permute(0, 2, 1, 3).reshape(B, N, d)  # (B, N, d)
  
  # 写法3（用拼接的 Q, K, V）
  qs_flat = qs.permute(0, 2, 1, 3).reshape(B, N, d)
  ks_flat = ks.permute(0, 2, 1, 3).reshape(B, N, d)
  vs_flat = vs.permute(0, 2, 1, 3).reshape(B, N, d)
  
  attn_flat = torch.matmul(qs_flat, ks_flat.transpose(-2, -1))  # (B, N, N)
  ua_flat = torch.matmul(attn_flat, vs_flat)                    # (B, N, d)
  ```

  测试之后发现，`ua_cat` 和 `ua_flat` 并不一样。这到底是为什么呢？怎么会是呢？

  自己画图模拟了一下大概完全（可能是完全吧）懂了。写法二是将原本的特征维度分成了多个头，而这多个头在进行 $Q K^{\top}V$ 的计算时都是在自己的头中计算的，也就是说头与头之间是独立的，计算时互不干涉，也即两个不同头之间的数据是**没有交互**的！但是写法三不分头，那么它计算的视角就是全局视角了，**所有的数据都是互相有交互的！！**，这样即便没有缩放因子与非线性函数 `softmax` 的影响，这两种做法得出的结果也是显然不同的。

* 文中设计伪标签的思路合理吗？有没有什么理论依据支撑？它是这么做的，同时训练 n 个模型，源码中是2个。在一轮训练结束后，在重复采样之前，先得到 n 个模型的节点重要性与不确定性的估计值。然后在进行采样，即在推理状态下重复 T 次，得到 T 组结果，即采样 T 组结果（这里是 4），然后对着 n * T 个结果求平均即得到了节点的重要性与不确定性的**伪标签**。

  这种做法其实是合理的，这种集成方法能降低方差。因为多个独立预测的平均比任何单个预测更接近真实值（数学上已证明）（自己学习一下证明，很经典的集成操作减小方差）

* 如何理解公式 (21) 中使用 `EXP(ẑ_{x',i})` 以避免负预测？

  这是一个经典的 **不确定性建模技巧**，用于保证你预测的“方差”永远是正数。

  

  > **背景**  
  >
  > 我们希望模型不仅能输出预测值 $\hat{s}$，还要输出**预测的可信程度**（不确定性）→ 用**方差 $\sigma^2$** 表示。  
  >
  > 但直接让模型输出 $\sigma^2$ 会有两个问题：  
  > 1. **没有正值约束** → 可能输出负数（$\sigma^2 < 0$）→ 不合法（方差必须是正数）。  
  > 2. **训练难以稳定** → 梯度可能爆炸。  
  >
  > **解决方案**  
  >
  > 让模型输出 $z \in \mathbb{R}$（任意实数），然后通过 **$\exp(z)$** 转换成正数：  
  > $$
  > \sigma^2 = \exp(z)
  > $$
  > 这个变换有两个好处：  
  > 1. **正值保证**：无论 $z$ 是多少，$\exp(z) > 0$，确保方差合法。  
  > 2. **数值稳定**：$\exp(z)$ 的梯度计算友好，训练更稳定。  
  >
  > **为什么这样做能避免负预测？**  
  >
  > 看损失函数（公式 21）：  
  > $$
  > L = \frac{(s^+ - \hat{s})^2}{2 \cdot \exp(z)} + \frac{z}{2}
  > $$
  > 其中 $\exp(z)$ 就是模型预测的**方差**。  
  >
  > - 如果直接用 $z$ 做分母（不加 $\exp$），当 $z$ 为负数时，整个 loss 会崩溃（分母为负或除零错误）。  
  > - 但用 $\exp(z)$，**分母永远为正**，无论 $z$ 预测什么值，loss 都不会出问题！  
  >
  > 这样，模型既能预测不确定性，又能保证训练稳定。 🚀
  >
  > 我们希望模型不仅能输出预测值 $\hat{s}$，还要输出**预测的可信程度**（不确定性）→ 用**方差 $\sigma^2$** 表示。  
  >
  > 但直接让模型输出 $\sigma^2$ 会有两个问题：  
  > 1. **没有正值约束** → 可能输出负数（$\sigma^2 < 0$）→ 不合法（方差必须是正数）。  
  > 2. **训练难以稳定** → 梯度可能爆炸。  
  >
  >  **解决方案**  
  >
  > 让模型输出 $z \in \mathbb{R}$（任意实数），然后通过 **$\exp(z)$** 转换成正数：  
  > $$
  > \sigma^2 = \exp(z)
  > $$
  > 这个变换有两个好处：  
  > 1. **正值保证**：无论 $z$ 是多少，$\exp(z) > 0$，确保方差合法。  
  > 2. **数值稳定**：$\exp(z)$ 的梯度计算友好，训练更稳定。  
  >
  > **为什么这样做能避免负预测？**  
  >
  > 看损失函数（公式 21）：  
  > $$
  > L = \frac{(s^+ - \hat{s})^2}{2 \cdot \exp(z)} + \frac{z}{2}
  > $$
  > 其中 $\exp(z)$ 就是模型预测的**方差**。  
  >
  > - 如果直接用 $z$ 做分母（不加 $\exp$），当 $z$ 为负数时，整个 loss 会崩溃（分母为负或除零错误）。  
  > - 但用 $\exp(z)$，**分母永远为正**，无论 $z$ 预测什么值，loss 都不会出问题！  
  >
  > 这样，模型既能预测不确定性，又能保证训练稳定。 🚀
  >
  > 我们希望模型不仅能输出预测值 $\hat{s}$，还要输出**预测的可信程度**（不确定性）→ 用**方差 $\sigma^2$** 表示。  
  >
  > 但直接让模型输出 $\sigma^2$ 会有两个问题：  
  > 1. **没有正值约束** → 可能输出负数（$\sigma^2 < 0$）→ 不合法（方差必须是正数）。  
  > 2. **训练难以稳定** → 梯度可能爆炸。  
  >
  >  **解决方案**  
  >
  > 让模型输出 $z \in \mathbb{R}$（任意实数），然后通过 **$\exp(z)$** 转换成正数：  
  > $$
  > \sigma^2 = \exp(z)
  > $$
  > 这个变换有两个好处：  
  > 1. **正值保证**：无论 $z$ 是多少，$\exp(z) > 0$，确保方差合法。  
  > 2. **数值稳定**：$\exp(z)$ 的梯度计算友好，训练更稳定。  
  >
  >  **为什么这样做能避免负预测？**  
  >
  > 看损失函数（公式 21）：  
  > $$
  > L = \frac{(s^+ - \hat{s})^2}{2 \cdot \exp(z)} + \frac{z}{2}
  > $$
  > 其中 $\exp(z)$ 就是模型预测的**方差**。  
  >
  > - 如果直接用 $z$ 做分母（不加 $\exp$），当 $z$ 为负数时，整个 loss 会崩溃（分母为负或除零错误）。  
  > - 但用 $\exp(z)$，**分母永远为正**，无论 $z$ 预测什么值，loss 都不会出问题！  
  >
  > 这样，模型既能预测不确定性，又能保证训练稳定。 🚀

  貌似与负对数似然函数有关。因为公式（21）是一个有明确概率意义的负对数似然。也就是 `epx` 能保证 `z` 为正数，但是 $\frac{z}{2}$ 不一定是正数，但也是合理的。损失不会为负，因为这个公式是有明确概率意义的。

* 如何理解公式（23）的意图

  我是这么认为的：直觉上想貌似是正确的，我们用多个模型多次采样取平均得到了节点的不确定性作为伪标签，然后我们让我们的预测值的不确定性更好地靠近这个伪标签，来保持稳定。我理解得对吗？有没有更深层次的原因？经过分析，其核心目的是：

  1. 公式（23）是**不确定性估计的稳定性损失**；

  2. 用伪标签的不确定性 去引导每个模型的预测不确定性靠近；

  3. 实际上是一种对模型**不确定性估计的一致性正则**。

     > **一致性正则（Consistency Regularization）** 是**半监督学习（SSL）和伪标签方法**中的常见技术，其基本思想是：
     >
     > > **输入发生扰动后，模型输出应保持一致。**
     >
     > 给定样本 $x$，我们对它加一个扰动（例如图中的 drop edge、文本中的同义词替换、图像中的旋转），得到 $x'$。  
     >
     > 然后：  
     > - 模型预测原样本得到输出 $s(x)$  
     > - 模型预测扰动后的样本得到 $s(x')$  
     >
     > 我们希望：  
     > $$ s(x) \approx s(x') $$  
     >
     > 于是就加一个**一致性损失项**：  
     > $$ L_{cons} = \| s(x) - s(x') \|_2 $$  
     >
     > 
     >
     > 类比到这里其实就是每次采样，由于 dropout 的影响，都会发生扰动，我们要让输出前后尽量保持一致
     >
     > 那么什么是对模型不确定性估计的一致性正则？
     >
     > 这是对“一致性正则”的更进一步推广——**不仅让模型输出预测值一致，还让模型输出的“不确定性估计”也一致。**
     >
     > 在我的场景中：
     >
     > 我在做伪标签学习，每个伪标签不仅有预测值（如 softmax 值），还估计了其**不确定性（uncertainty）**，比如预测的置信度、方差、熵等。
     >
     > 于是我希望：
     >
     > > 模型自己预测出的不确定性，应该与我们从“多个模型集成”中得到的不确定性（平均、集成推断）保持一致。
     >
     > 这就构成了 **对模型不确定性估计的一致性正则化**。

     为什么要这么做？

     1. 如果模型预测的不确定性与多模型集成的平均不一致，说明其预测不稳定；
     2. 所以通过这个正则项，**强制模型学习更接近真实（平均）不确定性的输出**，提升伪标签的可靠性；
     3. **同时也减少伪标签误差对训练的干扰（防止“伪标签不确定性过低”，导致过拟合）。**

* 司马作者

  是这样的我们发现 Figure4 中 (a) (b) 两图均是使用FB15K数据集进行的训练。并且我发现 在 labeld data percentage = 1时达到最佳指标。且 EASING 模型在MAE RMSE NRMSE这一块的最佳指标与table 2中 EASING模型 在 FB15K这一数据集上得到的MAE RMSE NRMSE的最佳指标 数据上几乎吻合！！ 这几乎实锤了 论文中 table2 中的 sota 是在 labeled data percentage = 1 时得到的。那么和sota其实和无监督没有关系！！！ 这样做是允许的吗？为什么这能过审啊！！！

**导入数据与预处理工作**

* 数据集划分。作者的数据集划分思路是这样的。首先将 `raw data` （有标记的可用的）划分整理了 1000 批次。然后将其再分成 10 组，也就是说每组有 100批次的数据。作者选择将一个组当作测试集，一个组当作验证集。其他的 8 组，用作 `labeled` 数据集与 `unlabeled` 数据集。使用 `train_num` 进行权衡， `train_num` 可以理解为使用的 `labeld` 的组，若设置为1，则为1组即100批。剩下的作为 `unlabeled` 的数据处理。从 `Table 1: Dataset statistics.` 中应该可以认为，实验时默认都将 `train_num` 设置为1

* 之后计算了训练集标签 `train_labels` 的均值 `mean` 与方差 `std`

  命令行参数中提到了**是否设置相对熵**，目前尚不清楚为什么要添加这一参数（待填坑）

  节点嵌入向量的结构维度：64；节点嵌入向量的语义维度：768

  打印了默认参数下训练的数据的情况：

  1. 边数：592213（这是整张图的边数）
  2. 未标记节点：9883（其实是有labeled的）
  3. 训练样本：1407
  4. 验证样本：1411
  5. 测试样本：1409
  6. 其他的有图的总节点数为 14951 （包括 841 个没有利用的节点）

  其中 9883 + 1407 + 1411 + 1409 = 14110 = 14951 - 840 - 1（**其中有840个节点的标签是丢失的，FB15K这个数据集还是比较特殊的，它的标签率是比较高的，但是 TMDB5K 和 IMDB 这两个数据集的标签率就比较低了**）

  为每个节点添加了自环、增加了自环这一边属性（使用一个正数来代表自环这一 `types`），`rel_num += 1`

  

##### 创建模型

* 将损失函数设置为 `torch.nn.MSELoss()`

* 创建了两个模型 `model` 与 `model_1` 即 `EASING` 框架

  `num_layers = 2`: 表示有 2 个 **中间的 Transform 层**（即隐藏层）

  `num_heads = 8`: 每个隐藏层使用 **8 个注意力头**，输出会是多个头拼接后的向量

  `num_out_heads = 4`: 最后一层（输出层）使用 **4 个注意力头**（有时会进行平均、拼接或求和）

  因此这里的 `heads`为 `[8, 8, 4]`

  `num_layers = 2` 只看隐藏层

  `num_hidden = 8` 

  1. 为每条边生成谓词嵌入 `self.rel_emb = nn.Embedding(rel_num, args.pred_dim)`，这里分别为 1346 与 10

  2. 分别对 `node feature` （包括结构与语义）进行 `transform` 操作，即进入 `GTRANRel_feat`

     ```python
     self.struct_gtran = GTRANRel_feat(g, args.num_layers, rel_num, args.pred_dim, struct_in_dim,
                                      args.num_hidden, heads, args.in_drop, args.attn_drop,
                                      args.residual, args.norm, args.edge_mode, self.rel_emb)
     self.content_gtran = GTRANRel_feat(g, args.num_layers, rel_num, args.pred_dim, content_in_dim,
                                        args.num_hidden, heads, args.in_drop, args.attn_drop,
                                        args.residual, args.norm, args.edge_mode, self.rel_emb)
     ```

  3. 根据之前的代码框架经验，我们还需要为**每一层封装一个类** `GTLayer`，如下：

     ```python
     self.gat_layers = nn.ModuleList()
     # input projection (no residual)
     self.gat_layers.append(GTLayer(
     	in_dim, num_hidden, pred_dim, heads[0],
     	feat_drop, attn_drop, residual, batch_norm, edge_mode))
     # hidden layers
     for l in range(1, num_layers):
         # due to multi-head, the in_dim = num_hidden * num_heads
         self.gat_layers.append(GTLayer(
             num_hidden * heads[l-1], num_hidden, pred_dim, heads[l],
             feat_drop, attn_drop, residual, batch_norm, edge_mode))
     ```

  4. 进入最底层的 `GTLayer` 就是 `transform` 在图上的应用了，$Q, K, V$  这种。尝试自己先写一遍

  5. 进入 `DJE` 模块！ `self.ut=DJE(args, self.h_dim*2, g.number_of_nodes())`，在这里分别被认为是参数空间、输入维度`in_dim = 128` 与批次 `batch_size = 14951`。该模块实现了论文中提出的 DJE（**Distribution-aware Joint Encoder**）中**用于生成均值预测和不确定性估计的部分**，是 DJE 的核心组成模块之一。其主要作用是

     输入一批节点表示 $q$（来自图 Encoder，例如 HGNN or Transformer），输出对应节点的重要性估计 $\mu$（均值）与不确定性 $\sigma^2$（方差），即 $\mathcal{N}(\mu, \sigma^2)$。

     这是解码器模块，当然还要进入最小的解码器层 `DJELayer`
  
  6. 进入 `DJE_layer`
  
     ```python
     super(DJE, self).__init__()
     self.unc_layers = args.unc_layers
     self.in_dim = in_dim
     self.N=args.uhgt_in_dim
     self.batch_size=batch_size
     self.heads_num=args.uhgt_heads
     ```
  
     另外还设置了 `self.p_s` 与 `self.p_u`，将每个批次（这里是节点数量）的**重要性与不确定性表示**都先**统一初始化**为一个 $N \times 1$ 的向量（在本例中 $N$ 为 1）
     
     ```python
     self.p_s = torch.randn(self.N, 1,requires_grad=True) # [N, 1]
     self.p_s=self.p_s.repeat(self.batch_size,1,1).cuda() # [B, N, 1]
     
     self.p_u = torch.randn(self.N, 1,requires_grad=True) # [N, 1]
     self.p_u=self.p_u.repeat(self.batch_size,1,1).cuda() # [B, N, 1]
     ```
     
     
  

##### 训练模型

1. 进入 `Easing` 实例中的 `forward` 模块

   ```python
   def forward(self, struct_input, content_input, edge_types):
   ```

2. 分别对结构嵌入与语义嵌入做编码

   ```python
   struct_h = self.struct_gtran(struct_input, edge_types)
   content_h = self.content_gtran(content_input, edge_types)
   ```

   进入到最底层的 trans 编码器，得到根据 $h$ 与 $rel$ 得到最新的 $h$ 

   ```python
   def forward(self, inputs, edge_types):
       h = inputs
       edge_feats = self.rel_emb(edge_types)
   
       for l in range(self.num_layers):
           h = self.gat_layers[l](self.g, q=h, k=h, v=h, edge_feat=edge_feats)
   
           return h
   ```

   那么最终便得到了关于 `struct` 与 `content` 的 `h`，将它们拼接起来并进行解码

   此时 `struct_h.shape` 和 `content_h.shape` 均为 `torch.Size([14951, 64])`

   `q = torch.cat((struct_h, content_h), 1) # (14951, 128)`

3. 进行解码

   ```python
   x_m, x_v = self.ut(q, self.centrality, self.gamma, self.beta, self.REnt)
   
   if self.training:
       return x_m, x_v
   else:
       return x_m, x_v
   ```

   执行 `self.ut(q, self.centrality, self.gamma, self.beta, self.REnt)` 这份代码后。其中这里的 `self.centrality.shape` 与 `self.gamma.shape` 和 `self.beta.shape` 均为 `N` 。而默认参数中的`self.REnt` 则为 0 。之后便进入了 `DJE` 实例的 `forward` 部分。

   而这里的 $q$ 其实就是编码结束之后图节点的结构嵌入与语义嵌入的拼接，对应论文中的 $H_x =G_x^{(L)} || T_x^{(L)}$

   首先需要理解 $S_x$ 与 $U_x$ 的**含义**与**形状**。论文中说到：我们的DJE编码器输出均值和协方差表示 $S_x,U_x \in \mathbb{R}^{N \times 2d}$，这里的 $N$ 是一个超参数，并非节点的数量！也就是说，每个节点的初始重要性与不确定性都先看成一个矩阵，而矩阵的行则通过 $N$ 设置。

   在代码中具体这样体现：

   ```python
   # 这里的 B 其实就是 N，同时代表批次与节点数量
   q_input = q_input.unsqueeze(1) #[B, 1, 2d]
   if q_input.shape[0] != self.p_s.shape[0]:
       p_s_new=torch.narrow(self.p_s, 0, 0, q_input.shape[0])
       p_u_new=torch.narrow(self.p_u, 0, 0, q_input.shape[0])
       s = torch.bmm(p_s_new, q_input) # [B, N, 2d]
       u = torch.bmm(p_u_new, q_input) # [B, N, 2d]
   else:
       s = torch.bmm(self.p_s, q_input) # [B, N, 2d]
       u = torch.bmm(self.p_u, q_input) # [B, N, 2d]
   ```

   上面针对每个节点（`B`），构造了对应的节点重要性与不确定性的表示，维度为 $N \times 2d$。即**针对每个节点**，大致的构造结果是这样的：一个列向量乘上一个行向量得到一个矩阵。就是论文中公式11的体现。

   对这个操作我们可以这样直觉理解：我们构造出 $N$ 个结构方向，每个方向给这个 $q$ 一个不同的“缩放比例”或“投影强度”，得到 $N$ 个版本的 $q$，每一个是这个节点在**某种结构视角下的表示**。用来表示节点的重要性或者不确定性。举个例子：

   > | 第 i 个结构方向 $p_s[i]$ | 生成的子表示 $S[i] = p_s[i] \cdot q$ |
   > | ------------------------ | ------------------------------------ |
   > | 1.2                      | q 被放大 1.2 倍（某个方向更重视）    |
   > | 0.8                      | q 被缩小 0.8 倍（某个方向较弱）      |
   > | -0.5                     | q 被反转方向                         |

   ```python
   ua_s_attn = torch.matmul(qs / self.sqrt_d, ks.transpose(-2,-1))
   ```

   这份代码的含义是：计算**每个子表示对其他子表示的注意力权重**，形成结构化注意力矩阵，以便对 token 间关系建模。这里的**子表示**后续会对其操作，计算各个子表示之间的注意力系数（就跟 transfrom 的框架一样）

   总之最后会得到 `s_output`/`s` 与 `u_output`/`u`，它们的 `shape` 均为 `[B, N, 2d]`，符合论文中对 $S_x$ 和 $U_x$ 给出空间 $\mathbb{R}^{(N \times 2d)}$，只是说在中间的处理过程中会将 $2d$ 这个维度拆成 $heads \times heads_{dim}$ 用于做注意力机制。

   然后对 `s` 与 `u` 做如下处理：

   ```python
   s=s.view(q_input.shape[0],-1)	# (B, N, 2d) -> (B, N * 2d) 相当于做了特征堆叠
   u=u.view(q_input.shape[0],-1)
   
   s=nn.functional.relu(((centrality * gamma + beta).unsqueeze(-1) + (REnt * (1- gamma) + beta).unsqueeze(-1)) * s)
   u=nn.functional.relu(((centrality * gamma + beta).unsqueeze(-1) + (REnt * (1 - gamma) + beta).unsqueeze(-1)) * u)
   ```

   这里的权重因子是 **根据 centrality 和 REnt 混合得到的缩放系数**，用于动态调整每个样本的特征表示。这部分是论文中提到的辅助缩放技巧：

   > **辅助缩放技巧的补充说明**  
   >
   > 正如文献[5,18]所指出的，图节点的重要性值可能与拓扑中心性（如特征向量中心性[2]）存在较强的相关性。受此启发，我们引入以下缩放技巧来进一步提升估计性能。具体而言，我们考虑两种辅助信息，即**图结构中心性**和**累积文本相对熵**。  
   >
   > **图结构中心性**  
   >
   > 对于任意节点 $x$，我们将其对数度中心性计算如下：  
   > $$
   > CEN(x) = \log(|\mathcal{N}(x)| + \delta)
   > $$
   > 其中 $\delta$ 是一个小项，例如 $\delta=1 \times 10^{-4}$。  
   >
   > **累积文本相对熵**  
   >
   > 首先，将通过 Transformer-XL 编码得到的 $d$ 维文本特征 $T_x$ 用 $Q_x = \text{SOFTMAX}(T_x)$ 进行归一化。对于归一化后的文本特征 $Q_x$，我们用 $Q_x(j)$ 表示其第 $j$ 个元素。然后，节点 $x$ 的文本相对熵计算为：  
   > $$
   > RENT(x) = \log\left(\sum_{y \in \mathcal{N}(x)} \sum_{j=1}^{d} Q_x(j) \log\frac{Q_x(j)}{Q_y(j)} + \delta\right)
   > $$
   >
   > 随后，我们直接将这两个标量与按公式(17)计算得到的重要性值 $\hat{s}_x$ 相乘（不确定性保持不变），如下所示：  
   > $$
   > (\mu_1 \cdot CEN(x) + \mu_2 \cdot RENT(x)) \cdot \hat{s}_x
   > $$
   > 其中 $\mu_1, \mu_2 \in (0,1)$。
   >
   > - **拓扑中心性（CEN (x)）的作用**： 节点的度中心性（邻居数量的对数）反映其在图结构中的连接密集程度，通常连接越多的节点（如社交网络中的枢纽节点）重要性更高。通过 $\log(|\mathcal{N}(x)| + \delta)$ 量化该特征，为重要性估计提供结构层面的支持。
   > - **文本相对熵（R2ENT (x)）的作用**： 如前所述，RENT (x) 度量节点与邻居的文本特征差异，差异越大可能表示节点语义越独特（如热门实体、关键角色），进而对应更高的重要性。该指标从文本语义层面补充了节点的 “独特性” 信号。

   经过缩放技巧处理之后 `s` 与 `u` 的 `shape` 仍然为 `[B, 2d]` （这里的 `B` 是节点数量）

   最后经过一个全连接层将特征映射到 1 维，终于解码出了真正的节点重要性与不确定性

   ```python
   x_m=self.fc_s(s)
   x_v=self.fc_u(u)
   ```

4. 处理 `labeled data` 与 `unlabeled data`

   ```python
   # labeled data
   mean = all_output_model_0_pred[train_idx].view(-1)
   var = var_pred_0[train_idx].view(-1)
   mean_1 = all_output_model_1_pred[train_idx].view(-1)
   var_1 = var_pred_1[train_idx].view(-1)
   train_labels_logits = ((mean  + mean_1)/2) * y_std + y_mean
   
   # unlabeled data
   all_output_unlb_0_pred_0=all_output_model_0_pred[unlabeled_idx]
   var_unlb_0_pred_0=var_pred_0[unlabeled_idx]
   all_output_unlb_1_pred_0=all_output_model_1_pred[unlabeled_idx]
   var_unlb_1_pred_0=var_pred_1[unlabeled_idx]
   ```

   其中 `y_std` 与 `y_mean` 是通过计算对应的 `train_lables` 的具体标签值得到的

   ```python
   y_mean=torch.mean(train_labels).item()
   y_std=torch.sqrt(torch.var(train_labels)).item()
   ```

5. 生成伪标签

   这部分它的变量命名写得很乱，就不写了。发现了一点是，其实所谓的不确定是只是为了用来指导与“矫正”训练的（即这个不确定性只是损失函数的一部分），我们最终在验证与测试阶段只需要节点重要性。

   它是这么做的，同时训练 n 个模型，源码中是2个。在一轮训练结束后，在重复采样之前，先得到 n 个模型的节点重要性与不确定性的估计值。然后在进行采样，即在推理状态下重复 T 次，得到 T 组结果，即采样 T 组结果（这里是 4），然后对着 n * T 个结果求平均即得到了节点的重要性与不确定性的**伪标签**。

   论文中公式（18）注意这里的字母上是没有上标 $t$ 的，也就是这个数据并不是在采样阶段获得的，公式（18）表示的数据就是模型得到的节点的重要性与不确定性的预测值；而采样阶段获得的值应该只是为了构造伪标签。也就是说这篇论文为了这个所谓的伪标签，其实是增加了很多的工作量的。

   公式（24）与公式（25）都是好理解的，公式（24）就是正常的计算回归损失。由于真实数据没有不确定性这一标签，因此我们只能通过 DJE1 和 DJE2 学习到的不确定性来提升模型的鲁棒性与泛化能力：如果两个模型对同一个节点给出完全不同的不确定性，那说明模型没学稳定；所以我们通过这个 loss **鼓励模型间的一致性（consistency）**，提升鲁棒性与泛化能力。

   

   代码中还给出了一项排序监督损失 `list_loss_labels`（通过 list_loss 函数计算），只是论文中并没有提到。其实就是计算 LTR 损失，**关注的是相对排名**。

   后续发现，引入的这个损失的价值将体现在 `Table 8` 中的 `EASING_rank` 中，纠正排名，使其性能更高。

   ```python
   list_loss_labels = list_loss(train_labels_logits.unsqueeze(1),train_labels.unsqueeze(1),args.list_num)
   ```

   其中，这里的 `train_labels_logits` 和 `train_labels` 都是真实值，也就是现实生活中的值，我们之前所讨论的模型预测值、伪标签构造等，通常都是在标准化后的空间中处理的。

   `train_labels` 是真实的标签值。

   ```python
   # 反标准化操作，还原为预测的真实值
   train_labels_logits = ((mean  + mean_1)/2) * y_std + y_mean
   ```

   `args.list_num` 是采样的个数。

6. 验证与测试

   这一部分没啥好说的，就是通过模型得到节点重要性值与不确定性然后进行对应的评估 `rank_evaluate`



感觉它好诈骗啊我草拟的，标签用的少效果训练稀烂，要达到 sota 效果基本上 labeled data percentage 要到达 100%？（先搁着，再跑一轮看看情况）

好气啊！好躁啊！！！

等等！貌似调参是对的！！貌似这个效果是对的.

后续：测完了0.3才反应过来 Figure4 中的 `labelded data percentage` 中的百分比指标原来是 `train_num`。（也就是说我们的有标签的训练集最高是1批，即 `train_num <= 1.0` ）



貌似不能进行批训练...解码器的代码强制使用了整图训练...不是很好搞...使用图的批处理会丢失一些图的聚合信息，而且还得修改代码，不是



##### 训练参数设置与实验结果报告

* `FB15K` 数据

这份是使用了残差连接 + 归一化（`batch_norm` 与 `layer_norm`）的操作

并且启用了 `REnt_bool`

训练的数据有标签的占据10%

```python
python easing/main_easing.py \
--dataset FB15K \
--data_path datasets \
--graph_data FB15K/fb15k_rel.pk \
--semantic_data FB15K/fb_lang.pk \
--gpu 0 \
--cross-num 5 \
--epochs 10000 \
--min-epoch 200 \
--num-hidden 8 \
--num-layers 2 \
--uhgt_in_dim 10 \
--uhgt_heads 4 \
--num-heads 4 \
--train_num 1.0 \
--samp_ssl 5 \
--samp_fq 5 \
--w_ulb 1.0 \
--centrality_gamma 0.9 \
--unc_layers 2 \
--in-drop 0.3 \
--attn-drop 0.3 \
--lr 0.005 \
--weight-decay 5e-4 \
--early-stop \
--patience 500
```



MAE：0.7505 +- 0.0114

RMSE：1.0152 +- 0.016

NRMSE：0.0995 +- 0.013

spearmans：0.7335 +- 0.0099

Precision@100：0.4900 +- 0.0245

ndcg：0.9507 +- 0.0060

在使用了早停机制开启了 REnt 以及正确地调参（包括启用残差）效果之下，貌似实验是可以复制的。尤其是加入了早停机制，从原本的30h到只需232min。原本设置的epoch为10000，早停之后只需跑 1000 轮左右。即便由于显存的原因我们的隐藏层没有像附录中那样设置到 256 而是8，但是跑出来的效果也确实不错。说明这项工作确实是work的

现在需要验证的是将这项工作中的Bug修改能否比它的更好？以及调整 `unlabeled data` 的比例，观察性能。



将 `train_num` 设置成 3.0 感受一下。跑了将近20h（其实这并不是实验的情况）

MAE：0.6663 +- 0.0247

RMSE：0.8984 +- 0.0361

NRMSE：0.0896 +- 0.0093

spearmans：0.7915 +- 0.0109

Precision@100：0.4900 +- 0.0245

ndcg：0.9567 +- 0.0081





* `TMDB5K` 数据（显存不足怎么办）只能调小参数

  将 `num_hidden` 由 256 改为 4。`uhgt_in_dim` 由 10 改 2

```python
python easing/main_easing.py \
--dataset TMDB5K \
--data_path datasets \
--graph_data TMDB5K/tmdb_rel.pk \
--semantic_data TMDB5K/tmdb_lang.pk \
--split_data idx_1000 \
--num_split_idx 1000 \
--gpu 0 \
--cross-num 5 \
--epochs 10000 \
--min-epoch 200 \
--num-hidden 4 \	# 256 -> 4
--num-layers 2 \
--uhgt_in_dim 2 \	# 10 -> 2
--uhgt_heads 4 \
--num-heads 4 \
--train_num 1.0 \
--samp_ssl 5 \
--samp_fq 5 \
--w_ulb 1.0 \
--centrality_gamma 0.9 \
--unc_layers 2 \
--in-drop 0.3 \
--attn-drop 0.3 \
--lr 0.005 \
--weight-decay 5e-4 \
--early-stop \
--patience 500
```



* `IMDB` 数据（将 `num_hidden` 与 `uhgt_in_dim` 调得非常小，才能跑通，跑了14h）

```python
python easing/main_easing.py \
--dataset IMDB \
--data_path datasets \
--graph_data IMDB/imdb_s_rel_150000.pk \
--semantic_data IMDB/imdb_s_lang_150000.pk \
--structure_data IMDB/imdb_s_node2vec_new_150000.pk \
--split_data idx_1000 \
--num_split_idx 1000 \
--gpu 0 \
--cross-num 5 \
--epochs 10000 \
--min-epoch 200 \
--num-hidden 2 \	# 256 -> 2	
--num-layers 2 \
--uhgt_in_dim 2 \	# 10 -> 2
--uhgt_heads 2 \	# 4 -> 2
--num-heads 2 \		# 4 -> 2
--train_num 1.0 \
--samp_ssl 5 \
--samp_fq 5 \
--w_ulb 1.0 \
--centrality_gamma 0.6 \
--unc_layers 2 \
--in-drop 0.3 \
--attn-drop 0.3 \
--lr 0.005 \
--weight-decay 5e-4 \
--early-stop \
--patience 500
```





<table>
  <tr>
    <td colspan="3">FB15K</td>
    <td colspan="3">TMDB5K</td>
    <td colspan="3">IMDB</td>
  </tr>
  <tr>
    <td>MAE</td><td>RMSE</td><td>NRMSE</td><td>MAE</td><td>RMSE</td><td>NRMSE</td><td>MAE</td><td>RMSE</td><td>NRMSE</td>
  </tr>
  <tr>
    <td>0.7505 +- 0.0114</td><td>1.0152 +- 0.016</td><td>0.0995 +- 0.013</td><td>0.6607 +- 0.0304</td><td>0.8269 +- 0.0403</td><td>0.1410 +- 0.0151</td><td>1.1913 +- 0.0079</td><td>1.4956 +- 0.0040</td><td>0.1200 +- 0.0017</td>
  </tr>
</table>



<table>
  <tr>
    <td colspan="3">FB15K</td>
    <td colspan="3">TMDB5K</td>
    <td colspan="3">IMDB</td>
  </tr>
  <tr>
    <td>SPEARMAN</td><td>Precision@100</td><td>NDCG@100</td>
    <td>SPEARMAN</td><td>Precision@100</td><td>NDCG@100</td>
    <td>SPEARMAN</td><td>Precision@100</td><td>NDCG@100</td>
  </tr>
  <tr>
    <td>0.7335 +- 0.0099</td><td>0.4900 +- 0.0245</td><td>0.9507 +- 0.0060</td>
    <td>0.7599 +- 0.0226</td><td>0.6100 +- 0.0261</td><td>0.9036 +- 0.0091</td>
    <td>0.7875 +- 0.0079</td><td>0.5800 +- 0.0385</td><td>0.9581 +- 0.0027</td>
  </tr>
</table>




发现所谓的修了Bug之后怎么效果反而更差？？？花费了 253 min，具体结果如下：

```bash
ndcg:  [0.95207965 0.94485492 0.9392547  0.9500981  0.94212037] 0.9456815481185913 0.004798152000009995
spearmans:  [0.73087509 0.72747766 0.6746616  0.72114046 0.75327097] 0.721485157983899 0.025795284932766116
RMSE:  [1.0109483  1.02717912 1.29107463 1.02992988 1.00363982] 1.072554349899292 0.10970085651105159
NRMSE:  [0.10484014 0.08671468 0.12931378 0.11935765 0.08599216] 0.10524368286132812 0.017278203959428938
MAE:  [0.75732714 0.7495601  1.0012225  0.7697183  0.745821  ] 0.80472976 0.09858614
[0.46 0.48 0.41 0.46 0.48] 0.458 0.025612496949731396
1.0:1:1
```



貌似改错了，应该是将 `-var1s_0_` 改为 `var_unlb_0_pred_0`，再跑一轮看看效果，实在不行把之前的改回去但是 transform 那个我一定是对的，控制变量法来验证一下。

结果如下，也是没有提升！！！生气.jpg，那么只能控制变量法了

```bash
ndcg:  [0.95376992 0.94999856 0.95779634 0.95200104 0.93987644] 0.9506884574890136 0.005985247800179511
spearmans:  [0.73956146 0.72411006 0.74176982 0.71901423 0.74301448] 0.7334940119387522 0.009936444854028318
RMSE:  [0.99687159 1.01901722 1.00109637 1.04173315 1.01707649] 1.0151589632034301 0.015855187293968585
NRMSE:  [0.10338032 0.08602566 0.10026962 0.12072553 0.08714341] 0.0995089054107666 0.012652390764271474
MAE:  [0.74359107 0.747105   0.7413935  0.77291745 0.7479881 ] 0.750599 0.011410436
[0.49 0.5  0.53 0.47 0.46] 0.49000000000000005 0.02449489742783179
1.0:1:1
```



控制变量法寄了，虽然六项指标差得不大，但是只有一项指标要高于原训练的方法。很奇怪，怎么会是呢？？明明源代码看起来都写错了，为什么效果反而更好呢？？结果如下：

```bash
ndcg:  [0.949705   0.94696599 0.95739251 0.95174128 0.94043958] 0.9492488741874695 0.005577708815529987
spearmans:  [0.74505134 0.72106733 0.73813495 0.72436618 0.74376945] 0.7344778490533661 0.009935742818600091
RMSE:  [0.98943359 1.03886592 1.02030039 1.03491402 1.01448107] 1.0195989966392518 0.017563606895565752
NRMSE:  [0.10260896 0.08770128 0.10219309 0.11993526 0.08692104] 0.09987192451953888 0.01209352349210109
MAE:  [0.7401805 0.7612334 0.7660329 0.7717691 0.7465029] 0.75714374 0.011921602
[0.45 0.49 0.51 0.48 0.46] 0.47800000000000004 0.021354156504062614
1.0:1:1
```

不是很懂啊，为什么呢
