# 新能源赛道

## 前言

* 输入和输出总共有 10 个场站：编号1-5：**风电场**；编号6-10：**光伏场**

* 关于输入：
  * 每个场站有 3 个气象源，分别为 `NWP_1`， `NWP_2`, `NWP_3`，每个气象源分别记录了 2024年12月31日 ~ 2025年2月27日 的情况。2 与 1， 3提供的数据有一项不同

* 关于输出：
  * 对于每个场站，预测结果以 `CSV` 格式输出，每个文件包含连续D日的预测数据，每日数据长为 96 行(24 小时x4，即 15 分钟一个预测)，列名为 "power" ，索引为对应的北京时间时间戳（可以见例子）

* 数据为归一化处理后的实发功率。

* 时间间隔为15分钟（北京时间）。

* 数据中可能包含空值、死值等异常值。

* 使用所有数据进行训练直接暴涨将近20个点！！！太亏贼了



## 目前构造的特征

下面是你列出的各个特征字段的中文解释：

------

### ☀️ 与太阳辐射相关的特征：

| 特征             | 中文含义                                            |
| ---------------- | --------------------------------------------------- |
| `ghi`            | 水平面太阳总辐射（Global Horizontal Irradiance）    |
| `poai`           | 面板接收到的太阳辐射量（Plane Of Array Irradiance） |
| `poai_div_ghi`   | 面板辐射与水平辐射的比值（反映倾角优化程度）        |
| `poai_adjusted`  | 调整后的 POAI（可能加入了某些修正项）               |
| `log_ghi`        | GHI 的对数值（用于降低尺度差异）                    |
| `poai_div_t2m`   | 面板辐射与气温的比值（反映温度与辐射间的耦合）      |
| `poai_minus_t2m` | 面板辐射减去气温（差值特征）                        |
| `ghi/poai`       | GHI 与 POAI 的比值（和上面的比值类似）              |
| `ghi_poai`       | GHI 与 POAI 的组合特征                              |

------

### 🌧 与气象变量相关的特征：

| 特征            | 中文含义                                  |
| --------------- | ----------------------------------------- |
| `sp`            | 表压（Surface Pressure）                  |
| `t2m`           | 2米高度气温（Temperature at 2 Meters）    |
| `tcc`           | 云量（Total Cloud Cover）                 |
| `tp`            | 降水量（Total Precipitation）             |
| `u100`          | 100米高度处东西向风速（U分量）            |
| `v100`          | 100米高度处南北向风速（V分量）            |
| `msl`           | 海平面气压（Mean Sea Level Pressure）     |
| `tp2`           | 可能是另一种时间粒度下的降水量（待确认）  |
| `tp_diff`       | 降水变化量（时序差分）                    |
| `rain_category` | 降水类别（如无雨/小雨/中雨/大雨，离散值） |

------

### 🌬 与风相关的特征：

| 特征           | 中文含义                               |
| -------------- | -------------------------------------- |
| `wind_speed`   | 风速（可能是由 u100 和 v100 合成的）   |
| `wind_energy`  | 风能（常为风速的三次方，风功率近似值） |
| `wind_dir_sin` | 风向的正弦值（用来平滑风向）           |
| `wind_dir_cos` | 风向的余弦值                           |

| `wind_speed/sp` | 风速与表压比值（复合特征） |

------

### 🔋 与目标变量相关：

| 特征    | 中文含义                 |
| ------- | ------------------------ |
| `power` | 场站输出功率（预测目标） |

------

### 🕰 与时间相关：

| 特征                    | 中文含义                                   |
| ----------------------- | ------------------------------------------ |
| `hour`                  | 小时（0~23）                               |
| `month`                 | 月份（1~12）                               |
| `day`                   | 日（1~31）                                 |
| `sin_time` / `cos_time` | 时间周期编码（通常是小时/日转成周期特征）  |
| `time_of_day`           | 一天中的时间段分类（如凌晨、上午、傍晚等） |

------

### 🌦 综合气象描述：

| 特征      | 中文含义                                                 |
| --------- | -------------------------------------------------------- |
| `weather` | 天气类别（如晴/阴/雨，分类特征，可能通过规则或模型识别） |

------

这些特征大多数属于新能源发电预测中常见的气象与环境变量组合。你要不要我帮你画成一个特征分类图或者推荐做哪些特征筛选与降维？



## 日记

* **经过测试，以下由`GPT` 构造出来的构造貌似对成绩提升微乎其微**

  * 从 0.2926 ~ 0.3214

* 考虑将 `NWP_1~NWP_3` 的数据合并，

  * 经过数据可视化（以1月的30天为例），可以发现，NWP_1 与 NWP_3 的数据在各项指标上貌似都能比较好的重合，所以我们可以考虑对这两组数据取平均而非进行 `cat` 操作
  * 但是可以发现在对比  NWP_1 和 NWP_2 的数据时，大部分数据在各项指标上也能比较好的拟合，除了 `tp` （总降水量）不太拟合；此外 `tcc` （总云量），`v100` 与 `u100` 变化趋势接近，但是数据并不是能特别好的拟合，但是挺相近的。
  * 后续又观察了几个月份的数据，发现我们可以考虑将 `tp` 单独拎出来，即  NWP_1 与 NWP_3 的平均为一组 `tp1` 与 NWP_2 的TP 也为一组 `tp2`
  * 检查了几个站点，发现分布基本大同小异，除了 `tp` 这个特征，其余的特征分布走向都差不多，就是数值大小的问题。
  * 最终我们考虑如下处理
    * 将 NWP_1与 NWP_3的大部分数据取均值，将 NWP_2 中的数据 `msl` 取出来，其 `tp`  属性也取出来作为 `tp2`.
    * 训练十个发电厂的数据而不只是训练一个发电厂（这是提大分的一个点）
    * 最终分数 0.3214~0.5196

* 先重构一下代码；考虑将天气分箱，将降水量的单位转化为 mm，一天的时间分为凌晨、夜晚、下午、上午、中午这一时间段；考虑使用 xgb对特征重要程度进行排序，重要程度高的特征再引入时序特征；原来操作是将每小时的四条数据去掉三条，我们可以考虑预测每小时的四条数据然后取平均值；考虑加入网格搜索以及融合操作

  我们对 catboost 选出的 top-10 特征以及 corr 的 top 10 特征取并集，结果并发现大部分我们构造的特征（尤其是一些类别特征）并没有加入到其中....目前在用网格搜索进行模型训练，训练结束之后考虑进行融合操作然后提交一下，看看得分情况。

  特征为 `['poai_minus_t2m', 'log_ghi', 'weather', 'wind_dir_cos', 'u100', 'poai_div_t2m', 'wind_energy', 'wind_speed', 'sp', 'wind_speed/sp', 'ghi', 'poai_adjusted', 't2m', 'poai_div_ghi', 'v100', 'poai']`

  感觉我还是没有领悟到这个赛题的精髓，没有彻底理解赛题，一直在向一只无头苍蝇那样去试特征（其实非常的低效）

  得分为 `0.5087` 越来越垃圾（说明特征不是越少越好）；网格搜索要跑很久，我给取消了。。

* 在 xhs 看到一个帖子，分别对1~5 和 6~10 进行训练，然后对发电功率进行加和！（难道说这里是提分点？）

  喜提 `0.3843` ！直接相加绝对有问题（==妈的我智障了，我把1~5的数据乘了两倍.......怪不得直接炸了我是猪我是猪我是猪我是猪==），要么索性1-5只留下与风电相关的数据，6-10只留下与广电相关的数据

  我把电厂分开处理达到了 `0.6116` 了！！还得是群友~

* 现在还想到了一种手段来进行优化：数据清洗优化，风力对光伏发电影响小，夜晚光伏发电几乎没有，可以先行可视化，然后取有效区间的数据。也就是说分别对 1~5 与 6~10进行针对性的特征优化（保留一些更有价值的信息？），后续还可以考虑stack方法再提一点分

  使用权重融合，分数反而还更低了 `0.6104`

  目前最高：0.6116/188
  
* 根据群友的反馈，发现某些表格的数据存在问题第六、八九场（不止）。某些场站的输出文件 `output` 的 `power` 是负值，这显然不对。貌似是有些测试集数据缺失或者出现了大量的 `NaN`。我们需要考虑清洗数据，将这些处理掉。应该能提一点分。

  目前最高：0.6116/196

  发现测试集的数据都是正常的，没有缺失值，问题应该出在训练集。发现6 ~ 10 个场中出现了 200 个 `power` 的缺失值
  
  经过删除异常值以及平滑处理（训练之前的label使用 log，将得到的label使用exp进行还原） + stacking，得到分数为 0.6179/188；直接平均的效果反而更好0.6191/187
  
* 后续可以考虑

  数据清洗优化：风力对光伏发电影响小，夜晚光伏发电几乎没有，可以先行可视化，然后取有效区间的数据。

  可以多个模型结合预测：加入深度学习的时序预测

  交叉验证的次数增加：可以变为10折 0.6195/186

  群友的经验：全自动计算的只有0.62。在此基础上，如果再根据线上评分的反馈做微调，可以接近0.68。例如，所有项目，或按风电、光伏项目，或单个项目的 预测功率，如果整体提高或降低一定幅度，线上得分的变化情况。从而了解改进方向。我还没有单个项目去测，可以去了解一下~
  
* 20折交叉验证从0.6195提升到了0.6197..目前在使用更细腻的参数调参三个树模型，并打算学习一下正规的调参流程

  使用更细腻的调参发现数据并没有向预想的结果升高（为 0.6191），并且在训练的过程中发现并没有学习到最优模型
  
* 我们对特征可以考虑以下处理：

  > 光伏（光电场）部分（表6~10）：
  >
  > - **夜晚**没有太阳，所以**夜晚的光伏发电几乎为零**。
  > - **风力**对光伏发电影响很小，所以在分析光伏发电时，可以**弱化风力特征**的作用（比如 u100、v100 可以作为次要特征）。
  > - **poai**（光伏面板辐照度）和**ghi**（水平面总辐照度）是光伏发电的直接影响因素，非常重要。
  > - 因此，**可以先画 poai、ghi 的时间序列图**，==观察什么时间段有明显的辐照度（即白天），然后**只保留白天有效数据**来建模，夜晚的可以丢弃或标记处理。==（我选择了标记处理，即将其直接作为0处理）
  >
  > 风电（风电场）部分（表1~5）：
  >
  > - 风电主要受**风速**（u100、v100的合成）影响，和昼夜关系不是特别强（风白天晚上都可能有）。
  > - 因此，对风电来说，**不一定要剔除夜晚数据**。
  > - 风电场可以重点使用风速信息，t2m（气温）、sp（地面气压）等也可能影响空气密度，间接影响风机功率，因此也可以考虑。
  >
  > 整体思路总结
  >
  > 1. **可视化**：
  >    - 画出 poai 和 ghi 的时间序列（按小时或15分钟粒度）；
  >    - 找出白天时间段（比如 poai > 某个阈值，比如 10W/m²）；
  > 2. **筛选数据**：
  >    - 光电场数据只保留有效发电（白天）的时段；
  >    - 风电场数据可以整体保留。
  > 3. **特征选择**：
  >    - 光电场模型重点考虑 **poai、ghi、tcc**（云量）；
  >    - 风电场模型重点考虑风速（u100、v100合成），t2m、sp次之。

  发现了发现了，我们在表6~10中发现，在一些没有光的时间段，`power`就是会出现大量的0，如果把这一部分解决可以提分不少。

  感觉还得添加一个月份信息（已添加，后面完全不知道该怎么处理了...）

  整理了一下思路，打算这样处理：

  首先在训练集中给筛选出 power = 0 的数据，然后将这些数据的 time_index	hour	minute	month	 day属性保留下来，取出测试集中对应的这一部分数据将数据，。令其power = 0；测试集中另外的部分输入到训练好的模型中（该模型使用的是训练集中 power > 0 的数据训练）

  另外的话，删除一些不必要的 `col` （比如说 `time_idx`），结果最终还是保留了。
  
  效果不理想效果不理想效果不理想最好的只有 `0.6137`！我要黑化了
  
* 考虑对单个项目进行测试一下。达到0.6213 / 194！！！太不容易了。而且训练了 1 h 终于看上去像是拟合了。（早上起来已经在rank200了，太卷了...）

* 考虑加入时序进行训练了，貌似也可以自定义损失函数，让模型学得更好一点？尝试一下

  很烦，不会使用LSTM进行训练...
  
* 很迷茫了，到现在还不知道怎么使用LSTM进行训练。

  发现数据处理好像出锅了，貌似没有对应起来？？？？是之前的 baseline 中处理时将四条数据整合成一条数据了。。。

  ==具体来说是这样的：==

  > 训练集 `train` 中给了 `2024-01-01~2024-12-30` 的数据。而 `target` 中给了 `2024-01-01~2024-12-31`的数据，也就是说题意是让我们预测后一天的数据（即真正的target是取后一天），这样的话就能匹配上了。
  >
  > 但是训练集中给我们的数据规模是（365 * 24 = 8760）即以每小时为时间间隔给出，而 target 文件中的数据则是（366 * 24 * 4 = 35136）即间隔15分钟给出。

  ==所以说之前数据的清理出锅了！！！很烦，我误认为是以15分钟为尺度进行的处理，从而误设了`minute` 这个特征==

  

  目前大致是调好了特征，明天再细看一下特征，并且把LSTM的时序代码处理好

  

  如果要进行LSTM训练的话，那么得重新组织数据，就不能在数据预处理的时候加载后15分钟的数据作为标签，而是使用此时的数据作为标签。

  * 如何处理测试集

* 目前先把能够批处理的给写完，但是批处理我们不以批次为10进行处理，而是以批次为5进行处理，即风电一组，光电一组进行处理。

* 我现在需要解决的问题是，如何正确地对这 5 + 5 电厂进行批处理预测。

  我现在有5组数据，每组数据有8760（8760 = 365 * 24）条数据，包含了一年中每个小时的气象信息。因此总共有8760 * 5 = 43,800 个样本。我现在想分成5个批次进行训练，但是由于时间窗口的缘故，会丢失一些数据（两天的数据，即48条）。然后导致出现了不完整的批次。以下是考虑的手段

  * 直接按组划分，每组作为一个独立批次

    > - **步骤**：
    >   1. **预处理**：对每组数据单独应用滑动窗口，每组得到 `8712` 条样本。
    >   2. **批次划分**：直接将每组数据作为一个批次（`batch_size=8712`）。
    >      - 每个批次形状：`(8712, 窗口大小, 特征数)`。
    >   3. **训练时**：按组（批次）迭代，无需拼接不同组的数据。
    > - **优点**：
    >   - 完全避免批次不完整问题。
    >   - 保留组内时间连续性，适合组间独立、组内连续的场景（如不同地点的气象数据）。
    > - **缺点**：
    >   - 批次极大（`batch_size=8712`），可能内存不足。
    >   - 需确保模型支持变长输入（如LSTM/Transformer）。

* 发现输出全是 `np.nan` 自闭了，进度好难推进我真有点自闭了

* 目前遇到的问题

  * 计算输出全是 `np.nan` 
  * 批处理的方式总感觉很别扭（还是没有完全理解批处理在时序数据）
  * 计算 acc 的方式不是很好
  
* 初始数据给的数据居然就有 nan 值，我以前还没有发现，今天才发现。而且每一个场站都有 nan 值数据，我来看看到底是哪些数据出锅了。

  * 发现是在计算 `tp_diff` （降雨量差分）这项属性时，出现了 NaN，每天的第一个数据为 NaN。我们用 0 进行填充。处理之后，发现还是会有部分数据出现了 `NaN` 情况

    ```python
    (8760, 1)
    (8760, 1)
    (8760, 1)
    (8760, 1)
    (8760, 1)
    (8758, 1)
    (8760, 1)
    (8732, 1)
    (8717, 1)
    (8633, 1)
    ```

    

* 貌似模型训练炸了，那个 `input_size` 是不算 `target` 那一列的，我给算进去了。。。（即应该是31但是我设置成了32）但先不管，先把预测功能写出来再说...

* 现在脑子非常混乱，感觉寄了。我要好好组织一下这个架构，思考该怎么规划代码

* **LSTM做时间序列预测时间序列长度应该怎么设置？**

  > 具体化这个回答:就像天气预报一样，如果历史数据够多，我可以用过去到现在为止10天、一个月甚至一年的数据来预测明天**一天**的结果，这个预测效果当然是比较好的;要是数据量有限怎么办，就用今天来预测明天或者前3天预测明天等等。在数据集有限的情况下，步长越小样本越多。因此，我们需要权衡的是步长要够大，样本量也要足够学习和测试。（**这里语境下的步长指的是历史输入长度也即滑动窗口的时间跨度**）
  >
  > 这段话强调的是：**在数据有限的前提下，需要在“历史输入长度（步长）”和“训练样本数量”之间做一个权衡。**
  >
  > 我之前犯得大错误是:我理解成用3步预测5步、10步了!**实际上都是前很多步预测下一步(因为这样是最准确的)。**那么，别人的文章为什么预测的步数那么多?是采用了移动窗口的方法，真实的123预测4，真实234预测5，一直循环下去，预测出456789。预测时，每次都把真实值再带入了一次(更改输入数据)。若不用真实的数据输入转而用当前预测的，也就是说，我用真123预测4，下一步就是真23预4来预测5。**这样的效果是，误差会累计，结果会越接近上一轮值，直到没有任何趋势(直线)。**
  >
  > 
  >
  > 作者：海底月
  > 链接：https://www.zhihu.com/question/429976362/answer/1581271976
  > 来源：知乎
  > 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

  所以我们得到的经验是：若数据足够多，那么我们可以用多步来预测一步，体现在本任务上就是我们可以考虑使用一周（7 * 24 = 168h 来预测一天 24h）的数据；或者考虑使用（24h的数据来预测1h的数据）

  GPT的建议：

  > ✅ 如果你有**足够多的高质量历史数据**，并且模型（如 LSTM、Transformer 等）能够处理长序列，**建议使用「方法1」**：用一周（168h）预测一天（24h），可一次性生成完整预测，更适合当前这种**预测整天功率曲线**的任务。

  > 🔄 若数据不多、模型较简单、或者你在调试阶段，**可以从「方法2」入手**，快速实现滚动预测逻辑，再逐步扩展。

  考虑到我们的数据是以年为单位的（数据量比较多，并且我们也想捕捉到周期性）因此选择方案一应该是需要考虑的。我们首先从人类的视角直观地来理解应该选择怎样的时间步长，再进行实验（此外，针对seq_len的设置，最好设置成能够包含周期的seq_len，比如一天、一周）。**还有就是LSTM能够有效的步长（seq_len）是有限的，3000步肯定是已经失效了，即早就忘记前面的信息了**。

  这样的话，在训练时，我能构造的训练样本数量为： $N = 8760 - 168 - 24 + 1 = 8569$ 即我的 `train_loader` 中会有 8569个样本对。

* 针对我的任务，`batch_size` 该怎么设置？以及是否应该打乱即 `shuffle=True`（我还是不能理解和接受这一块，尤其是在我有场站的情况下）

  我纠结的点其实就是在于分批次训练是不是会将时序这个非独立性的属性给”独立化“掉（因为分批次并行训练的话，不同批次的数据可以看成是独立的，但并非完全独立，因为它们的损失会一起影响模型的更新，相对纯串行训练，方差是更小的，更稳定的）。所以分批次能更好地带来模型的稳定性以及训练效率。

  至于分批次能否影响时序这个属性，对模型性能产生影响以及是否应该 `shuffle` 我有以下思考。

  首先需要理解的是，如果仅仅只是分批次，那么数据本身仍然是连续的，只是在训练或处理时被分成了若干小批次（btch）来进行，这通常是为了提高训练效率或减小内存消耗。可以举一个例子来进行直观上的理解，假设我有一个连续的时间序列的数据：
  ```csharp
  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
  ```

  如果用 batch_size=2 分批次训练，那么数据在训练时会被切分为：

  ```less
  Batch 1: [1, 2]
  Batch 2: [3, 4]
  Batch 3: [5, 6]
  ...
  
  ```

  但是这些数据**本身是连续的**，你只是每次喂给模型两个数据点而已。

  回到问题，虽然 `batch` 虽然看起来”打破了时序的连续性“，但是在每个 `batch` 中，样本是完全连续的，因为 `seq_len` 这一维度上的数据就是时序构建的，我们选取了一周 7  天的数据。所以 `batch_1` 可以认为是`batch_size` 个样本，每个样本是 7 天的数据，也就是 `batch_size x seq_len`， `batch_2` 以此类推，`batch`之间是独立的，但 `batch` 内部是连续的。并且需要注意的一点是：**模型的时序建模能力仍然体现在样本内部的时间维度上，而不是 `batch` 之间的顺序。**（我们可以对每个样本数据设计时序顺序来更好地保证模型质量，比如说月份，小时，季节），我们的 `seq_len` 设计的就是一周七天，再结合样本的属性，模型是能出色地预测出下一天的数据的，我们只需将这`七天 *  batch_size`的特征捕捉即可，**模型只需要在每个样本内部捕捉时序依赖，不需要跨样本记住前后信息**。）。其实一个批次里面也有挺多数据了，也够了。~~如果不使用批处理，那么整个时序太长了，模型根本记不住，效果反而可能会更差。~~（这段的理解其实是有误的，模型能否记住与批次无关，与 `seq_len` 的大小有关）

  虽然批次之间样本在时间上不连续，但**我们不期望模型学习跨样本的时间依赖**，因为我们**已经人为将序列片段分割成建模单位**，每个样本独立建模即可。这样来看的话，我们可以放心将批次打乱了（`shuffle = True`）。而 `batch_size` 的选取就是正常的从32、64、128中去选。
  
  而我之前的顾虑：为什么不以场站的数量为批次，每个场站的所有数据为一批进行训练（这样操作的话，`batch_size = 8569`， `seq_len = 168`（不变） ，那么 `len(train_loader) = 10`（`batch` = 10））批次太大了，将会极大降低梯度的方差，使得每次参数更新的方向变得过于“精确”，从而让模型在训练过程中更容易陷入陡峭但非全局的最小值，或者鞍点。
  
  **其实只要抓住本质：LSTM模型主要还是看 `seq_len` 这一维度上的数据（此处才是用来训练时序的），这里的数据不能乱！究其原因，我之前都是将 `batch` 这一维度和 `seq_len` 这一维度所充但的任务搞混了才会发出这种疑问**【针对我的任务，`batch_size` 该怎么设置？以及是否应该打乱即 `shuffle=True`（我还是不能理解和接受这一块，尤其是在我有场站的情况下）】（现在已理解）
  
  **因此目前我打算将前五个场站的数据合并，后五个场站的数据合并。然后 `shuffle = True` 并且设置 `batch_size` 进行训练，考虑设置为 64 或 32**，但是我还要写一份每个场站单独训练的代码，要思考并规划一下。

* 模型训练好了，我们有一组测试数据（1416 = 24 * 59），也就是说要得到1416个`target`，我们能做到test 中原本的前168个`target` 不丢失吗？是不是前 168 个 `target` 会丢失？

  是的，若按照**正常的预测过程**为：

  ```python
  x[0:167] → 预测 y[168]
  x[1:168] → 预测 y[169]
  ...
  ```

  我们需要在测试前额外准备一段历史（前 168 条）输入特征，即可完整预测 1416 个 `target`！（总数其实是1417个，我们考虑将最后一个结果剔除掉）

  若没有我们可以考虑**从训练集或验证集的末尾取出最后的 168 条输入特征数据**，拼接到测试集的前面，作为测试时的“历史上下文”。这样，模型就能用 `[train[-168:], test[:1416]]` 的滑动窗口来预测 `target[0] ~ target[1415]`。

  这种处理确实会引入轻微误差，但这是无法避免且普遍接受的做法。而**这是时序预测里业界、学界都默认接受的策略**；虽然会有误差，但这是我们可以接受的。

* 如果样本数量没有达到 `batch_size` 的整数倍，那么在训练时和预测时会怎么处理？

  默认（`drop_last = False`）都会选择继续处理小批次（`mini_batch`）模型会用这个小批次进行训练/预测并返回结果，剩余部分的样本不会被丢弃。

* 至此，我大致是懂了使用滑动窗口进行时序训练的流程了。

* 为什么我训练模型时候的输入数据 `seq_len` 为 168 。我现在为 `.eval` 形态，要进行预测，输入数据的 `seq_len` 为 1440 为什么能正常返回结果？？

  事实上，只要 `input_size` 匹配就能正常工作。我们写过 LSTM 源码的， `seq_len` 只是决定了你跑的序列长度（可以回忆一下源码 `for i in range(T):`）。我模型里没有任何依赖 `seq_len = 168` 的参数，所有的 `nn.Module` 层（LSTM、LayerNorm、Dropout、Linear）都不关心 `seq_len` 长度，所以 `seq_len=1440` 在推理阶段也是完全合法的。

  虽然模型在结构上允许任意 `seq_len`，但：

  - **训练时只见过 168 步长的序列**；
  - **你让它一次性跑 1440 步，可能效果极差，甚至累积误差严重**；
  - LSTM 对于很长序列会面临记忆能力下降的问题。



* 目前在重构代码，最好（务必）思考实现一下将验证集的 `target` 与 `pred` 可视化展现出来（更加直观地检验模型的性能）！！！，考虑添加 `stride` 模块



* 第一组 `test` 貌似寄了，==模型输出清一色全是 0.1403==，很烦....这说明它**没有学到时序动态或有效特征，只是学会了输出一个常数或近似均值**。

  这该怎么办啊。

  > ## 🔍 可能原因分析
  >
  > ### 1. **模型欠拟合**
  >
  > - LSTM太浅（`hidden_size`太小、`num_layers`太少）；
  > - 训练轮数不够；
  > - 学习率太小，优化器没动起来。
  >
  > ### 2. **训练集/标签问题**
  >
  > - 数据归一化后方差极小，模型学成了“输出均值”；
  > - 标签全为 0 或几乎恒定；
  > - 没有打乱训练数据，模型提前过拟合某种模式。
  >
  > ### 3. **loss 和梯度消失**
  >
  > - 如果你用的是 `MSELoss` 且训练时输出值卡在小范围内，可能梯度太小更新不了；
  > - 初始化不合理，或者激活函数（比如某些 ReLU）导致梯度为 0；
  > - 也可能是 LSTM 初始状态固定而没有训练/传入变化。

绷不住了，模型的训练损失（Train Loss）在逐步增加，而验证损失（Val Loss）也在波动，并且验证准确度（Val Acc）逐渐下降。这辈子有了。

明天感觉得好好看看[李世强](https://mp.weixin.qq.com/s/mKxOn9kRSrDn3UN443vxsQ)大佬写得文章了

* 现在的问题是这样的。我的LSTM训练效果是依托，首先在1-5场站的数据上非常答辩。然后在6-10场站的训练表现虽然看起来还行，但是在预测值上的输出基本是同一个值，没有任何的变化，这表明模型基本没有学到什么东西，只是学到了一个平均值。这通常说明模型**退化成了“平均预测器”**，即忽略了输入特征，仅输出一个近似常数。这种情况在时间序列预测中比较常见。问了下GPT，它指出可能有以下问题：

  > #### 1. **模型过拟合/欠拟合或退化**
  >
  > - 验证精度较高，但预测结果单调，说明模型可能只学会了某种“固定趋势”。
  > - 对训练集拟合得很好，但没有学到输入特征与输出之间真实的时间动态关系。
  >
  > #### 4. **滑动窗口构建有问题**
  >
  > 你这里用了：
  >
  > ```python
  > for i in range(len(tmp_data)):
  >     if (i + args.window_size < len(tmp_data)):
  >         new_data.append(tmp_data[i: i + args.window_size])
  > ```
  >
  > - 这构造的是一个滑动窗口，但你最后预测的是：
  >
  >   ```python
  >   res2 = res2[:, 0, :]
  >   ```
  >
  >   即预测每个窗口的**第一个时间点的输出**，这可能与你训练时的 target 设置不一致（你应该预测最后一个，或者一个未来 offset）。
  >
  > #### 5. **模型预测的是多步值，但你只取了第一步**
  >
  > - 如果模型训练时是输出整个序列（`seq2seq` 式），但你只取了 `res2[:, 0, :]`，就可能导致输出值误差堆积。

  事实上，针对4、5，我的逻辑上应该没有问题，但为什么会寄呢？？？先不管了

  考虑 `win_size = 168` `pre_len = 1`来进行训练模型呢？貌似更加符合我的需求

  GPT 说这样设置的优点：

  > **模型更简单、收敛更快**
  >  模型不需要学习未来 24 个点的序列，只需关注一个点，训练目标更清晰，效果反而更稳健。
  >
  > **更匹配真实需求**
  >  如果你的评估指标、比赛需求、实际业务都只关注“下一小时的功率”，那预测 24 小时反而是资源浪费。
  >
  > **减少过拟合风险**
  >  预测 24h 本身难度更大，误差可能扩散或累积。而预测 1h 更容易对齐 label，有利于模型泛化。
  >
  > | 项目         | 当前结构 (pre_len=24) | 建议结构 (pre_len=1) |
  > | ------------ | --------------------- | -------------------- |
  > | 是否匹配需求 | ❌预测太多，浪费       | ✅预测目标明确        |
  > | 模型训练难度 | 较高                  | 更低                 |
  > | 训练速度     | 慢                    | 更快                 |
  > | 泛化风险     | 较高                  | 更低                 |
  >
  > ✅ **你完全可以改成 `win_size=168`，`pre_len=1` 来训练模型，而且这是更合适的方式。**

  虽然测了一下感觉比之前好了，但是数据太平滑了（过拟合可能有点严重），感觉根本捕捉不到输出之间的差异的特征

  我的情况符合以下特征：训练集 loss 超低，val loss 忽高忽低，并且预测很平，那是明显的**欠拟合 + 过拟合交叠**。

  - **建议**：
    - 增大 `hidden_size`（比如从 64 改为 128 或 256）
    - 加更多 Dropout（比如 0.3 ~ 0.5）
    - 减少层数（例如 1 层 LSTM 可能效果更好）

* 李世强大佬的跑了0.6434，恐怖如斯

* 我发现李世强大佬的 `standerdize` 只是针对部分特征进行了标准化，这不是重点，重点是它针对的是对每个特征**这一列**进行归一化，而不是对行进行归一化；~~看一下我代码的操作：是对整个批次进行归一化~~。并不是，其实我的归一化也是针对每个特征维度进行标准化处理。不同的是，李世强的代码是对每一个场站 `pid` 的每一个数据源 `src`  的表格进行处理，存储其归一化之后的 `mean` 与 `std`，而我的操作则是对五个场站直接进行归一化处理。李世强的处理粒度更加细。具体来说，李世强的归一化处理策略又细分了以下几种：

  1.  `strategy = "space"` : 按时间片，在每个时间点上做空间归一化，对每个 `forecast_time` 的时间点，**将该时间点对应的所有空间位置（例如多个网格点）上的特征做标准化**。
  2. `strategy = "global"` : 全局标准化，对该 `source` 下所有时间、所有空间的数据整体做一次标准化。
  3. 其他补充：李世强的标准化处理的数据对象仅是 `cols`列，而非  `cols + target` 列

   而李世强默认采用的是策略2，所以本质上我的归一化和他的标准化最大的不同其实就是他是对一个场站进行标准化，而我则是对五个场站进行标准化。

  事实上，在标准化策略上，应该更推荐李世强的做法，为什么？**因为此方法能保留每个场站的原始变化趋势**

  > 原因如下：
  >
  > 1. **功率和气象数据在不同场站间差异大**（风场/光伏场的地理条件不一）；
  > 2. 如果你对每个场站训练一个模型或训练时使用了 `pid` 作为索引，那应该保证输入数值的尺度是匹配该场站自身分布的；
  > 3. 数据源 `src` 的误差结构、分布范围也可能不同，分开处理更稳妥；
  > 4. 对 LSTM 这种模型而言，输入值的尺度一致性和时间结构一致性至关重要，全局归一化可能破坏时序结构。

* 我要考虑重构代码了，借鉴一下李世强大佬的思路

  * 这个貌似搁了


* 不是，怎么突然抽风似得跑这么好了，我寻思我也没动代码啊。怎么突然数据跑得这么好了？？？当然还没提交去验证呢？验证喜提0.0171草泥马的。为什么啊啊啊啊啊啊啊啊，我自闭了
  * 我修改了一下初始化权重


## 对数据清洗的思考

清除一些死值数据



## 对特征构造的思考

| **变量** | **描述**             | **单位**           |
|---------|----------------------|--------------------|
| u100    | 100米高度纬向风      | m/s（米/秒）       |
| v100    | 100米高度经向风      | m/s（米/秒）       |
| t2m     | 2米气温              | K（开尔文）        |
| tp      | 总降水量             | m（米）            |
| tcc     | 总云量               | (0 - 1)            |
| sp      | 地面气压             | Pa（帕斯卡）       |
| poai    | 光伏面板辐照度       | W/m²（瓦/平方米）  |
| ghi     | 水平面总辐照度       | W/m²（瓦/平方米）  |
| msl     | 海平面气压           | Pa（帕斯卡）       |

### trick

* 计算各特征（包括我们构造的特征）与目标变量的相关系数（或者利用xgboost进行特征重要度排序），可以去掉一些与相关系数无关的特征
* 可以考虑将一天的时间分箱（凌晨，早晨，上午，中午，下午，晚上）





### 风速风向与空气密度

对风速 `u100` 和 `v100` 

* 利用 合力风 作为风速特征（**与风速大小成3次方关系**）

  * 风电机组的发电功率与风速之间的关系一般近似为（我们甚至可以直接将这个式子构造出来）：

  * $$
    P = \frac{1}{2} \rho A v^3
    $$

  * 其中：

    - $P$：发电功率

      $\rho$：==空气密度==

      * 我们可以利用地面气压 `sp` 与气温 `t2m` 来粗略估算空气密度，具体计算代码为：
        ```python
        rho = sp / (287.05 * t2m)  # sp 单位 Pa，t2m 单位 K
        ```
      
      $A$：风轮扫掠面积
      
      $v$：==风速的模长（即风速大小）==
      
      而 100 米正是风电机组常见的风轮高度，因此这个高度的风速是直接影响发电量的关键因素。

* 加入==风向==$\theta = arctan2(u,v)$作为额外特征

  * #### **1. 使用 arctan2 计算风向角**

    ```python
    import numpy as np
    # u: 纬向风速（正为东风），v: 经向风速（正为北风）
    # 计算风向（气象学标准）：风从哪个方向吹来
    wind_dir = (270 - np.degrees(np.arctan2(v100, u100))) % 360
    ```

     注意：

    - `arctan2(v, u)` 会返回风速向量指向的角度（从正东逆时针起算，单位是弧度），通过转换，我们得到**风从哪里吹来**（以正北为0°，顺时针）
    - 这样计算出来的风向符合**气象学的习惯**

    **周期性风向如何用于建模？**

    风向是周期变量，不能直接输入模型（若不进行处理，模型会认为0°和360°差很大，可实际上它们是同一角度）。你可以通过**正余弦编码**解决它的周期性：

    ```python
    wind_dir_rad = np.radians(wind_dir)	# 将角度制转换为弧度制，方便后续输入 `np.sin` 等函数
    wind_dir_sin = np.sin(wind_dir_rad)
    wind_dir_cos = np.cos(wind_dir_rad)
    ```

    然后就可以把 `wind_dir_sin` 和 `wind_dir_cos` 作为模型的输入特征。

    | 步骤 | 处理方法                                                     |
    | ---- | ------------------------------------------------------------ |
    | 1    | 有 u100、v100（范围可正可负）                                |
    | 2    | 计算风向（`(270 - arctan2(v, u) * 180/π) % 360`）            |
    | 3    | 正余弦编码风向                                               |
    | 4    | 构造成模型输入特征：`[u100, v100, wind_dir_sin, wind_dir_cos]`（可加风速模长） |

* 若为风场级建模，还可以引入风向与风机排布关系（比如是否顺风）作为空间特征

### 光照相关交叉项

我有：

- `poai`（面板辐照度）
- `ghi`（水平总辐照度）
- `tcc`（云量）

考虑计算：

- `poai / ghi`：面板效率或云遮影响比

  - 比值接近1：说明面板接收的辐射与水平面接近（可能是面板水平放置，或云层影响较小）。

    比值远小于1：可能是云层遮挡严重，或面板朝向/倾角不理想。

- `poai * (1 - tcc)`：考虑云层遮挡修正

  - 用于修正云层对实际辐照的影响（假设云层均匀遮挡辐射）。

    但实际中云的影响非线性（如厚云和薄云差异大），此计算仅为近似。

- `log(ghi + 1)`：可缓解高值影响，常见对数变换

  - 在统计分析或机器学习中，对数变换可使数据分布更接近正态分布，提高模型稳定性。

### **归一化大气压**

- 用 `sp / msl` 表示站点地形相对海平面变化的特征



### 时间序列特征

#### 时序窗口特征

例如过去几小时的统计量：

- 滑动均值/最大值/最小值/标准差（如过去1h、3h、6h）
- 滞后特征（如 t-1、t-2）
- 变化率：`delta_feature = feature_t - feature_(t-1)`

这类特征能提供动态趋势信息，对 LGB/XGBoost/LSTM 都很有效。

#### 周期性时间特征

你预测的是“未来24小时内逐15分钟发电功率”，所以要加入：

- `hour`（小时数）
- `minute`（分钟数，或 quarter 编码成 0~95）
- `sin_time = sin(2π * time/96)`
- `cos_time = cos(2π * time/96)`

类似风向的处理方法，用来建模**昼夜周期**



### 交叉组合特征

高温可能降低光伏组件效率（高温可能会影响半导体功效？），可以构造：
 `poai / t2m`，`poai - t2m` 等



### 统计或历史特征（需要有历史功率）

如果你手上还有**历史的功率数据**，可以做：

* **过去功率的移动平均**

  - 如 `mean_power_last_1h`, `mean_power_last_6h`

  - `power_t - power_(t-1)` 观察波动

* **历史相同时间段功率**
  - 去年/昨天的同一时间点功率（适合有明显日周期的光伏）



### 空间特征怎么利用？







## 工程技巧

### 树模型调参流程

> ### **Step 1 - 确定基础参数（主要是树模型基本结构）**
>
> - `objective`
>   - 回归问题：`reg:squarederror` / `regression`
>   - 分类问题：`binary:logistic` / `binary`
> - `eval_metric`
>   - 回归用 MAE、MSE；
>   - 分类用 AUC、Logloss；
> - `random_seed`
>   - 设定好随机种子，比如 2023。
>
> ------
>
> ### **Step 2 - 调 learning_rate 和迭代次数**
>
> - **学习率小一点**（比如 `0.05` 或 `0.01`），
> - **iterations/boost_round大一点**（比如 `20000`次）
> - 加上 `early_stopping_rounds=300`，防止跑死。
>
> **核心想法**：
>  👉 **低学习率 + 多迭代**，模型能学得细腻，泛化性好。
>
> > 示例：
> >
> > ```python
> > learning_rate=0.05, iterations=20000, early_stopping_rounds=300
> > ```
>
> ------
>
> ### **Step 3 - 调模型复杂度（控制欠拟合/过拟合）**
>
> - 控制每棵树的复杂度，主要参数：
>   - `depth` （树深度，5~8）
>   - `num_leaves` （LightGBM特有，一般 `2^(depth)`）
>   - `min_data_in_leaf` / `min_child_weight`（每个叶子的最小样本量）
>   - `max_bin`（特征离散化的精度）
>
> **核心想法**：
>  👉 树太深容易过拟合，太浅容易欠拟合。
>  👉 保证train和val同时下降，但val不会突然变差。
>
> ------
>
> ### **Step 4 - 调采样参数（提高泛化能力）**
>
> - 随机采样控制：
>   - `subsample` / `bagging_fraction`（每棵树用多少数据，建议 0.6~0.8）
>   - `colsample_bytree` / `feature_fraction`（每棵树用多少特征，建议 0.6~0.9）
>
> **核心想法**：
>  👉 让每棵树「看到不同的数据」，提升模型鲁棒性。
>
> ------
>
> ### **Step 5 - 加正则防过拟合**
>
> - `reg_lambda`（L2正则化）
> - `reg_alpha`（L1正则化）
> - `random_strength`（CatBoost独有，加强随机性）
>
> 通常：
>
> - **如果train太好val不行** ➔ 慢慢加正则，比如 `reg_lambda=5~20`。
>
> ------
>
> # **标准调参顺序小总结**
>
> ```
> text复制编辑确定基础参数
>       ↓
> 先调学习率、迭代次数
>       ↓
> 再调模型复杂度（depth/num_leaves）
>       ↓
> 再调采样参数（subsample/colsample）
>       ↓
> 最后才调正则（reg_lambda, reg_alpha）
> ```
>
> 一定要顺着来！这样又快又稳！

### 一些经验与 trick

* 当发现进行训练的时候，输出的日志提示 `best_iteration = n - 1` （即都是最后一轮）说明目前训练集和验证集的 loss 还在下降，模型还没有收敛到最佳状态
  * 学习率设置得太小，导致收敛
  * early_stopping_rounds 设置的太大，导致早停没怎么触发
  * 训练轮次 n_estimators 设置的太小，模型还没收敛到最佳状态
