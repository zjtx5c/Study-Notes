#  论文复现日志（2）

这里记录的主要是一些本人思考 idea 时借鉴的文章。



## HHGT

[链接](https://dl.acm.org/doi/pdf/10.1145/3701551.3703511)

2024.7

### ==思考与感悟==

这篇文章给我和我之前的一个想法有点相似：先局部 transformer 再全局 transformers



==我发现针对 HGT （异构图 transformer）的方法所遵循的原则和 dgl 的 block 机制（图采样 + 批处理手段）的底层逻辑几乎是一样的==。最大的区别是：HGT 强调 **异构类型**，DGL Block 是框架机制，但支持异构图处理。

那么针对我的 NIE 方向，我是不是可以通过改进预处理图的结构来使整个任务性能变得更好？

这篇文章指出当下 HGT 的手段与缺陷（1）不区分距离（2）不区分类型，所以我们需要关注的是：transformers 对异构信息的识别能力如何？直接喂给它一个异构图它能否准确地判断异构信息？若我们使用某种策略来人为地区分图上的异构信息（一种预处理手段），transformer的能力是否会增强。还是说我们直接再次设计一种能够天然识别针对图异构信息的 transformers 框架？（但是这项工作前人已经做过了）。

事实上，我们可以将目标放在大规模图上，那么进行训练的话就离不开 dgl 的 block 机制，这和之前HGT遵循的准则是一样的，这个操作顺便还能解决显存问题。所以我们可以考虑将重心放在预处理的框架上？？



transformers 能否自己学习到异构结构？

下面两个公式分别是 transformers 和 GAT 的异构图聚合和注意力计算公式（NIE 方向上）

下面这个公式是第 $h$ 个头的两点之间的注意力公式的计算

RGTN、SKES、EASING 均使用了下式这种聚合注意力计算公式（transformers）
$$
w^{(l),h}_{y \rightarrow x} = 
\frac{
\left( W^{(l),h}_Q H^{(l)}_x \cdot \left( W^{(l),h}_K H^{(l)}_y \right)^\top \right)
\cdot W^{(l),h}_E E^{(l)}_{y \rightarrow x}
}{
\sqrt{d}
}
$$

$$
\alpha_{y \to x}^{(l),h} = 
\sum_{e \in \mathcal{E}(y, x)} 
\frac{
    \exp\left( w_{y \xrightarrow{e} x}^{(l),h} \right)
}{
    \sum\limits_{y' \in \mathcal{N}(x)} \sum\limits_{e' \in \mathcal{E}(y', x)} \exp\left( w_{y' \xrightarrow{e'} x}^{(l),h} \right)
}
$$

___

GENI、MultiImport、EASING均使用了下面面这种聚合注意力计算公式（GAT）

> $\mathbf{h}_i$ 和 $\mathbf{h}_j$ 分别表示汇点和源点的隐向量， $\alpha$ 是一个可学习的注意力权重系数，学习并度量目标节点对该边的依赖强度

$$
\omega_l(i, j, m) = 
\frac{
    \exp\left( \mathrm{LeakyReLU}\left( \mathbf{a}_l^\top [ \mathbf{h}_{i}^{l-1} \| \pi(\rho_{ij}^{m}) \| \mathbf{h}_{j}^{l-1} \right]) \right)
}{
    \sum_{(k, n) \in \mathcal{N}(i)} 
    \exp\left( \mathrm{LeakyReLU}\left( \mathbf{a}_l^\top [ \mathbf{h}_{i}^{l-1} \| \pi(\rho_{ik}^{n}) \| \mathbf{h}_{k}^{l-1} \right]) \right)
}
$$

前者是**点积注意力**，用两个变换（Query/Key）产生向量，然后直接计算相似性，**能够自然捕捉高阶结构相似性、语义相似性、空间相似性**，并且**在理论上是通用函数逼近器**

后者是**加性注意力**，用一个向量 $\mathbf{a}$ 和拼接后的表示做一次投影 + 激活函数，属于浅层打分方式（Single-layer MLP 近似），**表达能力弱、结构简单**。





transformers 的优越性有

**表达能力更强**（点积注意力能建模更复杂的语义关系）；

GAT 是**加性注意力**，用一个向量 $\mathbf{a}$ 和拼接后的表示做一次投影 + 激活函数，属于浅层打分方式（**Single-layer MLP 近似**），**表达能力弱、结构简单**。

Transformers 是**点积注意力**，用两个变换（Query/Key）产生向量，然后直接计算相似性（该相似性是基于这一跳子图中目标节点及其邻居入点的”全局“视角的），**能够自然捕捉高阶结构相似性、语义相似性、空间相似性**，并且**在理论上是通用函数逼近器**

尽管 Transformer-style 注意力机制在理论上具有较强的表达能力，但在图神经网络中，它并不具备 LLM 中 Transformer 的那种显著的计算效率和扩展性优势。在 dgl 框架下，其原因在于，图结构是天然稀疏的，注意力仅在目标节点与其邻居之间计算，而非全图 token 之间的全连接计算。即使采用 full-batch 训练，DGL 等稀疏图框架下的计算也采用基于边的消息传递机制，不会构造显式的 $N \times N$自注意力矩阵，因此无法像 LLM 中那样使用高效的矩阵乘法加速（如 FlashAttention）。这一结构限制使得图上的 Transformer 无法在并行性和计算效率上获得与 NLP 中 Transformer 相同的优势。但是这不重要。既然是这样，那我们为什么会爆显存？仔细分析 `EASING` 中的 `GTLayer` 代码模块可以知道，内存复杂度随节点和边数是**线性增长**的，所以即便是在全图视角下怎么会爆内存呢？首先需要明确一点的是：**数据中所有的节点都会用到！因为我们为所有的节点都创建了结构特征与语义特征，但是只有少部分节点有标签。**

不懂啊，为什么会爆显存啊。刚测试了一下，使用自己能在服务器上跑的参数与FB15k数据集去训练模型，发现一个模型第一次反向传播后会用到 2G，继续深究

边[607164, 10]和节点[14951, 64]特征加起来约为 24MB

q, k, v[14951, 4, 8] 加起来大约 10M

`graph.apply_edges(fn.v_dot_u('q', 'k', 't'))` 约 9M（4B存）

`attn_score = graph.edata.pop('t').sum(-1) / self.sqrt_dim  # [n_edge, n_head]` 约 9M（4B存）

```python
attn_score = self.attn_drop(edge_softmax(graph, attn_score.unsqueeze(-1), norm_by='dst'))

graph.edata.update({'t': attn_score})
```

  30MB

后续的 前馈神经网络 一共也就加了 20MB，不仔细细算了。

反正截至到计算 struct_h 的编码器的两层一共是223.01MB正常

content_h 则是 500.90MB



解码器部分一计算 x_m 和 x_v 直接变成 2361 MB，接下来细究

```python
s = torch.bmm(self.p_s, q_input) # [B, N, 2d]
u = torch.bmm(self.p_u, q_input) # [B, N, 2d]
```

花费了 70MB（4B），这里是 `[14951, 10, 64]`，我们将 N 设置为10， 我们的 num_hidden 设置为 8 ，heads 设置为 4，这里的 2d 就是 4 * 8 * 2 = 64



计算完下述这6个矩阵，增加了216MB

```python
qs = self.w_qs(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
ks = self.w_ks(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
vs = self.w_vs(s).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]

qu = self.w_qu(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
ku = self.w_ku(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
vu = self.w_vu(u).reshape(s.shape[0],self.heads_num,s.shape[1],self.heads_dim) # [B, heads_num, N, heads_dim]
```

[14951, 4, 10, 16]



60MB

```
ua_s_attn = torch.matmul(qs / self.sqrt_d, ks.transpose(-2,-1)) # [B, heads_num, N, N]
```

[14951, 4, 10, 10]



后面的不细算了，反正一层前向 DJE 大概是700MB。我们还用了两个模型，每次采样还要再重复一整个前向过程。这么一累计确实大了。所以问题终于得到了解决，和 transformers 的自注意力机制无关（==**自注意力需要的显存其实只与 $E$ 呈线性关系而不是和 $n^2$ 正相关**==），就是单纯的模型参数多（尤其是解码部分） +  数据量大（整图 + 大图） + 常数大（模型多用）



上述这种transformers 的 attention 构造方式**能有效建模==单跳==邻接关系中的异构性**，适合做类型感知的局部信息聚合；但它的表达能力受限，**不能捕捉复杂、跨边/跨跳/多元异构路径下的语义交互**。（**我所见的论文中 NIE 方向相关的 transformer 建模在聚合层面确实只关注一层的信息，但不排除其他 HIG 方向的论文有跨边/跨跳/多元异构路径下的建模**）

```python
# 对异构图边注意力机制的处理
if self.edge_mode == 'DOT':
    rel_feat = self.e_linear(edge_feat).reshape(-1, self.n_heads, self.out_dim)
    graph.edata.update({'rel': rel_feat})
    graph.apply_edges(lambda edges: {'e': edges.src['q'] * edges.data['rel']})
    rel_attn = graph.edata.pop('e').sum(-1) / self.sqrt_dim
    attn_score = attn_score + rel_attn
elif self.edge_mode == 'MUL':
    edge_attn = self.e_linear(edge_feat)  # [n_edge, n_head]
    attn_score = attn_score * edge_attn
elif self.edge_mode == 'ADD':
    edge_attn = self.e_linear(edge_feat)  # [n_edge, n_head]
    attn_score = attn_score + edge_attn
elif self.edge_mode == 'GATE':
    edge_attn = self.e_linear(edge_feat)
    attn_score = attn_score * edge_attn
    attn_score = self.attn_drop(edge_softmax(graph, attn_score.unsqueeze(-1), norm_by='dst'))
```



理论上 transformer 有 capacity，但存在问题：

| 问题               | 说明                                                         |
| ------------------ | ------------------------------------------------------------ |
| **异构类型弱建模** | 多数 HGT 架构中 type embedding 只是一个加性偏置？（反正我见到的都是乘一个系数即直接对边类型嵌入得到一个乘法系数加入到自注意力的计算当中），事实上，做法有很多具体见上面的公式和代码。是否能建模复杂关系呢（在 NIE 这个方向上的 Gtrans 确实是聚合时只关注周围一层，而没有捕捉复杂、跨边/跨跳/多元异构路径下的语义交互） |
| **距离信息缺失**   | 由于 attention 本身不感知 hop distance，需要额外引入 positional bias |
| **图结构信息稀疏** | 大图场景中，局部结构不完整，Transformer 表现力过剩，容易过拟合或失效 |

事实上，既然已经明确==**自注意力需要的显存其实只与 $E$ 呈线性关系而不是和 $n^2$ 正相关**==，那么很遗憾，我之前的 idea 计划的动机就已经被打翻了。我以为 g_trans 是针对全图的 g_trans 因而有了将图分成子图训练的想法，但实际上 g_trans 就是针对的一跳子图即**基于邻居进行聚合**，所以上述的做法其实并不需要了。这波很伤。

那么我们还可以往哪里思考突破呢？

1. NIE 方向上的 g_trans 相关论文确实可能没有充分考虑到图的异质性 $\rightarrow$ 如何充分挖掘图中的异质性

   1. 新框架？（重新设计一个 HGT 还是做一些预处理之类的工作）

      当下的 HGT 存在表达能力[35]、过度平滑[5]和过度压缩[1]等挑战，如果选择往这个方向做那就是要换塞到了...

   2. 新理论？

2. 我们将目标瞄到异构图的大规模图的训练上，那么势必要用到图采样 + 批处理技术。之前的做法是随机采样目标节点，但是我们是在大规模的异构图上，所以直觉上感觉这种做法其实是比较莽撞的，原因如下（可能有误）：

   1. （训练稳定性角度）打乱节点顺序和在小批量中处理节点，可能会导致每次训练的梯度计算**基于不同的子图**。这样会使得训练过程中的梯度波动较大，因为每个 mini-batch 内的节点信息局部性较强，**无法全面反映全图结构**。因此，训练的收敛速度可能较慢，需要更多的训练轮次来达到与 full-batch 相同的效果。训练的效果也可能受到批次大小和打乱顺序的影响，我们可能需要一定的策略来保证每个 batch 能代表整体图的结构。
   2. （异构图复杂性角度）在 mini-batch 中，每个 batch 的节点和其邻居可能来自图的不同部分，并且包含不同类型的节点和边。因此，打乱节点顺序可能导致某些类型的节点信息不足，影响异构图中各类信息的均衡学习。为此，一些方法会使用采样策略（如基于节点类型或边类型的采样）来保持训练中各类节点的代表性。

   我们是否可以考虑在这一个方向优化







### 摘要

表现力限制和过度平滑促使研究人员探索图形变换器（GT）以增强HIN**表示学习**。





### 引言

近年来，关于异构图的表示学习激增，这项技术可以**将节点嵌入到低维表示**中，同时**保留图结构和异构性**。

#### HGCN

基于HGNN的方法[11,19]通常利用**邻居聚合**策略，在HIN中的不同类型节点之间有效地捕获和传播信息。例如，R-GCN[23]通过结合关系特定的权重矩阵，在HIN中捕获各种关系，扩展了传统的图卷积网络（GCN）[17]。Fu等人[11]提出沿元路径合并中间节点，使用元路径内和元路径间信息进行高阶语义信息聚合。

尽管HGNN在模拟现实世界的HIN方面取得了成功，**但表达能力[35]、过度平滑[5]和过度压缩[1]等挑战的存在促使研究人员研究图形变换器（GT）[40]，以增强HIN表示学习**。例如，Hu等人[14]提出了一种**用于邻居聚合的异构Transformer式注意力架构**。Mao等人[21]利用**局部结构编码器和异构关系编码器来捕获HIN中的结构和异构信息**。一般来说，现有的基于GT的HIN表示学习方法，即图1（b）所示的基于HGT  （异构图 transformer） 的方法，遵循一个典型的原则：**给定一个目标节点，首先提取其k跳邻域（即距离目标节点≤k的可达距离内的节点）。然后，Transformer[29]将用于将信息从这些节点传播到目标节点。**（==其实就是做一个子图的处理==）这不就是一个 dgl 的 block 机制

比如 `figure 1` 中的 `b Existing HGT-based methods` 就揭露了当下的 HGT 的手段与缺陷！！！：

> 将 P1 的 2-hop 邻居（P2、A1、A3、S1、P3、P4）**全部统一处理**；
>
> 也就是说：
>
> - **不区分距离**：P2 是直接邻居（1-hop），P3 是间接邻居（2-hop），都混在一起；
> - **不区分类型**：论文、作者、主题的表示放到一个 attention 序列中统一计算；
>
> 缺点：语义容易混淆，难以理解不同节点“在结构中的不同语义角色”。



论文中也指出了了当下 HGT 的痛点、缺陷与不足（==这一块务必仔细阅读，好好理解==）

> 然而，现有的基于HGT的方法倾向于混合不同类型的节点，并在邻居聚合过程中统一处理k-hop邻域内的所有节点，从而导致潜在的语义混淆。特别是，（1）限制1：HIN中不同距离的目标节点的邻居具有不同的语义。以图1（a）为例，论文P1的直接邻居论文P2表示引用关系。相反，p1的间接邻居p3暗示了一种没有直接引用关系的主题联系，展示了不同的内涵。遗憾的是，现有的策略通过统一处理距离k内的每个邻居来忽略这些区别，即将P1、P2、P3**打包成一个序列**并统一聚合它们。这是不理想的，因为这些节点服务于不同的功能。（2）限制2：不同类型的目标节点的邻居也具有不同的语义。以图1（a）为例，论文P1的直接邻居包括论文P2、作者A1、A3和受试者S1。这里，P2表示引用关系，A1、A3表示作者关系，S1表示主题对齐关系。虽然现有的基于HGT的方法**考虑了节点类型**，**但它们通常将P2、A1、A3、S1打包在一起作为一个统一的序列**（**这是 HGT 所没有考虑到的**）。这种方法是不可取的，**因为它在邻居聚合过程中混合了不同类型的节点，模糊了论文、作者和受试者的不同功能。**

总结来说就是异构图中存在距离和邻居的异质性，而之前的 HGT 都没有考虑到



下面列举了一些**以前的**代表性工作

* R-GCN

  其实就是**最原始的**异构图的处理手段，对不同类型的边（关系）使用不同的变换矩阵，从而实现“关系感知”的聚合。

  > 我们以一个学术图（Academic Graph）为例，图中包含：
  >
  > - **三种节点类型**：Paper（P）、Author（A）、Venue（V）
  > - **几种关系类型**：
  >   - Paper ←write-by→ Author
  >   - Paper ←published-in→ Venue
  >   - Paper ←cite→ Paper
  >
  > 例如：
  >
  > - P1 是由 A1 和 A2 撰写的论文，发表于 V1；
  > - P2 是由 A2 撰写的论文，引用了 P1；
  > - P3 是由 A3 撰写的，和 P1 都发表于 V1。
  >
  > 图自己画一下就行了（很简单）
  >
  > 
  >
  > **方法核心：**
  >
  > ==R-GCN 对不同类型的边（关系）使用不同的**变换矩阵**，从而实现“关系感知”的聚合。==
  >
  > 
  >
  >  **举例：**
  >
  > 假设我们要更新节点 P1 的表示：
  >
  > - P1 的邻居包括：
  >   - A1, A2（write 关系）
  >   - V1（published-in）
  >   - P2（被 P2 引用）
  >
  > R-GCN 的聚合逻辑是：
  >
  > - 使用写作者的表示向量，通过参数矩阵 **W_write** 变换；
  > - 使用 Venue 的表示向量，通过 **W_publish** 变换；
  > - 使用被引用的论文的表示向量，通过 **W_cite** 变换；
  > - 聚合时不同关系分别处理，不会“混淆”。

  

* MAGNN [csdn阅读链接](https://blog.csdn.net/byn12345/article/details/105101492) （**暂时搁置**。。）反正这里这种方法是基于元路径的多种聚合手段

  基于元路径的手段，使用元路径合并中间节点，使用元路径内和元路径间信息**进行高阶语义信息聚合**。聚合整个路径的表示

  > 现有的基于元路径的嵌入学习方法有以下局限性：
  >
  > （1）忽略节点的内容特征（属性信息），不能很好地处理节点属性特征丰富的异质图。例如 metapath2vec, ESim, HIN2vec, HERec。
  >
  > （2）舍弃了元路径内部的节点信息，只考虑元路径的起始节点和末尾节点，造成信息损失。例如 HERec, HAN。
  >
  > （3）只依赖于单个元路径，因此需要人工选择元路径，丢失了来自其他元路径的部分信息，导致性能不佳。例如 metapath2vec。
  >
  > 为了解决上述问题，本文提出MAGNN（Metapath Aggregated Graph Neural Network ）。
  >
  > MAGNN由三个部分组成：
  >
  > （1）节点内容转换(node content transformation )，将异质的节点属性信息映射到同一个**隐层的向量空间**；
  >
  > （2）元路径**内部聚合**(intra-metapath aggregation )，使用注意力机制将元路径**内部的语义信息**纳入考虑；
  >
  > （3）元路径**间的聚合**(inter-metapath aggregation )，使用**注意力机制从多个元路径聚合信息**。
  > 
  >



* HGT （贡献很大的一篇文章）

  > 将标准 Transformer 改造为**异构图专用模型**，支持多种节点类型与边类型。
  >
  > 可以理解为：**注意力不仅考虑邻接关系，还区分每种异构边、异构节点对的交互模式。**
  >
  > **2. 时间编码（可选）：**
  >
  > 他们还为动态图（如引用网络）引入时间编码，可以处理时间序列。
  >
  > **3. 基于 Transformer 的堆叠式结构：**
  >
  > 和标准 GNN 一样，多层 HGT 会逐层融合多跳邻居信息，但内部机制是带类型感知的 Transformer。



* HINormer （2023年 80 引用）

  利用局部结构编码器和异构关系编码器来捕获HIN中的结构和异构信息。（貌似和我最开始的想法很像）

  进一步改进 HGT，缓解计算量大、信息干扰的问题，同时提升表达能力。

  > 1. **Local Structure Encoder**
  >
  > - 构造目标节点的局部结构视图，比如：
  >   - 局部子图中有哪些节点、类型、边；
  >   - 用轻量注意力机制捕捉结构模式。
  >
  > 2. **Heterogeneous Relation Encoder**
  >
  > - 更精细建模不同关系的作用（类似于 HGT 但更高效）；
  > - 使用了结构编码 + 边编码的组合策略；
  > - 学习关系类型与语义的交互表示。
  >
  > 3. **优势：性能更优，计算更快**
  >
  > - 他们主张结构编码和语义融合可以减少**不必要的全 attention**；
  > - 因此**更适合大图、低资源环境**；
  > - 实验中比 HGT 更快，效果也更强。

#### HHGT 的设计

##### 设计1

**为了区分不同距离的节点邻居**，我们引入了一种称为kring邻域的创新结构。这种结构具体指的是与目标节点的距离恰好为k的节点，将其与众所周知的k-hop邻域区分开。本质上，我们将k跳邻域划分为k+1个不重叠的k环邻域，其中每个k环邻域中的节点与目标节点的距离相同。如图1（c）所示，考虑k=2，对于纸张P1，其距离为2的邻居可以分解为三个不同的k环邻居：0环邻居{P1}、1环邻居{P2，A1，A3，S1}和2环邻居{P3，P4}。基于这种新结构，**我们为每个节点提取了不同的k环邻域，这可以自然地辨别不同的功能，从而防止语义混淆**（但事实上，个人认为即便是在同一环领域的节点，其语义信息也并不一致）。**然后，设计一个环级变换器，分别聚合不同的k环邻域，聚合基于每个k环邻域与目标节点的相关性和重要性。**（相当于在距离这一层上直接编码区分）

##### 设计2

**为了避免在每个k环结构中混合不同类型的节点（这里是考虑在同一环形邻域内的情况）**，我们进一步提出了一种新的（k，t）环结构，根据每个k环的类型将节点排列成不同的组。基于这种邻域划分，考虑到每种类型对目标节点的重要性，提出了一种类型级变换器，用于分别聚合每个k环结构内目标节点的不同类型的邻域。在图1（a）中，考虑节点P1的1-环邻域（即P2、A1、A3、S1），其中不同类型的节点共存。我们根据节点类型将这个1-环邻域分为三组，即论文P2、作者A1、A3和主题S1，**每组都携带唯一的函数**。然后，我们应用一个类型级Transformer来单独聚合每个组，而不是像现有的基于HGT的方法那样将它们视为一个统一的序列。这种方法使我们能够模拟不同类型节点的不同角色。



总结：

对于每个目标节点，我们从不同的k环邻域中提取其邻居，其中每个环内的节点根据其类型进一步分组，形成创新的（k，t）**环**    **邻域**    结构。基于这种结构，我们引入了一种新的分层异构图变换器（HHGT）模型。该模型无缝集成了一个类型级转换器，**用于分别聚合每个k环邻域内不同类型的节点**，然后是一个**环形转换器**，用于以**分层方式聚合不同的k环邻域**。



##### 贡献

* 我们首次为HIN表示学习设计了一种创新的（k，t）环邻域结构，强调了HIN中距离和类型的异质性。（这里的类型可以更加激进地理解为同一环形邻域内的不同节点类型）
* 据我们所知，我们是**第一个使用分层的图 transformers 模型，来进行异构图中的节点表征学习任务**，该模型无缝集成了类型级变换器，用于分别聚合每个k环结构中不同类型的节点，然后利用环形级变换器对不同的k环邻域进行分层聚合。
* 在两个真实世界的HIN基准数据集上的实验结果表明，我们的HHGT在两个典型的下游任务上明显优于14种基准方法。此外，消融研究验证了考虑HIN距离和类型异质性的优势和意义。



### 相关工作

#### HIN嵌入的浅层模型

近年来，许多图嵌入技术应运而生，旨在将节点或子结构映射到低维空间，同时保留图中的连接结构。由于现实世界中的网络通常包含多种类型的节点和关系，针对异构信息网络（HIN）嵌入的浅层模型研究引起了广泛关注。浅层模型主要分为基于随机游走的方法和基于一阶/二阶邻近性的 methods。这些方法利用**元路径**或**类型感知的网络邻近约束**来利用网络的异构性进行HIN嵌入。尽管这些方法有所贡献，但它们未能有效捕捉HIN中的复杂关系和语义，导致表示学习效果不理想。



#### HIN嵌入的深度模型

1. **HINs的研究背景**：
   - 深度学习模型在同质图中的成功激发了对异构信息网络（HINs）研究的关注。HINs涉及不同类型的节点和边，要求模型能够处理这种复杂的结构。
2. **两类HIN嵌入模型**：
   - **基于元路径的深度模型**：这些模型使用**元路径**来聚合特定类型邻居的信息，能够捕捉更高阶的语义信息。一个例子是**HAN**模型，它采用了层次注意力机制来学习节点和元路径的重要性。缺点是**需要专家知识来选择元路径**，这对模型性能有较大影响。
   - **无元路径的深度模型**：这些模型（如**Schlichtkrull**的关系感知图卷积层和**Hu**的基于Transformer的注意力机制）不依赖于元路径，旨在通过邻居聚合来进行表示学习。虽然无元路径的模型减少了人工选择元路径的需求，但存在两个问题：
     1. **节点类型混合**：在邻居聚合过程中，不同类型的节点被混合处理，导致无法充分捕捉不同类型节点之间的关联。
     2. **距离语义混淆**：忽视了HIN中不同距离邻居所携带的不同语义信息，导致邻居聚合时出现语义混淆，从而影响下游任务的性能。

HIN嵌入有两种主要方法，并指出了无元路径模型在处理节点关系和语义信息时的不足之处。

有时间去了解一下这两类处理方法的代表性方法



### 准备工作

* 问题定义
* transformers 编码器



### 方法论

该模型由两个重要模块组成：Ring2Token和TRGT。总体框架如图2（a）所示。给定一个HIN和一个整数K，对于每个目标节点，我们最初利用Ring2Token提取多个K环邻域（K∈[0，K]），从0环邻域到K环邻域，在每个K环结构中按类型划分组织良好的节点，形成（k，t）-环邻域结构。在邻域划分之后，**我们使用TRGT模块基于这些提取的（k，t）环邻域通过GT层学习节点表示**。这涉及一个类型级转换器来聚合每个k环邻域内不同类型的节点，然后是一个环级转换器来分层聚合不同的k环邻域。



#### Ring2Token

==如何有效地将邻居的信息聚合到节点中，对于设计强大的HIN表示学习模型至关重要==。

这个模块好理解，看 Figure 3 就能理解了



#### TRGT Module

##### 类型 Transformer

T 一致，不够补 0 

* 类型级注意机制

##### 环形 Transformer
