# BUG é›†åˆ

## Hard Bug

* Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward

  å°è¯•ç¬¬äºŒæ¬¡å‘åéå†å›¾ï¼ˆæˆ–è€…å°è¯•è®¿é—®åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­ä¿å­˜çš„ä¸­é—´è®¡ç®—ç»“æœï¼‰ã€‚å½“æ‚¨è°ƒç”¨.backwardï¼ˆï¼‰æˆ–autograd.gradï¼ˆï¼‰æ—¶ï¼Œå°†é‡Šæ”¾å›¾ä¸­ä¿å­˜çš„ä¸­é—´å€¼ã€‚å¦‚æœéœ€è¦ç¬¬äºŒæ¬¡å‘åéå†å›¾ï¼Œæˆ–è€…åœ¨è°ƒç”¨backwardåéœ€è¦è®¿é—®ä¿å­˜çš„å¼ é‡ï¼Œåˆ™æŒ‡å®šretain_graph=True

  * ä¸ªäººæ„Ÿè§‰æœ‰ä¸¤ä¸ªåŸå› ï¼ˆ1ï¼‰è¿ç»­ä¸¤æ¬¡è°ƒç”¨ `.backward()`ï¼ˆ2ï¼‰å°è¯•åœ¨åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è®¿é—®å·²ç»é‡Šæ”¾æ‰çš„ä¸­é—´ç»“æœã€‚
  * æœ€ç®€å•æš´åŠ›çš„è§£å†³åŠæ³•å°±æ˜¯ `loss.backward(retain_graph=True)`ï¼Œåªæ˜¯å¯¹å†…å­˜æ¶ˆè€—å¤§ï¼Œå¯¹å®é™…çš„ç»“æœå¹¶æ²¡æœ‰ä»€ä¹ˆå½±å“ã€‚
  * **ç»è¿‡ç ”ç©¶ï¼Œæˆ‘å‘ç°äº†æ˜¯å“ªä¸ªåœ°æ–¹çš„æ¢¯åº¦æ–­äº†ï¼Œä½¿ç”¨ä»£ç è¿›è¡Œè¯¦ç»†æ’æŸ¥**
  
    ```
    for name, param in model.named_parameters(): 
        print(name, param.requires_grad, param.grad)
    ```
    æˆ–è¾“å…¥ä»¥ä¸‹ä»£ç è¿›è¡Œå¿«é€Ÿæ’æŸ¥
    ```
     for name, param in model.named_parameters():
        if param.grad is None:
            print(f"å‚æ•° {name} çš„æ¢¯åº¦æ˜¯ Noneï¼Œè®¡ç®—å›¾å¯èƒ½æ–­è£‚")
    ```
    å‘ç°å‡ ä¹éƒ½æ˜¯ `gat_layers0` æˆ– `gat_layers1` ä¸­çš„ `attn_l`, `attn_r`, `attn_m`, `.bias` ä¸ `fc.weight` æ–­è£‚ ä¸”éƒ½ä¸**è¾¹åµŒå…¥**ç›¸å…³ï¼ï¼ï¼ï¼ã€‚äºæ˜¯é¡ºè…¾æ‘¸ç“œç»ˆäºè¢«æˆ‘æ’æŸ¥å‡ºäº†é”™è¯¯ï¼ŒåŸæ¥æ˜¯åœ¨ `MultiImportModel` ä¸­ä¼ å…¥ `edge_weight` æ—¶å€™ï¼Œ `edge_weight` å¹¶ä¸æ˜¯å¯å­¦ä¹ çš„å¼ é‡ã€‚è§£å†³æ–¹æ³•ä¸ºå°†åŸå…ˆ`models` æ¨¡å—ä¸­çš„ `edge_weight_dic = {etype: g.edges[etype].data['weight'] for etype in g.etypes}` ä¿®æ”¹ä¸º `edge_weight_dic = {etype: nn.Parameter(g.edges[etype].data['weight']) for etype in g.etypes}`
  * èŠ±è´¹æ—¶é—´ ä¸€å¤©+ä¸€ä¸Šåˆ
  * ==åç»­ï¼šåˆåœ¨å¼ é‡çš„é—®é¢˜ä¸Šå‡ºé”™äº†ï¼Œä»¥åçš„å®éªŒä¸€å®šè¦å¥½å¥½æ£€æŸ¥å“ªäº›åº”è¯¥è¢«è®¾ç½®æˆ**å¶å­å¼ é‡**== ï¼ˆå¯¼è‡´è¿™ç‚¹å‡ºç°çš„åŸå› æ˜¯ï¼Œæˆ‘ä»¬å¿½ç•¥äº†æˆ‘ä»¬çš„åµŒå…¥æ˜¯è‡ªå·±æ„é€ çš„ï¼Œè€Œä¸€èˆ¬çš„åµŒå…¥éƒ½æ˜¯é€šè¿‡ `word2vec` ç­‰ç®—æ³•ç”Ÿæˆçš„ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­ä¼šä½¿ç”¨åˆ° `nn.Module` æ¨¡å—ï¼Œå®ƒä»¬ä¼šè‡ªåŠ¨å°†å¯¹åº”çš„æ•°æ®æ³¨å†Œä¸ºå¶å­å¼ é‡ï¼‰ã€‚

## Easy Bug

* TypeError: torch.FloatTensor is not a Module subclass
  FloatTensorä¸æ˜¯Moduleçš„å­ç±»ã€‚

  ```python
  layers = nn.ModuleList([  # ä½¿ç”¨ ModuleList
      nn.Linear(10, 20),
      nn.ReLU(),
      nn.Linear(20, 1),
      torch.tensor(3.0)
  ])
  ```

  å½“æˆ‘å°è¯•è¿›è¡Œå¦‚ä¸Šæ“ä½œæ—¶ï¼Œè¢«æŠ¥é”™äº†ã€‚åŸå› åœ¨äº `torch.tensor()` å¹¶ä¸æ˜¯ `nn.Module` å­ç±»ï¼Œè€Œæ˜¯ `Tensor()` çš„å­ç±»ã€‚`nn.ModuleList()` ä¸­ï¼ˆåªèƒ½åŒ…å«ï¼‰éœ€è¦ä¼ å…¥çš„æ˜¯ç±»ä¼¼äº `nn.Linear()`,`nn.ReLU` ç­‰ `nn` ã€‚è€Œè¿™ç±»ä¸œè¥¿å®ƒä»¬çš„å‚æ•°èƒ½å¤Ÿè¢«è‡ªåŠ¨æ³¨å†Œä¸”å¯ä»¥è®¡ç®—æ¢¯åº¦ï¼Œå³èƒ½è¢«`parameters()` æ–¹æ³•è¯†åˆ«ä¸ä¼˜åŒ–å™¨æ›´æ–°ï¼Œä½†æ˜¯ `Tensor` ç±»ä¸å…·å¤‡è¿™ä¸ªåŠŸèƒ½ã€‚

  
  
  ```python
  layers = nn.ModuleList([  # ä½¿ç”¨ ModuleList
      nn.Linear(10, 20),
      nn.ReLU(),
      nn.Linear(20, 1),
      nn.Parameter(torch.tensor(3.0))
  ])
  ```
  
  æˆ‘åœ¨æ­¤è¿›è¡Œäº†å°è¯•ï¼Œä»ç„¶æ”¶åˆ°äº†åŒä¸Šè¿°ä¸€æ ·çš„æŠ¥é”™ã€‚**è¿™æ˜¯å› ä¸º `nn.Parameter` å¹¶ä¸æ˜¯ `nn.Module`  çš„å­ç±»ï¼Œ`nn.Parameter` åªæ˜¯ä¸€ä¸ªå¯è®­ç»ƒçš„ `Tensor`** ã€‚`nn.Parameter` æ˜¯ **`torch.Tensor` çš„å­ç±»**ï¼Œå®ƒçš„å”¯ä¸€ä½œç”¨æ˜¯**å‘Šè¯‰ PyTorch è¿™ä¸ª `Tensor` éœ€è¦è¢«è®­ç»ƒ**ï¼Œ**å®ƒä¸åŒ…å« `forward()` é€»è¾‘ï¼Œä¹Ÿä¸å­˜å‚¨å­æ¨¡å—ï¼Œæ‰€ä»¥ä¸æ˜¯ `nn.Module`**ã€‚
  
  è€Œ `nn.Module` æ˜¯ä¸€ä¸ªå®¹å™¨ï¼š`nn.Module` ä¸»è¦ç”¨äº**ç®¡ç†** `nn.Linear()`ã€`nn.Conv2d()` ç­‰**åŒ…å«æƒé‡**çš„å±‚ï¼Œå¹¶ä¸”å®ƒå¯ä»¥**åµŒå¥—**å…¶ä»– `nn.Module`ï¼Œå½¢æˆå®Œæ•´çš„æ¨¡å‹ã€‚
  
  `nn.Module` æœ‰ **`forward()` æ–¹æ³•**ï¼Œå¯ä»¥å®šä¹‰å‰å‘ä¼ æ’­çš„è®¡ç®—é€»è¾‘ã€‚
  
  `nn.Parameter` åªæœ‰ä½œä¸º `nn.Module` çš„ **å±æ€§**ï¼ˆæ¯”å¦‚ `self.param = nn.Parameter(...)`ï¼‰ï¼Œæ‰ä¼šè¢« `parameters()` è¯†åˆ«ã€‚
  
  å¦‚æœ `nn.Parameter` **å¹¶æœª**æ·»åŠ åˆ°æ¨¡å‹çš„ `parameters()` ä¸­ï¼Œè€Œ**åªæ˜¯ä½œä¸ºä¸­é€”è®¡ç®—çš„ä¸€éƒ¨åˆ†**ï¼Œå®ƒå°† **ä¸ä¼š** è¢«è§†ä¸ºæ¨¡å‹çš„å¯è®­ç»ƒå‚æ•°ï¼Œä¸”ä¸ä¼šé€šè¿‡åå‘ä¼ æ’­è¿›è¡Œæ›´æ–°ã€‚å®ƒçš„æ•ˆæœå®é™…ä¸Šç­‰åŒäºä¸€ä¸ªæ™®é€šçš„ **æœ‰æ¢¯åº¦çš„ Tensor**ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªçœŸæ­£çš„å¯è®­ç»ƒå‚æ•°ã€‚

* å‘ç”Ÿå¼‚å¸¸: NotImplementedError exception: no descriptionï¼ˆå¤ªè ¢äº†è¿™ä¸ªBUGï¼‰

  `NotImplementedError` æ˜¯ Python ä¸­çš„ä¸€ç§é”™è¯¯ï¼Œå®ƒé€šå¸¸è¡¨ç¤ºæŸä¸ªæ–¹æ³•æˆ–å‡½æ•°åœ¨ä»£ç ä¸­è¢«å£°æ˜äº†ï¼Œä½†æ²¡æœ‰å®ç°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œè™½ç„¶è¯¥æ–¹æ³•è¢«è°ƒç”¨äº†ï¼Œä½†å®ƒçš„å…·ä½“å®ç°ç¼ºå¤±äº†ã€‚

  ```python
  loss_1 = self.loss_eta1 * self.loss_1_fcn(embed_important, embed_normal)
  ```

  é•¿è¯çŸ­è¯´ï¼ŒæŠ¥é”™çš„åŸå› æ˜¯æˆ‘çš„ `self.loss_1_fcn` çš„ `forward` æ‹¼å†™é”™äº†ï¼ˆğŸ˜‚ï¼‰

* æœ‰ä¸€ä¸ªåœ¨ `pandas` çš„æ¡†æ¶ä¸Šç»è¿‡ç­›é€‰æ“ä½œä¹‹åä½¿ç”¨ `.reshape()` ä¹‹åï¼Œå‘ç° `data.shape` å±…ç„¶ä¼šæœ‰ 0 ç»´ï¼Œè€Œä¸” `data ` å±…ç„¶æ˜¯ `None` ã€‚è¿™æ˜¯ä»€ä¹ˆåŸå› ï¼Ÿ

  æ¡ä»¶ç­›é€‰è¿™ä¸€å—å‡ºé”™äº†ï¼Œç»è¿‡ç­›é€‰ä¹‹åæ•°æ®å˜ç©ºäº†...è¿™ä¸ªé”™è¯¯å®åœ¨æ˜¯å¤ªè ¢äº†...
